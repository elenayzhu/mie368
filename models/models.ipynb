{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3ec55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, r2_score, mean_squared_error\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "265e9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data_with_clusters.csv\"\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    \"airline_bucket\",\n",
    "    \"origin_bucket\",\n",
    "    \"destination_bucket\",\n",
    "    \"lagged_delay_flag\",\n",
    "    \"prev_real_delay\",\n",
    "]\n",
    "\n",
    "TARGET_CLF = \"DEP_DEL15\" #binary departure delay indicator\n",
    "TARGET_REG = \"DEP_DELAY_NEW\" #continuous departure delay (min)\n",
    "CLUSTER_COL = \"cluster\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# keep only needed columns, drop rows with missing in features/targets\n",
    "df = df.dropna(subset=FEATURE_COLS + [TARGET_CLF, TARGET_REG])\n",
    "\n",
    "X_clf = df[FEATURE_COLS]\n",
    "y_clf = df[TARGET_CLF].astype(int)\n",
    "\n",
    "X_reg = df[FEATURE_COLS]\n",
    "y_reg = df[TARGET_REG].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "024353c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_models():\n",
    "    return {\n",
    "        \"LR_L2\": LogisticRegression(\n",
    "            random_state=0, solver=\"liblinear\", max_iter=200\n",
    "        ),\n",
    "        \"LR_L1\": LogisticRegression(\n",
    "            random_state=0,\n",
    "            penalty=\"l1\",\n",
    "            solver=\"liblinear\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=500,\n",
    "        ),\n",
    "        \"CART\": DecisionTreeClassifier(\n",
    "            random_state=0, class_weight=\"balanced\"\n",
    "        ),\n",
    "        \"RF\": RandomForestClassifier(\n",
    "            random_state=0, class_weight=\"balanced\"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "def init_all_models():\n",
    "    model_names = (\"LR_L2\", \"LR_L1\", \"CART\", \"RF\")\n",
    "    techniques = (\"Baseline\", \"Scaling\")  # subset of full Lab 6 list\n",
    "\n",
    "    idx = pd.MultiIndex.from_product(\n",
    "        [model_names, techniques],\n",
    "        names=(\"model\", \"technique\"),\n",
    "    )\n",
    "    all_models = pd.DataFrame(\n",
    "        index=idx,\n",
    "        columns=[\"Precision\", \"Recall\", \"Score\", \"Model\"],\n",
    "    )\n",
    "    all_models[[\"Precision\", \"Recall\", \"Score\"]] = all_models[\n",
    "        [\"Precision\", \"Recall\", \"Score\"]\n",
    "    ].astype(float)\n",
    "    return all_models\n",
    "\n",
    "\n",
    "def standardize_data(X_train, X_out):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    Xtr = pd.DataFrame(\n",
    "        scaler.transform(X_train),\n",
    "        index=X_train.index,\n",
    "        columns=X_train.columns,\n",
    "    )\n",
    "    Xout = pd.DataFrame(\n",
    "        scaler.transform(X_out),\n",
    "        index=X_out.index,\n",
    "        columns=X_out.columns,\n",
    "    )\n",
    "    return Xtr, Xout, scaler\n",
    "\n",
    "\n",
    "def fit_and_score_model(all_models, stage_name,\n",
    "                        X_train, X_out, y_train, y_out):\n",
    "    models_dict = make_models()\n",
    "\n",
    "    for model_name, model in models_dict.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_out)\n",
    "\n",
    "        p = precision_score(y_out, y_pred)\n",
    "        r = recall_score(y_out, y_pred)\n",
    "        s = 0.5 * (p + r)\n",
    "\n",
    "        idx = (model_name, stage_name)\n",
    "        \n",
    "        all_models.at[idx, \"Precision\"] = p\n",
    "        all_models.at[idx, \"Recall\"] = r\n",
    "        all_models.at[idx, \"Score\"] = s\n",
    "        all_models.at[idx, \"Model\"] = model\n",
    "\n",
    "    return all_models\n",
    "\n",
    "\n",
    "def compare_models(all_models, technique_name=\"Scaling\"):\n",
    "    diffs = (\n",
    "        all_models.xs(technique_name, level=\"technique\").Score.values\n",
    "        - all_models.xs(\"Baseline\", level=\"technique\").Score.values\n",
    "    )\n",
    "    print(\n",
    "        f\"{technique_name}: mean ΔScore={diffs.mean():.3f}, \"\n",
    "        f\"max ΔScore={diffs.max():.3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13d59b8",
   "metadata": {},
   "source": [
    "# Model Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c4352a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling: mean ΔScore=-0.000, max ΔScore=0.000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Score</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>technique</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LR_L2</th>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.311712</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.157284</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scaling</th>\n",
       "      <td>0.311847</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.157354</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LR_L1</th>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.239996</td>\n",
       "      <td>0.513178</td>\n",
       "      <td>0.376587</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scaling</th>\n",
       "      <td>0.239987</td>\n",
       "      <td>0.512857</td>\n",
       "      <td>0.376422</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">CART</th>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.259102</td>\n",
       "      <td>0.444737</td>\n",
       "      <td>0.351919</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scaling</th>\n",
       "      <td>0.259099</td>\n",
       "      <td>0.444734</td>\n",
       "      <td>0.351916</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RF</th>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.258949</td>\n",
       "      <td>0.442471</td>\n",
       "      <td>0.350710</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scaling</th>\n",
       "      <td>0.258941</td>\n",
       "      <td>0.442458</td>\n",
       "      <td>0.350699</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Precision    Recall     Score  \\\n",
       "model technique                                  \n",
       "LR_L2 Baseline    0.311712  0.002857  0.157284   \n",
       "      Scaling     0.311847  0.002861  0.157354   \n",
       "LR_L1 Baseline    0.239996  0.513178  0.376587   \n",
       "      Scaling     0.239987  0.512857  0.376422   \n",
       "CART  Baseline    0.259102  0.444737  0.351919   \n",
       "      Scaling     0.259099  0.444734  0.351916   \n",
       "RF    Baseline    0.258949  0.442471  0.350710   \n",
       "      Scaling     0.258941  0.442458  0.350699   \n",
       "\n",
       "                                                             Model  \n",
       "model technique                                                     \n",
       "LR_L2 Baseline   LogisticRegression(max_iter=200, random_state=...  \n",
       "      Scaling    LogisticRegression(max_iter=200, random_state=...  \n",
       "LR_L1 Baseline   LogisticRegression(class_weight='balanced', ma...  \n",
       "      Scaling    LogisticRegression(class_weight='balanced', ma...  \n",
       "CART  Baseline   DecisionTreeClassifier(class_weight='balanced'...  \n",
       "      Scaling    DecisionTreeClassifier(class_weight='balanced'...  \n",
       "RF    Baseline   (DecisionTreeClassifier(max_features='sqrt', r...  \n",
       "      Scaling    (DecisionTreeClassifier(max_features='sqrt', r...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_global_classification_models(X, y, test_size=0.2, random_state=0):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    all_models = init_all_models()\n",
    "\n",
    "    # Baseline\n",
    "    all_models = fit_and_score_model(\n",
    "        all_models, \"Baseline\", Xtr, Xte, ytr, yte\n",
    "    )\n",
    "\n",
    "    # Scaling\n",
    "    Xtr_s, Xte_s, scaler = standardize_data(Xtr, Xte)\n",
    "    all_models = fit_and_score_model(\n",
    "        all_models, \"Scaling\", Xtr_s, Xte_s, ytr, yte\n",
    "    )\n",
    "\n",
    "    compare_models(all_models, \"Scaling\")\n",
    "\n",
    "    best_row = all_models.sort_values(\"Score\").iloc[-1]\n",
    "    best_model = best_row[\"Model\"]\n",
    "\n",
    "    return {\n",
    "        \"all_models\": all_models,\n",
    "        \"best_model\": best_model,\n",
    "        \"scaler\": scaler,\n",
    "        \"train_split\": (Xtr, Xte, ytr, yte),\n",
    "    }\n",
    "\n",
    "\n",
    "global_clf_results = train_global_classification_models(X_clf, y_clf)\n",
    "global_clf_results[\"all_models\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "608de875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_classification_models(df,\n",
    "                                        feature_cols,\n",
    "                                        target_col,\n",
    "                                        cluster_col=\"cluster\",\n",
    "                                        test_size=0.2,\n",
    "                                        random_state=0):\n",
    "    cluster_results = {}\n",
    "\n",
    "    for clust_id, df_c in df.groupby(cluster_col):\n",
    "        y_c = df_c[target_col].astype(int)\n",
    "        if y_c.nunique() < 2 or len(df_c) < 40:\n",
    "            continue\n",
    "\n",
    "        X_c = df_c[feature_cols]\n",
    "\n",
    "        Xtr, Xte, ytr, yte = train_test_split(\n",
    "            X_c, y_c,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=y_c,\n",
    "        )\n",
    "\n",
    "        all_models = init_all_models()\n",
    "\n",
    "        all_models = fit_and_score_model(\n",
    "            all_models, \"Baseline\", Xtr, Xte, ytr, yte\n",
    "        )\n",
    "\n",
    "        Xtr_s, Xte_s, scaler = standardize_data(Xtr, Xte)\n",
    "        all_models = fit_and_score_model(\n",
    "            all_models, \"Scaling\", Xtr_s, Xte_s, ytr, yte\n",
    "        )\n",
    "\n",
    "        best_row = all_models.sort_values(\"Score\").iloc[-1]\n",
    "        best_model = best_row[\"Model\"]\n",
    "\n",
    "        cluster_results[clust_id] = {\n",
    "            \"all_models\": all_models,\n",
    "            \"best_model\": best_model,\n",
    "            \"scaler\": scaler,\n",
    "        }\n",
    "\n",
    "    return cluster_results\n",
    "\n",
    "\n",
    "cluster_clf_results = train_cluster_classification_models(\n",
    "    df,\n",
    "    FEATURE_COLS,\n",
    "    TARGET_CLF,\n",
    "    cluster_col=CLUSTER_COL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d360e644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear': {'model': LinearRegression(),\n",
       "  'r2': 0.004382212091354809,\n",
       "  'mse': 3031.940064178128},\n",
       " 'lasso': {'model': LassoCV(cv=5, random_state=0),\n",
       "  'scaler': StandardScaler(),\n",
       "  'r2': 0.004382149319585027,\n",
       "  'mse': 3031.9402553360665},\n",
       " 'train_split': (         airline_bucket  origin_bucket  destination_bucket  lagged_delay_flag  \\\n",
       "  2840684               1              2                   3                  0   \n",
       "  2506158               1              2                   4                  0   \n",
       "  1795334               1              4                   2                  0   \n",
       "  930487                1              3                   1                  0   \n",
       "  749653                1              4                   1                  0   \n",
       "  ...                 ...            ...                 ...                ...   \n",
       "  2249467               1              1                   2                  0   \n",
       "  5157699               1              2                   4                  0   \n",
       "  2215104               1              4                   2                  1   \n",
       "  1484405               1              3                   1                  0   \n",
       "  4500015               1              3                   1                  0   \n",
       "  \n",
       "           prev_real_delay  \n",
       "  2840684              0.0  \n",
       "  2506158           1482.0  \n",
       "  1795334              0.0  \n",
       "  930487              24.0  \n",
       "  749653               0.0  \n",
       "  ...                  ...  \n",
       "  2249467              0.0  \n",
       "  5157699              0.0  \n",
       "  2215104             36.0  \n",
       "  1484405              0.0  \n",
       "  4500015             27.0  \n",
       "  \n",
       "  [5955264 rows x 5 columns],\n",
       "           airline_bucket  origin_bucket  destination_bucket  lagged_delay_flag  \\\n",
       "  4154393               1              3                   4                  0   \n",
       "  4902533               1              4                   1                  0   \n",
       "  649961                1              2                   3                  0   \n",
       "  489667                1              2                   3                  0   \n",
       "  6209768               1              4                   3                  0   \n",
       "  ...                 ...            ...                 ...                ...   \n",
       "  2005209               1              3                   1                  1   \n",
       "  4582310               0              1                   1                  0   \n",
       "  1673490               1              4                   2                  0   \n",
       "  3544446               1              3                   1                  0   \n",
       "  6635196               1              4                   2                  0   \n",
       "  \n",
       "           prev_real_delay  \n",
       "  4154393              0.0  \n",
       "  4902533             83.0  \n",
       "  649961               0.0  \n",
       "  489667               0.0  \n",
       "  6209768              0.0  \n",
       "  ...                  ...  \n",
       "  2005209            104.0  \n",
       "  4582310              0.0  \n",
       "  1673490              0.0  \n",
       "  3544446              0.0  \n",
       "  6635196              0.0  \n",
       "  \n",
       "  [1488816 rows x 5 columns],\n",
       "  2840684     0.0\n",
       "  2506158     0.0\n",
       "  1795334    60.0\n",
       "  930487      0.0\n",
       "  749653      0.0\n",
       "             ... \n",
       "  2249467     0.0\n",
       "  5157699     0.0\n",
       "  2215104     0.0\n",
       "  1484405     0.0\n",
       "  4500015     0.0\n",
       "  Name: DEP_DELAY_NEW, Length: 5955264, dtype: float64,\n",
       "  4154393      1.0\n",
       "  4902533      0.0\n",
       "  649961       0.0\n",
       "  489667       0.0\n",
       "  6209768      0.0\n",
       "             ...  \n",
       "  2005209      0.0\n",
       "  4582310    255.0\n",
       "  1673490      0.0\n",
       "  3544446      0.0\n",
       "  6635196     17.0\n",
       "  Name: DEP_DELAY_NEW, Length: 1488816, dtype: float64)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_global_regression_models(X, y, test_size=0.2, random_state=0):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Plain linear regression (unscaled)\n",
    "    lin = LinearRegression()\n",
    "    lin.fit(Xtr, ytr)\n",
    "    yhat_lin = lin.predict(Xte)\n",
    "    lin_r2 = r2_score(yte, yhat_lin)\n",
    "    lin_mse = mean_squared_error(yte, yhat_lin)\n",
    "\n",
    "    # LassoCV (scaled)\n",
    "    Xtr_s, Xte_s, scaler = standardize_data(Xtr, Xte)\n",
    "    lasso = LassoCV(cv=5, random_state=random_state)\n",
    "    lasso.fit(Xtr_s, ytr)\n",
    "    yhat_lasso = lasso.predict(Xte_s)\n",
    "    lasso_r2 = r2_score(yte, yhat_lasso)\n",
    "    lasso_mse = mean_squared_error(yte, yhat_lasso)\n",
    "\n",
    "    return {\n",
    "        \"linear\": {\n",
    "            \"model\": lin,\n",
    "            \"r2\": lin_r2,\n",
    "            \"mse\": lin_mse,\n",
    "        },\n",
    "        \"lasso\": {\n",
    "            \"model\": lasso,\n",
    "            \"scaler\": scaler,\n",
    "            \"r2\": lasso_r2,\n",
    "            \"mse\": lasso_mse,\n",
    "        },\n",
    "        \"train_split\": (Xtr, Xte, ytr, yte),\n",
    "    }\n",
    "\n",
    "\n",
    "global_reg_results = train_global_regression_models(X_reg, y_reg)\n",
    "global_reg_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06a2f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_regression_models(df,\n",
    "                                    feature_cols,\n",
    "                                    target_col,\n",
    "                                    cluster_col=\"cluster\",\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=0,\n",
    "                                    min_rows=40):\n",
    "    cluster_reg_results = {}\n",
    "\n",
    "    for clust_id, df_c in df.groupby(cluster_col):\n",
    "        if len(df_c) < min_rows:\n",
    "            continue\n",
    "\n",
    "        X_c = df_c[feature_cols]\n",
    "        y_c = df_c[target_col].astype(float)\n",
    "\n",
    "        Xtr, Xte, ytr, yte = train_test_split(\n",
    "            X_c, y_c,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        # linear\n",
    "        lin = LinearRegression()\n",
    "        lin.fit(Xtr, ytr)\n",
    "        yhat_lin = lin.predict(Xte)\n",
    "        lin_r2 = r2_score(yte, yhat_lin)\n",
    "        lin_mse = mean_squared_error(yte, yhat_lin)\n",
    "\n",
    "        # lasso (scaled)\n",
    "        Xtr_s, Xte_s, scaler = standardize_data(Xtr, Xte)\n",
    "        lasso = LassoCV(cv=5, random_state=random_state)\n",
    "        lasso.fit(Xtr_s, ytr)\n",
    "        yhat_lasso = lasso.predict(Xte_s)\n",
    "        lasso_r2 = r2_score(yte, yhat_lasso)\n",
    "        lasso_mse = mean_squared_error(yte, yhat_lasso)\n",
    "\n",
    "        cluster_reg_results[clust_id] = {\n",
    "            \"linear\": {\n",
    "                \"model\": lin,\n",
    "                \"r2\": lin_r2,\n",
    "                \"mse\": lin_mse,\n",
    "            },\n",
    "            \"lasso\": {\n",
    "                \"model\": lasso,\n",
    "                \"scaler\": scaler,\n",
    "                \"r2\": lasso_r2,\n",
    "                \"mse\": lasso_mse,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    return cluster_reg_results\n",
    "\n",
    "\n",
    "cluster_reg_results = train_cluster_regression_models(\n",
    "    df,\n",
    "    FEATURE_COLS,\n",
    "    TARGET_REG,\n",
    "    cluster_col=CLUSTER_COL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1bc1a7",
   "metadata": {},
   "source": [
    "# Cluster Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf2a49af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_clusters(df, k, cluster_features, cluster_col_name):\n",
    "    X_cluster = df[cluster_features].copy()\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    labels = kmeans.fit_predict(X_cluster)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[cluster_col_name] = labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ead0d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_EXPERIMENTS = [\n",
    "    {\n",
    "        \"name\": \"k3_all_feats\",\n",
    "        \"k\": 3,\n",
    "        \"cluster_features\": FEATURE_COLS,      # use all current features\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"k5_all_feats\",\n",
    "        \"k\": 5,\n",
    "        \"cluster_features\": FEATURE_COLS,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"k5_subset_origin_dest\",\n",
    "        \"k\": 5,\n",
    "        \"cluster_features\": [\"origin_bucket\", \"destination_bucket\"],\n",
    "    },\n",
    "    # add more as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49f5aca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "all_cluster_clf_results = {}\n",
    "all_cluster_reg_results = {}\n",
    "\n",
    "for cfg in CLUSTER_EXPERIMENTS:\n",
    "    exp_name = cfg[\"name\"]\n",
    "    k = cfg[\"k\"]\n",
    "    cluster_features = cfg[\"cluster_features\"]\n",
    "\n",
    "    # 1) assign cluster labels for this experiment\n",
    "    cluster_col = f\"cluster_{exp_name}\"\n",
    "    df_with_clusters = assign_clusters(df, k, cluster_features, cluster_col)\n",
    "\n",
    "    # 2) train cluster-specific classification models\n",
    "    cluster_clf_results = train_cluster_classification_models(\n",
    "        df_with_clusters,\n",
    "        FEATURE_COLS,       # you can choose to change this too, if needed\n",
    "        TARGET_CLF,\n",
    "        cluster_col=cluster_col,\n",
    "    )\n",
    "\n",
    "    # 3) train cluster-specific regression models\n",
    "    cluster_reg_results = train_cluster_regression_models(\n",
    "        df_with_clusters,\n",
    "        FEATURE_COLS,\n",
    "        TARGET_REG,\n",
    "        cluster_col=cluster_col,\n",
    "    )\n",
    "\n",
    "    # 4) store results keyed by experiment name\n",
    "    all_cluster_clf_results[exp_name] = cluster_clf_results\n",
    "    all_cluster_reg_results[exp_name] = cluster_reg_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea8ff41",
   "metadata": {},
   "source": [
    "# Gathering Summary Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35dd3e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>ClusterExp</th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Score</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.259102</td>\n",
       "      <td>0.444737</td>\n",
       "      <td>0.351919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.259099</td>\n",
       "      <td>0.444734</td>\n",
       "      <td>0.351916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.239996</td>\n",
       "      <td>0.513178</td>\n",
       "      <td>0.376587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.239987</td>\n",
       "      <td>0.512857</td>\n",
       "      <td>0.376422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L2</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.311712</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.157284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L2</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.311847</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.157354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>RF</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.258949</td>\n",
       "      <td>0.442471</td>\n",
       "      <td>0.350710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>RF</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.258941</td>\n",
       "      <td>0.442458</td>\n",
       "      <td>0.350699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.359075</td>\n",
       "      <td>0.604621</td>\n",
       "      <td>0.481848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.240317</td>\n",
       "      <td>0.447639</td>\n",
       "      <td>0.343978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.338638</td>\n",
       "      <td>0.601810</td>\n",
       "      <td>0.470224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.364837</td>\n",
       "      <td>0.607510</td>\n",
       "      <td>0.486173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.211704</td>\n",
       "      <td>0.522327</td>\n",
       "      <td>0.367016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.339322</td>\n",
       "      <td>0.568427</td>\n",
       "      <td>0.453875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.331784</td>\n",
       "      <td>0.544751</td>\n",
       "      <td>0.438267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>4</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.346546</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>0.475644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.260214</td>\n",
       "      <td>0.452842</td>\n",
       "      <td>0.356528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.258898</td>\n",
       "      <td>0.352007</td>\n",
       "      <td>0.305453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.265713</td>\n",
       "      <td>0.481200</td>\n",
       "      <td>0.373456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.307741</td>\n",
       "      <td>0.288359</td>\n",
       "      <td>0.298050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>4</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.208258</td>\n",
       "      <td>0.387939</td>\n",
       "      <td>0.298098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>6007.356960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>6007.356643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>2889.234537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>2889.234554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>7117.469209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>7111.294382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>6350.934545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>6350.931530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>2723.883022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>2723.882993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002294</td>\n",
       "      <td>7935.651595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>7934.597012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>4382.175054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>4382.188236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>4</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000894</td>\n",
       "      <td>7699.487776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>4</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001242</td>\n",
       "      <td>7702.166822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>2512.836732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>2512.836059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>4127.691024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>4127.694307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>3243.101835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>3243.098624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007436</td>\n",
       "      <td>1993.850727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007438</td>\n",
       "      <td>1993.847747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>4</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>3351.785667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>4</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003172</td>\n",
       "      <td>3351.785154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>3031.940255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>3031.940064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Level Cluster             ClusterExp            Task             Model  \\\n",
       "0    Global       -                      -  Classification              CART   \n",
       "1    Global       -                      -  Classification              CART   \n",
       "2    Global       -                      -  Classification             LR_L1   \n",
       "3    Global       -                      -  Classification             LR_L1   \n",
       "4    Global       -                      -  Classification             LR_L2   \n",
       "5    Global       -                      -  Classification             LR_L2   \n",
       "6    Global       -                      -  Classification                RF   \n",
       "7    Global       -                      -  Classification                RF   \n",
       "8   Cluster       0           k3_all_feats  Classification             LR_L1   \n",
       "9   Cluster       1           k3_all_feats  Classification             LR_L1   \n",
       "10  Cluster       2           k3_all_feats  Classification             LR_L1   \n",
       "11  Cluster       0           k5_all_feats  Classification             LR_L1   \n",
       "12  Cluster       1           k5_all_feats  Classification             LR_L1   \n",
       "13  Cluster       2           k5_all_feats  Classification             LR_L1   \n",
       "14  Cluster       3           k5_all_feats  Classification             LR_L1   \n",
       "15  Cluster       4           k5_all_feats  Classification             LR_L1   \n",
       "16  Cluster       0  k5_subset_origin_dest  Classification             LR_L1   \n",
       "17  Cluster       1  k5_subset_origin_dest  Classification              CART   \n",
       "18  Cluster       2  k5_subset_origin_dest  Classification             LR_L1   \n",
       "19  Cluster       3  k5_subset_origin_dest  Classification              CART   \n",
       "20  Cluster       4  k5_subset_origin_dest  Classification             LR_L1   \n",
       "21  Cluster       0           k3_all_feats      Regression           LassoCV   \n",
       "22  Cluster       0           k3_all_feats      Regression  LinearRegression   \n",
       "23  Cluster       1           k3_all_feats      Regression           LassoCV   \n",
       "24  Cluster       1           k3_all_feats      Regression  LinearRegression   \n",
       "25  Cluster       2           k3_all_feats      Regression           LassoCV   \n",
       "26  Cluster       2           k3_all_feats      Regression  LinearRegression   \n",
       "27  Cluster       0           k5_all_feats      Regression           LassoCV   \n",
       "28  Cluster       0           k5_all_feats      Regression  LinearRegression   \n",
       "29  Cluster       1           k5_all_feats      Regression           LassoCV   \n",
       "30  Cluster       1           k5_all_feats      Regression  LinearRegression   \n",
       "31  Cluster       2           k5_all_feats      Regression           LassoCV   \n",
       "32  Cluster       2           k5_all_feats      Regression  LinearRegression   \n",
       "33  Cluster       3           k5_all_feats      Regression           LassoCV   \n",
       "34  Cluster       3           k5_all_feats      Regression  LinearRegression   \n",
       "35  Cluster       4           k5_all_feats      Regression           LassoCV   \n",
       "36  Cluster       4           k5_all_feats      Regression  LinearRegression   \n",
       "37  Cluster       0  k5_subset_origin_dest      Regression           LassoCV   \n",
       "38  Cluster       0  k5_subset_origin_dest      Regression  LinearRegression   \n",
       "39  Cluster       1  k5_subset_origin_dest      Regression           LassoCV   \n",
       "40  Cluster       1  k5_subset_origin_dest      Regression  LinearRegression   \n",
       "41  Cluster       2  k5_subset_origin_dest      Regression           LassoCV   \n",
       "42  Cluster       2  k5_subset_origin_dest      Regression  LinearRegression   \n",
       "43  Cluster       3  k5_subset_origin_dest      Regression           LassoCV   \n",
       "44  Cluster       3  k5_subset_origin_dest      Regression  LinearRegression   \n",
       "45  Cluster       4  k5_subset_origin_dest      Regression           LassoCV   \n",
       "46  Cluster       4  k5_subset_origin_dest      Regression  LinearRegression   \n",
       "47   Global       -                    NaN      Regression           LassoCV   \n",
       "48   Global       -                    NaN      Regression  LinearRegression   \n",
       "\n",
       "   Technique  Precision    Recall     Score        R2          MSE  \n",
       "0   Baseline   0.259102  0.444737  0.351919       NaN          NaN  \n",
       "1    Scaling   0.259099  0.444734  0.351916       NaN          NaN  \n",
       "2   Baseline   0.239996  0.513178  0.376587       NaN          NaN  \n",
       "3    Scaling   0.239987  0.512857  0.376422       NaN          NaN  \n",
       "4   Baseline   0.311712  0.002857  0.157284       NaN          NaN  \n",
       "5    Scaling   0.311847  0.002861  0.157354       NaN          NaN  \n",
       "6   Baseline   0.258949  0.442471  0.350710       NaN          NaN  \n",
       "7    Scaling   0.258941  0.442458  0.350699       NaN          NaN  \n",
       "8   Baseline   0.359075  0.604621  0.481848       NaN          NaN  \n",
       "9    Scaling   0.240317  0.447639  0.343978       NaN          NaN  \n",
       "10   Scaling   0.338638  0.601810  0.470224       NaN          NaN  \n",
       "11   Scaling   0.364837  0.607510  0.486173       NaN          NaN  \n",
       "12   Scaling   0.211704  0.522327  0.367016       NaN          NaN  \n",
       "13  Baseline   0.339322  0.568427  0.453875       NaN          NaN  \n",
       "14   Scaling   0.331784  0.544751  0.438267       NaN          NaN  \n",
       "15   Scaling   0.346546  0.604743  0.475644       NaN          NaN  \n",
       "16   Scaling   0.260214  0.452842  0.356528       NaN          NaN  \n",
       "17   Scaling   0.258898  0.352007  0.305453       NaN          NaN  \n",
       "18   Scaling   0.265713  0.481200  0.373456       NaN          NaN  \n",
       "19   Scaling   0.307741  0.288359  0.298050       NaN          NaN  \n",
       "20   Scaling   0.208258  0.387939  0.298098       NaN          NaN  \n",
       "21    Scaled        NaN       NaN       NaN  0.001508  6007.356960  \n",
       "22  Baseline        NaN       NaN       NaN  0.001508  6007.356643  \n",
       "23    Scaled        NaN       NaN       NaN  0.003329  2889.234537  \n",
       "24  Baseline        NaN       NaN       NaN  0.003329  2889.234554  \n",
       "25    Scaled        NaN       NaN       NaN  0.002586  7117.469209  \n",
       "26  Baseline        NaN       NaN       NaN  0.003451  7111.294382  \n",
       "27    Scaled        NaN       NaN       NaN  0.002085  6350.934545  \n",
       "28  Baseline        NaN       NaN       NaN  0.002085  6350.931530  \n",
       "29    Scaled        NaN       NaN       NaN  0.001415  2723.883022  \n",
       "30  Baseline        NaN       NaN       NaN  0.001415  2723.882993  \n",
       "31    Scaled        NaN       NaN       NaN  0.002294  7935.651595  \n",
       "32  Baseline        NaN       NaN       NaN  0.002427  7934.597012  \n",
       "33    Scaled        NaN       NaN       NaN  0.002771  4382.175054  \n",
       "34  Baseline        NaN       NaN       NaN  0.002768  4382.188236  \n",
       "35    Scaled        NaN       NaN       NaN -0.000894  7699.487776  \n",
       "36  Baseline        NaN       NaN       NaN -0.001242  7702.166822  \n",
       "37    Scaled        NaN       NaN       NaN  0.005689  2512.836732  \n",
       "38  Baseline        NaN       NaN       NaN  0.005689  2512.836059  \n",
       "39    Scaled        NaN       NaN       NaN  0.002043  4127.691024  \n",
       "40  Baseline        NaN       NaN       NaN  0.002043  4127.694307  \n",
       "41    Scaled        NaN       NaN       NaN  0.004787  3243.101835  \n",
       "42  Baseline        NaN       NaN       NaN  0.004788  3243.098624  \n",
       "43    Scaled        NaN       NaN       NaN  0.007436  1993.850727  \n",
       "44  Baseline        NaN       NaN       NaN  0.007438  1993.847747  \n",
       "45    Scaled        NaN       NaN       NaN  0.003171  3351.785667  \n",
       "46  Baseline        NaN       NaN       NaN  0.003172  3351.785154  \n",
       "47    Scaled        NaN       NaN       NaN  0.004382  3031.940255  \n",
       "48  Baseline        NaN       NaN       NaN  0.004382  3031.940064  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_rows = []\n",
    "#global classification\n",
    "global_df = global_clf_results[\"all_models\"].copy()\n",
    "global_df = global_df.reset_index()\n",
    "for _, row in global_df.iterrows():\n",
    "    summary_rows.append({\n",
    "        \"Level\": \"Global\",\n",
    "        \"Cluster\": \"-\",\n",
    "        \"ClusterExp\": \"-\",  \n",
    "        \"Task\": \"Classification\",\n",
    "        \"Model\": row[\"model\"],\n",
    "        \"Technique\": row[\"technique\"],\n",
    "        \"Precision\": row[\"Precision\"],\n",
    "        \"Recall\": row[\"Recall\"],\n",
    "        \"Score\": row[\"Score\"],\n",
    "        \"R2\": None,\n",
    "        \"MSE\": None\n",
    "    })\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# CLUSTER CLASSIFICATION (MULTIPLE EXPERIMENTS)\n",
    "# ==========================================================\n",
    "for exp_name, cluster_clf_results in all_cluster_clf_results.items():\n",
    "    for clust_id, res in cluster_clf_results.items():\n",
    "\n",
    "        best_row = res[\"all_models\"].sort_values(\"Score\").iloc[-1]\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"Level\": \"Cluster\",\n",
    "            \"Cluster\": clust_id,\n",
    "            \"ClusterExp\": exp_name,     # <--- TRACK EXPERIMENT\n",
    "            \"Task\": \"Classification\",\n",
    "            \"Model\": best_row.name[0],  # model name\n",
    "            \"Technique\": best_row.name[1],\n",
    "            \"Precision\": best_row[\"Precision\"],\n",
    "            \"Recall\": best_row[\"Recall\"],\n",
    "            \"Score\": best_row[\"Score\"],\n",
    "            \"R2\": None,\n",
    "            \"MSE\": None\n",
    "        })\n",
    "\n",
    "# --------------------------\n",
    "# GLOBAL REGRESSION\n",
    "# --------------------------\n",
    "# linear\n",
    "summary_rows.append({\n",
    "    \"Level\": \"Global\",\n",
    "    \"Cluster\": \"-\",\n",
    "    \"Task\": \"Regression\",\n",
    "    \"Model\": \"LinearRegression\",\n",
    "    \"Technique\": \"Baseline\",\n",
    "    \"Precision\": None,\n",
    "    \"Recall\": None,\n",
    "    \"Score\": None,\n",
    "    \"R2\": global_reg_results[\"linear\"][\"r2\"],\n",
    "    \"MSE\": global_reg_results[\"linear\"][\"mse\"]\n",
    "})\n",
    "\n",
    "# lasso\n",
    "summary_rows.append({\n",
    "    \"Level\": \"Global\",\n",
    "    \"Cluster\": \"-\",\n",
    "    \"Task\": \"Regression\",\n",
    "    \"Model\": \"LassoCV\",\n",
    "    \"Technique\": \"Scaled\",\n",
    "    \"Precision\": None,\n",
    "    \"Recall\": None,\n",
    "    \"Score\": None,\n",
    "    \"R2\": global_reg_results[\"lasso\"][\"r2\"],\n",
    "    \"MSE\": global_reg_results[\"lasso\"][\"mse\"]\n",
    "})\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# CLUSTER REGRESSION (MULTIPLE EXPERIMENTS)\n",
    "# ==========================================================\n",
    "for exp_name, cluster_reg_results in all_cluster_reg_results.items():\n",
    "    for clust_id, res in cluster_reg_results.items():\n",
    "\n",
    "        # linear\n",
    "        summary_rows.append({\n",
    "            \"Level\": \"Cluster\",\n",
    "            \"Cluster\": clust_id,\n",
    "            \"ClusterExp\": exp_name, \n",
    "            \"Task\": \"Regression\",\n",
    "            \"Model\": \"LinearRegression\",\n",
    "            \"Technique\": \"Baseline\",\n",
    "            \"Precision\": None,\n",
    "            \"Recall\": None,\n",
    "            \"Score\": None,\n",
    "            \"R2\": res[\"linear\"][\"r2\"],\n",
    "            \"MSE\": res[\"linear\"][\"mse\"]\n",
    "        })\n",
    "\n",
    "        # lasso\n",
    "        summary_rows.append({\n",
    "            \"Level\": \"Cluster\",\n",
    "            \"Cluster\": clust_id,\n",
    "            \"ClusterExp\": exp_name,\n",
    "            \"Task\": \"Regression\",\n",
    "            \"Model\": \"LassoCV\",\n",
    "            \"Technique\": \"Scaled\",\n",
    "            \"Precision\": None,\n",
    "            \"Recall\": None,\n",
    "            \"Score\": None,\n",
    "            \"R2\": res[\"lasso\"][\"r2\"],\n",
    "            \"MSE\": res[\"lasso\"][\"mse\"]\n",
    "        })\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# BUILD FINAL SUMMARY TABLE\n",
    "# --------------------------\n",
    "summary_table = pd.DataFrame(summary_rows)\n",
    "\n",
    "# sorting for readability\n",
    "summary_table = summary_table.sort_values(\n",
    "    by=[\"Task\", \"ClusterExp\", \"Level\", \"Cluster\", \"Model\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "summary_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
