{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ec55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, r2_score, mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    HistGradientBoostingClassifier,\n",
    "    HistGradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier,\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265e9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data_with_clusters.csv\"\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    \"MONTH\",\n",
    "    \"HOUR\",\n",
    "    \"origin_flights_day\",\n",
    "    \"airline_bucket\",\n",
    "    \"origin_bucket\",\n",
    "    \"destination_bucket\",\n",
    "    \"lagged_delay_flag\",\n",
    "    \"prev_real_delay\",\n",
    "]\n",
    "\n",
    "TARGET_CLF = \"DEP_DEL15\" #binary departure delay indicator\n",
    "TARGET_REG = \"DEP_DELAY_NEW\" #continuous departure delay (min)\n",
    "CLUSTER_COL = \"cluster\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# keep only needed columns, drop rows with missing in features/targets\n",
    "df = df.dropna(subset=FEATURE_COLS + [TARGET_CLF, TARGET_REG])\n",
    "\n",
    "X_clf = df[FEATURE_COLS]\n",
    "y_clf = df[TARGET_CLF].astype(int)\n",
    "\n",
    "X_reg = df[FEATURE_COLS]\n",
    "y_reg = df[TARGET_REG].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b93fae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>QUARTER</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>MKT_CARRIER_AIRLINE_ID</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>ORIGIN_AIRPORT_SEQ_ID</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_real_delay</th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>origin_flights_day</th>\n",
       "      <th>origin_bucket</th>\n",
       "      <th>dest_flights_day</th>\n",
       "      <th>destination_bucket</th>\n",
       "      <th>distance_bucket</th>\n",
       "      <th>airline_bucket</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19393</td>\n",
       "      <td>10140</td>\n",
       "      <td>1014005</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>10423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19393</td>\n",
       "      <td>10140</td>\n",
       "      <td>1014005</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>10423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19393</td>\n",
       "      <td>10140</td>\n",
       "      <td>1014005</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>10800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19393</td>\n",
       "      <td>10140</td>\n",
       "      <td>1014005</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>10821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19393</td>\n",
       "      <td>10140</td>\n",
       "      <td>1014005</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>11259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  QUARTER  MONTH  DAY  DAY_OF_WEEK  MKT_CARRIER_AIRLINE_ID  \\\n",
       "0  2024        1      1    1            1                   19393   \n",
       "1  2024        1      1    1            1                   19393   \n",
       "2  2024        1      1    1            1                   19393   \n",
       "3  2024        1      1    1            1                   19393   \n",
       "4  2024        1      1    1            1                   19393   \n",
       "\n",
       "   ORIGIN_AIRPORT_ID  ORIGIN_AIRPORT_SEQ_ID ORIGIN_CITY_NAME  DEST_AIRPORT_ID  \\\n",
       "0              10140                1014005  Albuquerque, NM            10423   \n",
       "1              10140                1014005  Albuquerque, NM            10423   \n",
       "2              10140                1014005  Albuquerque, NM            10800   \n",
       "3              10140                1014005  Albuquerque, NM            10821   \n",
       "4              10140                1014005  Albuquerque, NM            11259   \n",
       "\n",
       "   ...  prev_real_delay     FL_DATE  origin_flights_day  origin_bucket  \\\n",
       "0  ...              0.0  2024-01-01                  67              1   \n",
       "1  ...              0.0  2024-01-01                  67              1   \n",
       "2  ...              0.0  2024-01-01                  67              1   \n",
       "3  ...              0.0  2024-01-01                  67              1   \n",
       "4  ...              0.0  2024-01-01                  67              1   \n",
       "\n",
       "   dest_flights_day  destination_bucket  distance_bucket  airline_bucket  \\\n",
       "0               241                   2                2               1   \n",
       "1               241                   2                2               1   \n",
       "2                90                   1                3               1   \n",
       "3               265                   2                4               1   \n",
       "4               214                   2                2               1   \n",
       "\n",
       "   HOUR  cluster  \n",
       "0     7        0  \n",
       "1    18        0  \n",
       "2    14        1  \n",
       "3    15        0  \n",
       "4     5        0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024353c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_models():\n",
    "    return {\n",
    "        \"LR_L2\": LogisticRegression(\n",
    "            random_state=0, solver=\"liblinear\", max_iter=200\n",
    "        ),\n",
    "        \"LR_L1\": LogisticRegression(\n",
    "            random_state=0,\n",
    "            penalty=\"l1\",\n",
    "            solver=\"liblinear\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=500,\n",
    "        ),\n",
    "        \"CART\": DecisionTreeClassifier(\n",
    "            random_state=0, class_weight=\"balanced\"\n",
    "        ),\n",
    "        \"RF\": RandomForestClassifier(\n",
    "            random_state=0, class_weight=\"balanced\", n_jobs=-1,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "def init_all_models():\n",
    "    model_names = (\"LR_L2\", \"LR_L1\", \"CART\", \"RF\")\n",
    "    techniques = (\"Baseline\", \"Scaling\")  # subset of full Lab 6 list\n",
    "\n",
    "    idx = pd.MultiIndex.from_product(\n",
    "        [model_names, techniques],\n",
    "        names=(\"model\", \"technique\"),\n",
    "    )\n",
    "    all_models = pd.DataFrame(\n",
    "        index=idx,\n",
    "        columns=[\"Precision\", \"Recall\", \"Score\", \"Model\"],\n",
    "    )\n",
    "    all_models[[\"Precision\", \"Recall\", \"Score\"]] = all_models[\n",
    "        [\"Precision\", \"Recall\", \"Score\"]\n",
    "    ].astype(float)\n",
    "    return all_models\n",
    "\n",
    "\n",
    "def standardize_data(X_train, X_out):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    Xtr = pd.DataFrame(\n",
    "        scaler.transform(X_train),\n",
    "        index=X_train.index,\n",
    "        columns=X_train.columns,\n",
    "    )\n",
    "    Xout = pd.DataFrame(\n",
    "        scaler.transform(X_out),\n",
    "        index=X_out.index,\n",
    "        columns=X_out.columns,\n",
    "    )\n",
    "    return Xtr, Xout, scaler\n",
    "\n",
    "\n",
    "def fit_and_score_model(all_models, stage_name,\n",
    "                        X_train, X_out, y_train, y_out):\n",
    "    models_dict = make_models()\n",
    "\n",
    "    for model_name, model in models_dict.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_out)\n",
    "\n",
    "        p = precision_score(y_out, y_pred)\n",
    "        r = recall_score(y_out, y_pred)\n",
    "        s = 0.5 * (p + r)\n",
    "\n",
    "        idx = (model_name, stage_name)\n",
    "        \n",
    "        all_models.at[idx, \"Precision\"] = p\n",
    "        all_models.at[idx, \"Recall\"] = r\n",
    "        all_models.at[idx, \"Score\"] = s\n",
    "        all_models.at[idx, \"Model\"] = model\n",
    "\n",
    "    return all_models\n",
    "\n",
    "\n",
    "def compare_models(all_models, technique_name=\"Scaling\"):\n",
    "    diffs = (\n",
    "        all_models.xs(technique_name, level=\"technique\").Score.values\n",
    "        - all_models.xs(\"Baseline\", level=\"technique\").Score.values\n",
    "    )\n",
    "    print(\n",
    "        f\"{technique_name}: mean ΔScore={diffs.mean():.3f}, \"\n",
    "        f\"max ΔScore={diffs.max():.3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98712080",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_CLF_TRAIN_FRAC = 0.25   # 25% of global clf train\n",
    "CLUSTER_CLF_TRAIN_FRAC = 0.5    # up to 50% of each cluster's train\n",
    "GLOBAL_REG_TRAIN_FRAC = 0.25   # 25% of global reg train\n",
    "CLUSTER_REG_TRAIN_FRAC = 0.5    # 30% of each cluster's reg train\n",
    "LASSO_TRAIN_FRAC = 0.2  # 20% just for LassoCV (more expensive)\n",
    "\n",
    "MIN_SUBSAMPLE_SIZE = 10000    # don't bother subsampling below this\n",
    "\n",
    "def stratified_subsample_xy_frac(X, y, frac=1.0, random_state=0):\n",
    "    \"\"\"\n",
    "    Classification subsample: take a fraction of (X, y), stratified by y.\n",
    "    If frac >= 1.0 or dataset is already small, return (X, y) unchanged.\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    if frac >= 1.0 or n <= MIN_SUBSAMPLE_SIZE:\n",
    "        return X, y\n",
    "\n",
    "    n_sub = int(n * frac)\n",
    "    if n_sub < MIN_SUBSAMPLE_SIZE:\n",
    "        # if frac is tiny on a small dataset, just keep all\n",
    "        return X, y\n",
    "\n",
    "    X_sub, _, y_sub, _ = train_test_split(\n",
    "        X, y,\n",
    "        train_size=n_sub,\n",
    "        stratify=y,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    return X_sub, y_sub\n",
    "\n",
    "\n",
    "def random_subsample_xy_frac(X, y, frac=1.0, random_state=0):\n",
    "    \"\"\"\n",
    "    Regression subsample: take a random fraction of (X, y).\n",
    "    If frac >= 1.0 or dataset is already small, return (X, y) unchanged.\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    if frac >= 1.0 or n <= MIN_SUBSAMPLE_SIZE:\n",
    "        return X, y\n",
    "\n",
    "    n_sub = int(n * frac)\n",
    "    if n_sub < MIN_SUBSAMPLE_SIZE:\n",
    "        return X, y\n",
    "\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    idx = rng.choice(n, size=n_sub, replace=False)\n",
    "\n",
    "    if isinstance(X, (pd.DataFrame, pd.Series)):\n",
    "        return X.iloc[idx], y.iloc[idx]\n",
    "    else:\n",
    "        return X[idx], y[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13d59b8",
   "metadata": {},
   "source": [
    "# Model Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36aba590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling: mean ΔScore=-0.000, max ΔScore=0.000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Score</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>technique</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LR_L2</th>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.383997</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.193734</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scaling</th>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.193214</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LR_L1</th>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.281996</td>\n",
       "      <td>0.608067</td>\n",
       "      <td>0.445032</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scaling</th>\n",
       "      <td>0.282005</td>\n",
       "      <td>0.608064</td>\n",
       "      <td>0.445034</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">CART</th>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.264188</td>\n",
       "      <td>0.390509</td>\n",
       "      <td>0.327349</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scaling</th>\n",
       "      <td>0.264067</td>\n",
       "      <td>0.390331</td>\n",
       "      <td>0.327199</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RF</th>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.283857</td>\n",
       "      <td>0.296324</td>\n",
       "      <td>0.290091</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scaling</th>\n",
       "      <td>0.283797</td>\n",
       "      <td>0.296304</td>\n",
       "      <td>0.290051</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Precision    Recall     Score  \\\n",
       "model technique                                  \n",
       "LR_L2 Baseline    0.383997  0.003472  0.193734   \n",
       "      Scaling     0.382979  0.003448  0.193214   \n",
       "LR_L1 Baseline    0.281996  0.608067  0.445032   \n",
       "      Scaling     0.282005  0.608064  0.445034   \n",
       "CART  Baseline    0.264188  0.390509  0.327349   \n",
       "      Scaling     0.264067  0.390331  0.327199   \n",
       "RF    Baseline    0.283857  0.296324  0.290091   \n",
       "      Scaling     0.283797  0.296304  0.290051   \n",
       "\n",
       "                                                             Model  \n",
       "model technique                                                     \n",
       "LR_L2 Baseline   LogisticRegression(max_iter=200, random_state=...  \n",
       "      Scaling    LogisticRegression(max_iter=200, random_state=...  \n",
       "LR_L1 Baseline   LogisticRegression(class_weight='balanced', ma...  \n",
       "      Scaling    LogisticRegression(class_weight='balanced', ma...  \n",
       "CART  Baseline   DecisionTreeClassifier(class_weight='balanced'...  \n",
       "      Scaling    DecisionTreeClassifier(class_weight='balanced'...  \n",
       "RF    Baseline   (DecisionTreeClassifier(max_features='sqrt', r...  \n",
       "      Scaling    (DecisionTreeClassifier(max_features='sqrt', r...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_global_classification_models(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    "    train_frac=GLOBAL_CLF_TRAIN_FRAC,\n",
    "):\n",
    "    # Full split first\n",
    "    Xtr, Xte, ytr, yte = train_test_split(\n",
    "        X, y,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "    # === SUBSAMPLE TRAINING SET (stratified by y) ===\n",
    "    Xtr_sub, ytr_sub = stratified_subsample_xy_frac(\n",
    "        Xtr, ytr,\n",
    "        frac=train_frac,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    all_models = init_all_models()\n",
    "\n",
    "    # Baseline (unscaled) – train on subsample, test on full test set\n",
    "    all_models = fit_and_score_model(\n",
    "        all_models, \"Baseline\",\n",
    "        Xtr_sub, Xte, ytr_sub, yte\n",
    "    )\n",
    "\n",
    "    # Scaling – fit scaler on subsample, transform full test\n",
    "    Xtr_s, Xte_s, scaler = standardize_data(Xtr_sub, Xte)\n",
    "    all_models = fit_and_score_model(\n",
    "        all_models, \"Scaling\",\n",
    "        Xtr_s, Xte_s, ytr_sub, yte\n",
    "    )\n",
    "\n",
    "    compare_models(all_models, \"Scaling\")\n",
    "\n",
    "    best_row = all_models.sort_values(\"Score\").iloc[-1]\n",
    "    best_model = best_row[\"Model\"]\n",
    "\n",
    "    return {\n",
    "        \"all_models\": all_models,\n",
    "        \"best_model\": best_model,\n",
    "        \"scaler\": scaler,\n",
    "        # store what we *actually used* for training\n",
    "        \"train_split\": (Xtr_sub, Xte, ytr_sub, yte),\n",
    "    }\n",
    "\n",
    "\n",
    "global_clf_results = train_global_classification_models(X_clf, y_clf)\n",
    "global_clf_results[\"all_models\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2811f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_classification_models(\n",
    "    df,\n",
    "    feature_cols,\n",
    "    target_col,\n",
    "    cluster_col=\"cluster\",\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    "    train_frac=CLUSTER_CLF_TRAIN_FRAC,\n",
    "):\n",
    "    cluster_results = {}\n",
    "\n",
    "    for clust_id, df_c in df.groupby(cluster_col):\n",
    "        y_c = df_c[target_col].astype(int)\n",
    "        if y_c.nunique() < 2 or len(df_c) < 40:\n",
    "            continue\n",
    "\n",
    "        X_c = df_c[feature_cols]\n",
    "\n",
    "        Xtr, Xte, ytr, yte = train_test_split(\n",
    "            X_c, y_c,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=y_c,\n",
    "        )\n",
    "\n",
    "        # === SUBSAMPLE TRAINING SET IN THIS CLUSTER ===\n",
    "        Xtr_sub, ytr_sub = stratified_subsample_xy_frac(\n",
    "            Xtr, ytr,\n",
    "            frac=train_frac,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        all_models = init_all_models()\n",
    "\n",
    "        # Baseline\n",
    "        all_models = fit_and_score_model(\n",
    "            all_models, \"Baseline\", Xtr_sub, Xte, ytr_sub, yte\n",
    "        )\n",
    "\n",
    "        # Scaling\n",
    "        Xtr_s, Xte_s, scaler = standardize_data(Xtr_sub, Xte)\n",
    "        all_models = fit_and_score_model(\n",
    "            all_models, \"Scaling\", Xtr_s, Xte_s, ytr_sub, yte\n",
    "        )\n",
    "\n",
    "        best_row = all_models.sort_values(\"Score\").iloc[-1]\n",
    "        best_model = best_row[\"Model\"]\n",
    "\n",
    "        cluster_results[clust_id] = {\n",
    "            \"all_models\": all_models,\n",
    "            \"best_model\": best_model,\n",
    "            \"scaler\": scaler,\n",
    "            \"train_split\": (Xtr_sub, Xte, ytr_sub, yte),\n",
    "        }\n",
    "\n",
    "    return cluster_results\n",
    "\n",
    "\n",
    "cluster_clf_results = train_cluster_classification_models(\n",
    "    df,\n",
    "    FEATURE_COLS,\n",
    "    TARGET_CLF,\n",
    "    cluster_col=CLUSTER_COL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0edccf15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear': {'model': LinearRegression(),\n",
       "  'r2': 0.013018494131079361,\n",
       "  'mse': 3005.6401227349497},\n",
       " 'lasso': {'model': LassoCV(cv=3, n_jobs=-1, random_state=0),\n",
       "  'scaler': StandardScaler(),\n",
       "  'r2': 0.013005703102057287,\n",
       "  'mse': 3005.6790750656787},\n",
       " 'train_split': (         MONTH  HOUR  origin_flights_day  airline_bucket  origin_bucket  \\\n",
       "  656565       2    16                 115               1              1   \n",
       "  5538059      9    13                  82               1              1   \n",
       "  5469672      9     6                 391               0              3   \n",
       "  3576367      6    20                 494               1              3   \n",
       "  95935        1    10                 234               0              2   \n",
       "  ...        ...   ...                 ...             ...            ...   \n",
       "  3111319      6    14                 193               1              2   \n",
       "  4536074      8    12                  24               1              1   \n",
       "  7307663     12    19                 750               1              4   \n",
       "  7136540     12    12                 469               1              3   \n",
       "  4217852      7     7                1036               1              4   \n",
       "  \n",
       "           destination_bucket  lagged_delay_flag  prev_real_delay  \n",
       "  656565                    4                  0             15.0  \n",
       "  5538059                   4                  0              0.0  \n",
       "  5469672                   3                  0              0.0  \n",
       "  3576367                   3                  0              0.0  \n",
       "  95935                     2                  0              0.0  \n",
       "  ...                     ...                ...              ...  \n",
       "  3111319                   2                  0              0.0  \n",
       "  4536074                   4                  0              0.0  \n",
       "  7307663                   1                  0              0.0  \n",
       "  7136540                   3                  0              0.0  \n",
       "  4217852                   4                  0              0.0  \n",
       "  \n",
       "  [1488816 rows x 8 columns],\n",
       "           MONTH  HOUR  origin_flights_day  airline_bucket  origin_bucket  \\\n",
       "  4154393      7     9                 494               1              3   \n",
       "  4902533      8    16                 981               1              4   \n",
       "  649961       2    17                 188               1              2   \n",
       "  489667       1     9                 125               1              2   \n",
       "  6209768     11    14                 886               1              4   \n",
       "  ...        ...   ...                 ...             ...            ...   \n",
       "  2005209      4    21                 344               1              3   \n",
       "  4582310      8    10                  13               0              1   \n",
       "  1673490      3     9                 894               1              4   \n",
       "  3544446      6    10                 350               1              3   \n",
       "  6635196     11    22                1063               1              4   \n",
       "  \n",
       "           destination_bucket  lagged_delay_flag  prev_real_delay  \n",
       "  4154393                   4                  0              0.0  \n",
       "  4902533                   1                  0             83.0  \n",
       "  649961                    3                  0              0.0  \n",
       "  489667                    3                  0              0.0  \n",
       "  6209768                   3                  0              0.0  \n",
       "  ...                     ...                ...              ...  \n",
       "  2005209                   1                  1            104.0  \n",
       "  4582310                   1                  0              0.0  \n",
       "  1673490                   2                  0              0.0  \n",
       "  3544446                   1                  0              0.0  \n",
       "  6635196                   2                  0              0.0  \n",
       "  \n",
       "  [1488816 rows x 8 columns],\n",
       "  656565       0.0\n",
       "  5538059      0.0\n",
       "  5469672      0.0\n",
       "  3576367      0.0\n",
       "  95935        0.0\n",
       "             ...  \n",
       "  3111319    195.0\n",
       "  4536074      0.0\n",
       "  7307663      0.0\n",
       "  7136540      4.0\n",
       "  4217852      0.0\n",
       "  Name: DEP_DELAY_NEW, Length: 1488816, dtype: float64,\n",
       "  4154393      1.0\n",
       "  4902533      0.0\n",
       "  649961       0.0\n",
       "  489667       0.0\n",
       "  6209768      0.0\n",
       "             ...  \n",
       "  2005209      0.0\n",
       "  4582310    255.0\n",
       "  1673490      0.0\n",
       "  3544446      0.0\n",
       "  6635196     17.0\n",
       "  Name: DEP_DELAY_NEW, Length: 1488816, dtype: float64)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_global_regression_models(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    "    train_frac=GLOBAL_REG_TRAIN_FRAC,\n",
    "    lasso_frac=LASSO_TRAIN_FRAC,\n",
    "):\n",
    "    # Full split\n",
    "    Xtr, Xte, ytr, yte = train_test_split(\n",
    "        X, y,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    # === SUBSAMPLE TRAINING FOR LINEAR & LASSO ===\n",
    "    Xtr_sub, ytr_sub = random_subsample_xy_frac(\n",
    "        Xtr, ytr,\n",
    "        frac=train_frac,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    # Plain linear regression (unscaled)\n",
    "    lin = LinearRegression()\n",
    "    lin.fit(Xtr_sub, ytr_sub)\n",
    "    yhat_lin = lin.predict(Xte)\n",
    "    lin_r2 = r2_score(yte, yhat_lin)\n",
    "    lin_mse = mean_squared_error(yte, yhat_lin)\n",
    "\n",
    "    # LassoCV (scaled) – optionally even smaller subsample\n",
    "    Xtr_lasso, ytr_lasso = random_subsample_xy_frac(\n",
    "        Xtr_sub, ytr_sub,\n",
    "        frac=lasso_frac / max(train_frac, 1e-9) if lasso_frac < train_frac else 1.0,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    Xtr_s, Xte_s, scaler = standardize_data(Xtr_lasso, Xte)\n",
    "    lasso = LassoCV(\n",
    "        cv=3,               # lighter than 5-fold\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    lasso.fit(Xtr_s, ytr_lasso)\n",
    "    yhat_lasso = lasso.predict(Xte_s)\n",
    "    lasso_r2 = r2_score(yte, yhat_lasso)\n",
    "    lasso_mse = mean_squared_error(yte, yhat_lasso)\n",
    "\n",
    "    return {\n",
    "        \"linear\": {\n",
    "            \"model\": lin,\n",
    "            \"r2\": lin_r2,\n",
    "            \"mse\": lin_mse,\n",
    "        },\n",
    "        \"lasso\": {\n",
    "            \"model\": lasso,\n",
    "            \"scaler\": scaler,\n",
    "            \"r2\": lasso_r2,\n",
    "            \"mse\": lasso_mse,\n",
    "        },\n",
    "        \"train_split\": (Xtr_sub, Xte, ytr_sub, yte),\n",
    "    }\n",
    "\n",
    "\n",
    "global_reg_results = train_global_regression_models(X_reg, y_reg)\n",
    "global_reg_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3860af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_regression_models(\n",
    "    df,\n",
    "    feature_cols,\n",
    "    target_col,\n",
    "    cluster_col=\"cluster\",\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    "    min_rows=40,\n",
    "    train_frac=CLUSTER_REG_TRAIN_FRAC,\n",
    "    lasso_frac=LASSO_TRAIN_FRAC,\n",
    "):\n",
    "    cluster_reg_results = {}\n",
    "\n",
    "    for clust_id, df_c in df.groupby(cluster_col):\n",
    "        if len(df_c) < min_rows:\n",
    "            continue\n",
    "\n",
    "        X_c = df_c[feature_cols]\n",
    "        y_c = df_c[target_col].astype(float)\n",
    "\n",
    "        Xtr, Xte, ytr, yte = train_test_split(\n",
    "            X_c, y_c,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        # === SUBSAMPLE TRAINING FOR THIS CLUSTER ===\n",
    "        Xtr_sub, ytr_sub = random_subsample_xy_frac(\n",
    "            Xtr, ytr,\n",
    "            frac=train_frac,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        # Linear\n",
    "        lin = LinearRegression()\n",
    "        lin.fit(Xtr_sub, ytr_sub)\n",
    "        yhat_lin = lin.predict(Xte)\n",
    "        lin_r2 = r2_score(yte, yhat_lin)\n",
    "        lin_mse = mean_squared_error(yte, yhat_lin)\n",
    "\n",
    "        # Lasso\n",
    "        Xtr_lasso, ytr_lasso = random_subsample_xy_frac(\n",
    "            Xtr_sub, ytr_sub,\n",
    "            frac=lasso_frac / max(train_frac, 1e-9) if lasso_frac < train_frac else 1.0,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        Xtr_s, Xte_s, scaler = standardize_data(Xtr_lasso, Xte)\n",
    "        lasso = LassoCV(\n",
    "            cv=3,\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        lasso.fit(Xtr_s, ytr_lasso)\n",
    "        yhat_lasso = lasso.predict(Xte_s)\n",
    "        lasso_r2 = r2_score(yte, yhat_lasso)\n",
    "        lasso_mse = mean_squared_error(yte, yhat_lasso)\n",
    "\n",
    "        cluster_reg_results[clust_id] = {\n",
    "            \"linear\": {\n",
    "                \"model\": lin,\n",
    "                \"r2\": lin_r2,\n",
    "                \"mse\": lin_mse,\n",
    "            },\n",
    "            \"lasso\": {\n",
    "                \"model\": lasso,\n",
    "                \"scaler\": scaler,\n",
    "                \"r2\": lasso_r2,\n",
    "                \"mse\": lasso_mse,\n",
    "            },\n",
    "            \"train_split\": (Xtr_sub, Xte, ytr_sub, yte),\n",
    "        }\n",
    "\n",
    "    return cluster_reg_results\n",
    "\n",
    "\n",
    "cluster_reg_results = train_cluster_regression_models(\n",
    "    df,\n",
    "    FEATURE_COLS,\n",
    "    TARGET_REG,\n",
    "    cluster_col=CLUSTER_COL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ed1dc2",
   "metadata": {},
   "source": [
    "## Not on a subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c4352a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling: mean ΔScore=-0.000, max ΔScore=0.000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Score</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>technique</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LR_L2</th>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.383242</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.193359</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scaling</th>\n",
       "      <td>0.382331</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.192888</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LR_L1</th>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.281975</td>\n",
       "      <td>0.608097</td>\n",
       "      <td>0.445036</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scaling</th>\n",
       "      <td>0.281999</td>\n",
       "      <td>0.608103</td>\n",
       "      <td>0.445051</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">CART</th>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.284489</td>\n",
       "      <td>0.453134</td>\n",
       "      <td>0.368811</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scaling</th>\n",
       "      <td>0.284410</td>\n",
       "      <td>0.453041</td>\n",
       "      <td>0.368725</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RF</th>\n",
       "      <th>Baseline</th>\n",
       "      <td>0.300135</td>\n",
       "      <td>0.379523</td>\n",
       "      <td>0.339829</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scaling</th>\n",
       "      <td>0.300093</td>\n",
       "      <td>0.379437</td>\n",
       "      <td>0.339765</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Precision    Recall     Score  \\\n",
       "model technique                                  \n",
       "LR_L2 Baseline    0.383242  0.003475  0.193359   \n",
       "      Scaling     0.382331  0.003445  0.192888   \n",
       "LR_L1 Baseline    0.281975  0.608097  0.445036   \n",
       "      Scaling     0.281999  0.608103  0.445051   \n",
       "CART  Baseline    0.284489  0.453134  0.368811   \n",
       "      Scaling     0.284410  0.453041  0.368725   \n",
       "RF    Baseline    0.300135  0.379523  0.339829   \n",
       "      Scaling     0.300093  0.379437  0.339765   \n",
       "\n",
       "                                                             Model  \n",
       "model technique                                                     \n",
       "LR_L2 Baseline   LogisticRegression(max_iter=200, random_state=...  \n",
       "      Scaling    LogisticRegression(max_iter=200, random_state=...  \n",
       "LR_L1 Baseline   LogisticRegression(class_weight='balanced', ma...  \n",
       "      Scaling    LogisticRegression(class_weight='balanced', ma...  \n",
       "CART  Baseline   DecisionTreeClassifier(class_weight='balanced'...  \n",
       "      Scaling    DecisionTreeClassifier(class_weight='balanced'...  \n",
       "RF    Baseline   (DecisionTreeClassifier(max_features='sqrt', r...  \n",
       "      Scaling    (DecisionTreeClassifier(max_features='sqrt', r...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_global_classification_models(X, y, test_size=0.2, random_state=0):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    all_models = init_all_models()\n",
    "\n",
    "    # Baseline\n",
    "    all_models = fit_and_score_model(\n",
    "        all_models, \"Baseline\", Xtr, Xte, ytr, yte\n",
    "    )\n",
    "\n",
    "    # Scaling\n",
    "    Xtr_s, Xte_s, scaler = standardize_data(Xtr, Xte)\n",
    "    all_models = fit_and_score_model(\n",
    "        all_models, \"Scaling\", Xtr_s, Xte_s, ytr, yte\n",
    "    )\n",
    "\n",
    "    compare_models(all_models, \"Scaling\")\n",
    "\n",
    "    best_row = all_models.sort_values(\"Score\").iloc[-1]\n",
    "    best_model = best_row[\"Model\"]\n",
    "\n",
    "    return {\n",
    "        \"all_models\": all_models,\n",
    "        \"best_model\": best_model,\n",
    "        \"scaler\": scaler,\n",
    "        \"train_split\": (Xtr, Xte, ytr, yte),\n",
    "    }\n",
    "\n",
    "\n",
    "global_clf_results = train_global_classification_models(X_clf, y_clf)\n",
    "global_clf_results[\"all_models\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "608de875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_classification_models(df,\n",
    "                                        feature_cols,\n",
    "                                        target_col,\n",
    "                                        cluster_col=\"cluster\",\n",
    "                                        test_size=0.2,\n",
    "                                        random_state=0):\n",
    "    cluster_results = {}\n",
    "\n",
    "    for clust_id, df_c in df.groupby(cluster_col):\n",
    "        y_c = df_c[target_col].astype(int)\n",
    "        if y_c.nunique() < 2 or len(df_c) < 40:\n",
    "            continue\n",
    "\n",
    "        X_c = df_c[feature_cols]\n",
    "\n",
    "        Xtr, Xte, ytr, yte = train_test_split(\n",
    "            X_c, y_c,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=y_c,\n",
    "        )\n",
    "\n",
    "        all_models = init_all_models()\n",
    "\n",
    "        all_models = fit_and_score_model(\n",
    "            all_models, \"Baseline\", Xtr, Xte, ytr, yte\n",
    "        )\n",
    "\n",
    "        Xtr_s, Xte_s, scaler = standardize_data(Xtr, Xte)\n",
    "        all_models = fit_and_score_model(\n",
    "            all_models, \"Scaling\", Xtr_s, Xte_s, ytr, yte\n",
    "        )\n",
    "\n",
    "        best_row = all_models.sort_values(\"Score\").iloc[-1]\n",
    "        best_model = best_row[\"Model\"]\n",
    "\n",
    "        cluster_results[clust_id] = {\n",
    "            \"all_models\": all_models,\n",
    "            \"best_model\": best_model,\n",
    "            \"scaler\": scaler,\n",
    "        }\n",
    "\n",
    "    return cluster_results\n",
    "\n",
    "\n",
    "cluster_clf_results = train_cluster_classification_models(\n",
    "    df,\n",
    "    FEATURE_COLS,\n",
    "    TARGET_CLF,\n",
    "    cluster_col=CLUSTER_COL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d360e644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear': {'model': LinearRegression(),\n",
       "  'r2': 0.013037203925674645,\n",
       "  'mse': 3005.583146075319},\n",
       " 'lasso': {'model': LassoCV(cv=5, random_state=0),\n",
       "  'scaler': StandardScaler(),\n",
       "  'r2': 0.0130350140483948,\n",
       "  'mse': 3005.589814876078},\n",
       " 'train_split': (         MONTH  HOUR  origin_flights_day  airline_bucket  origin_bucket  \\\n",
       "  2840684      5    14                 298               1              2   \n",
       "  2506158      5    12                 309               1              2   \n",
       "  1795334      4     8                 550               1              4   \n",
       "  930487       2    14                 418               1              3   \n",
       "  749653       2    21                 815               1              4   \n",
       "  ...        ...   ...                 ...             ...            ...   \n",
       "  2249467      4     7                  79               1              1   \n",
       "  5157699      9    16                 164               1              2   \n",
       "  2215104      4    14                 835               1              4   \n",
       "  1484405      3    22                 433               1              3   \n",
       "  4500015      8    14                 403               1              3   \n",
       "  \n",
       "           destination_bucket  lagged_delay_flag  prev_real_delay  \n",
       "  2840684                   3                  0              0.0  \n",
       "  2506158                   4                  0           1482.0  \n",
       "  1795334                   2                  0              0.0  \n",
       "  930487                    1                  0             24.0  \n",
       "  749653                    1                  0              0.0  \n",
       "  ...                     ...                ...              ...  \n",
       "  2249467                   2                  0              0.0  \n",
       "  5157699                   4                  0              0.0  \n",
       "  2215104                   2                  1             36.0  \n",
       "  1484405                   1                  0              0.0  \n",
       "  4500015                   1                  0             27.0  \n",
       "  \n",
       "  [5955264 rows x 8 columns],\n",
       "           MONTH  HOUR  origin_flights_day  airline_bucket  origin_bucket  \\\n",
       "  4154393      7     9                 494               1              3   \n",
       "  4902533      8    16                 981               1              4   \n",
       "  649961       2    17                 188               1              2   \n",
       "  489667       1     9                 125               1              2   \n",
       "  6209768     11    14                 886               1              4   \n",
       "  ...        ...   ...                 ...             ...            ...   \n",
       "  2005209      4    21                 344               1              3   \n",
       "  4582310      8    10                  13               0              1   \n",
       "  1673490      3     9                 894               1              4   \n",
       "  3544446      6    10                 350               1              3   \n",
       "  6635196     11    22                1063               1              4   \n",
       "  \n",
       "           destination_bucket  lagged_delay_flag  prev_real_delay  \n",
       "  4154393                   4                  0              0.0  \n",
       "  4902533                   1                  0             83.0  \n",
       "  649961                    3                  0              0.0  \n",
       "  489667                    3                  0              0.0  \n",
       "  6209768                   3                  0              0.0  \n",
       "  ...                     ...                ...              ...  \n",
       "  2005209                   1                  1            104.0  \n",
       "  4582310                   1                  0              0.0  \n",
       "  1673490                   2                  0              0.0  \n",
       "  3544446                   1                  0              0.0  \n",
       "  6635196                   2                  0              0.0  \n",
       "  \n",
       "  [1488816 rows x 8 columns],\n",
       "  2840684     0.0\n",
       "  2506158     0.0\n",
       "  1795334    60.0\n",
       "  930487      0.0\n",
       "  749653      0.0\n",
       "             ... \n",
       "  2249467     0.0\n",
       "  5157699     0.0\n",
       "  2215104     0.0\n",
       "  1484405     0.0\n",
       "  4500015     0.0\n",
       "  Name: DEP_DELAY_NEW, Length: 5955264, dtype: float64,\n",
       "  4154393      1.0\n",
       "  4902533      0.0\n",
       "  649961       0.0\n",
       "  489667       0.0\n",
       "  6209768      0.0\n",
       "             ...  \n",
       "  2005209      0.0\n",
       "  4582310    255.0\n",
       "  1673490      0.0\n",
       "  3544446      0.0\n",
       "  6635196     17.0\n",
       "  Name: DEP_DELAY_NEW, Length: 1488816, dtype: float64)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_global_regression_models(X, y, test_size=0.2, random_state=0):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Plain linear regression (unscaled)\n",
    "    lin = LinearRegression()\n",
    "    lin.fit(Xtr, ytr)\n",
    "    yhat_lin = lin.predict(Xte)\n",
    "    lin_r2 = r2_score(yte, yhat_lin)\n",
    "    lin_mse = mean_squared_error(yte, yhat_lin)\n",
    "\n",
    "    # LassoCV (scaled)\n",
    "    Xtr_s, Xte_s, scaler = standardize_data(Xtr, Xte)\n",
    "    lasso = LassoCV(cv=5, random_state=random_state)\n",
    "    lasso.fit(Xtr_s, ytr)\n",
    "    yhat_lasso = lasso.predict(Xte_s)\n",
    "    lasso_r2 = r2_score(yte, yhat_lasso)\n",
    "    lasso_mse = mean_squared_error(yte, yhat_lasso)\n",
    "\n",
    "    return {\n",
    "        \"linear\": {\n",
    "            \"model\": lin,\n",
    "            \"r2\": lin_r2,\n",
    "            \"mse\": lin_mse,\n",
    "        },\n",
    "        \"lasso\": {\n",
    "            \"model\": lasso,\n",
    "            \"scaler\": scaler,\n",
    "            \"r2\": lasso_r2,\n",
    "            \"mse\": lasso_mse,\n",
    "        },\n",
    "        \"train_split\": (Xtr, Xte, ytr, yte),\n",
    "    }\n",
    "\n",
    "\n",
    "global_reg_results = train_global_regression_models(X_reg, y_reg)\n",
    "global_reg_results_df = pd.DataFrame(global_reg_results)\n",
    "global_reg_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94215599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ModelName</th>\n",
       "      <th>Estimator</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>3005.583146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lasso</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.013035</td>\n",
       "      <td>3005.589815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ModelName         Estimator        R2          MSE\n",
       "0    linear  LinearRegression  0.013037  3005.583146\n",
       "1     lasso           LassoCV  0.013035  3005.589815"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rows = []\n",
    "\n",
    "for name, res in global_reg_results.items():\n",
    "    if name == \"train_split\":\n",
    "        continue  # skip raw data here\n",
    "\n",
    "    rows.append({\n",
    "        \"ModelName\": name,\n",
    "        \"Estimator\": type(res[\"model\"]).__name__,\n",
    "        \"R2\": res[\"r2\"],\n",
    "        \"MSE\": res[\"mse\"],\n",
    "    })\n",
    "\n",
    "global_reg_metrics_df = pd.DataFrame(rows)\n",
    "global_reg_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a2f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_regression_models(df,\n",
    "                                    feature_cols,\n",
    "                                    target_col,\n",
    "                                    cluster_col=\"cluster\",\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=0,\n",
    "                                    min_rows=40):\n",
    "    cluster_reg_results = {}\n",
    "\n",
    "    for clust_id, df_c in df.groupby(cluster_col):\n",
    "        if len(df_c) < min_rows:\n",
    "            continue\n",
    "\n",
    "        X_c = df_c[feature_cols]\n",
    "        y_c = df_c[target_col].astype(float)\n",
    "\n",
    "        Xtr, Xte, ytr, yte = train_test_split(\n",
    "            X_c, y_c,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        # linear\n",
    "        lin = LinearRegression()\n",
    "        lin.fit(Xtr, ytr)\n",
    "        yhat_lin = lin.predict(Xte)\n",
    "        lin_r2 = r2_score(yte, yhat_lin)\n",
    "        lin_mse = mean_squared_error(yte, yhat_lin)\n",
    "\n",
    "        # lasso (scaled)\n",
    "        Xtr_s, Xte_s, scaler = standardize_data(Xtr, Xte)\n",
    "        lasso = LassoCV(cv=5, random_state=random_state)\n",
    "        lasso.fit(Xtr_s, ytr)\n",
    "        yhat_lasso = lasso.predict(Xte_s)\n",
    "        lasso_r2 = r2_score(yte, yhat_lasso)\n",
    "        lasso_mse = mean_squared_error(yte, yhat_lasso)\n",
    "\n",
    "        cluster_reg_results[clust_id] = {\n",
    "            \"linear\": {\n",
    "                \"model\": lin,\n",
    "                \"r2\": lin_r2,\n",
    "                \"mse\": lin_mse,\n",
    "            },\n",
    "            \"lasso\": {\n",
    "                \"model\": lasso,\n",
    "                \"scaler\": scaler,\n",
    "                \"r2\": lasso_r2,\n",
    "                \"mse\": lasso_mse,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    return cluster_reg_results\n",
    "\n",
    "\n",
    "cluster_reg_results = train_cluster_regression_models(\n",
    "    df,\n",
    "    FEATURE_COLS,\n",
    "    TARGET_REG,\n",
    "    cluster_col=CLUSTER_COL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1bc1a7",
   "metadata": {},
   "source": [
    "# Cluster Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf2a49af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_clusters(df, k, cluster_features, cluster_col_name):\n",
    "    X_cluster = df[cluster_features].copy()\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    labels = kmeans.fit_predict(X_cluster)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[cluster_col_name] = labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ead0d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_EXPERIMENTS = [\n",
    "    {\n",
    "        \"name\": \"k3_all_feats\",\n",
    "        \"k\": 3,\n",
    "        \"cluster_features\": FEATURE_COLS,      # use all current features\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"k4_all_feats\",\n",
    "        \"k\": 4,\n",
    "        \"cluster_features\": FEATURE_COLS,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"k5_all_feats\",\n",
    "        \"k\": 5,\n",
    "        \"cluster_features\": FEATURE_COLS,\n",
    "    },\n",
    "    # add more as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49f5aca1",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "could not allocate 8388608 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\elena\\anaconda3\\Lib\\site-packages\\joblib\\_utils.py\", line 72, in __call__\n    return self.func(**kwargs)\n           ~~~~~~~~~^^^^^^^^^^\n  File \"c:\\Users\\elena\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\elena\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\elena\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 189, in _parallel_build_trees\n    tree._fit(\n    ~~~~~~~~~^\n        X,\n        ^^\n    ...<3 lines>...\n        missing_values_in_feature_mask=missing_values_in_feature_mask,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\elena\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"_tree.pyx\", line 153, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n  File \"_tree.pyx\", line 268, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n  File \"_tree.pyx\", line 923, in sklearn.tree._tree.Tree._add_node\n  File \"_tree.pyx\", line 891, in sklearn.tree._tree.Tree._resize_c\n  File \"_utils.pyx\", line 29, in sklearn.tree._utils.safe_realloc\nMemoryError: could not allocate 8388608 bytes\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m df_with_clusters \u001b[38;5;241m=\u001b[39m assign_clusters(df, k, cluster_features, cluster_col)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 2) train cluster-specific classification models\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m cluster_clf_results \u001b[38;5;241m=\u001b[39m train_cluster_classification_models(\n\u001b[0;32m     15\u001b[0m     df_with_clusters,\n\u001b[0;32m     16\u001b[0m     FEATURE_COLS,       \u001b[38;5;66;03m# you can choose to change this too, if needed\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     TARGET_CLF,\n\u001b[0;32m     18\u001b[0m     cluster_col\u001b[38;5;241m=\u001b[39mcluster_col,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 3) train cluster-specific regression models\u001b[39;00m\n\u001b[0;32m     22\u001b[0m cluster_reg_results \u001b[38;5;241m=\u001b[39m train_cluster_regression_models(\n\u001b[0;32m     23\u001b[0m     df_with_clusters,\n\u001b[0;32m     24\u001b[0m     FEATURE_COLS,\n\u001b[0;32m     25\u001b[0m     TARGET_REG,\n\u001b[0;32m     26\u001b[0m     cluster_col\u001b[38;5;241m=\u001b[39mcluster_col,\n\u001b[0;32m     27\u001b[0m )\n",
      "Cell \u001b[1;32mIn[6], line 30\u001b[0m, in \u001b[0;36mtrain_cluster_classification_models\u001b[1;34m(df, feature_cols, target_col, cluster_col, test_size, random_state)\u001b[0m\n\u001b[0;32m     25\u001b[0m all_models \u001b[38;5;241m=\u001b[39m fit_and_score_model(\n\u001b[0;32m     26\u001b[0m     all_models, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline\u001b[39m\u001b[38;5;124m\"\u001b[39m, Xtr, Xte, ytr, yte\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     29\u001b[0m Xtr_s, Xte_s, scaler \u001b[38;5;241m=\u001b[39m standardize_data(Xtr, Xte)\n\u001b[1;32m---> 30\u001b[0m all_models \u001b[38;5;241m=\u001b[39m fit_and_score_model(\n\u001b[0;32m     31\u001b[0m     all_models, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScaling\u001b[39m\u001b[38;5;124m\"\u001b[39m, Xtr_s, Xte_s, ytr, yte\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     34\u001b[0m best_row \u001b[38;5;241m=\u001b[39m all_models\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     35\u001b[0m best_model \u001b[38;5;241m=\u001b[39m best_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[1;32mIn[4], line 62\u001b[0m, in \u001b[0;36mfit_and_score_model\u001b[1;34m(all_models, stage_name, X_train, X_out, y_train, y_out)\u001b[0m\n\u001b[0;32m     59\u001b[0m models_dict \u001b[38;5;241m=\u001b[39m make_models()\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 62\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     63\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_out)\n\u001b[0;32m     65\u001b[0m     p \u001b[38;5;241m=\u001b[39m precision_score(y_out, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\elena\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\elena\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    479\u001b[0m ]\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    488\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    489\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    490\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    491\u001b[0m )(\n\u001b[0;32m    492\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    493\u001b[0m         t,\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    495\u001b[0m         X,\n\u001b[0;32m    496\u001b[0m         y,\n\u001b[0;32m    497\u001b[0m         sample_weight,\n\u001b[0;32m    498\u001b[0m         i,\n\u001b[0;32m    499\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    500\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    501\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    502\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    503\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    504\u001b[0m     )\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    506\u001b[0m )\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\elena\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\elena\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\elena\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elena\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_error_fast()\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elena\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     error_job\u001b[38;5;241m.\u001b[39mget_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\elena\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_or_raise()\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\elena\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: could not allocate 8388608 bytes"
     ]
    }
   ],
   "source": [
    "all_cluster_clf_results = {}\n",
    "all_cluster_reg_results = {}\n",
    "\n",
    "for cfg in CLUSTER_EXPERIMENTS:\n",
    "    exp_name = cfg[\"name\"]\n",
    "    k = cfg[\"k\"]\n",
    "    cluster_features = cfg[\"cluster_features\"]\n",
    "\n",
    "    # 1) assign cluster labels for this experiment\n",
    "    cluster_col = f\"cluster_{exp_name}\"\n",
    "    df_with_clusters = assign_clusters(df, k, cluster_features, cluster_col)\n",
    "\n",
    "    # 2) train cluster-specific classification models\n",
    "    cluster_clf_results = train_cluster_classification_models(\n",
    "        df_with_clusters,\n",
    "        FEATURE_COLS,       # you can choose to change this too, if needed\n",
    "        TARGET_CLF,\n",
    "        cluster_col=cluster_col,\n",
    "    )\n",
    "\n",
    "    # 3) train cluster-specific regression models\n",
    "    cluster_reg_results = train_cluster_regression_models(\n",
    "        df_with_clusters,\n",
    "        FEATURE_COLS,\n",
    "        TARGET_REG,\n",
    "        cluster_col=cluster_col,\n",
    "    )\n",
    "\n",
    "    # 4) store results keyed by experiment name\n",
    "    all_cluster_clf_results[exp_name] = cluster_clf_results\n",
    "    all_cluster_reg_results[exp_name] = cluster_reg_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea8ff41",
   "metadata": {},
   "source": [
    "# Gathering Summary Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35dd3e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>ClusterExp</th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Score</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.284489</td>\n",
       "      <td>0.453134</td>\n",
       "      <td>0.368811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.284410</td>\n",
       "      <td>0.453041</td>\n",
       "      <td>0.368725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.281975</td>\n",
       "      <td>0.608097</td>\n",
       "      <td>0.445036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.281999</td>\n",
       "      <td>0.608103</td>\n",
       "      <td>0.445051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L2</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.383242</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.193359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L2</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.382331</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.192888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>RF</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.300135</td>\n",
       "      <td>0.379523</td>\n",
       "      <td>0.339829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>RF</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.300093</td>\n",
       "      <td>0.379437</td>\n",
       "      <td>0.339765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.343519</td>\n",
       "      <td>0.350662</td>\n",
       "      <td>0.347090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.340782</td>\n",
       "      <td>0.345936</td>\n",
       "      <td>0.343359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.375139</td>\n",
       "      <td>0.638941</td>\n",
       "      <td>0.507040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.375069</td>\n",
       "      <td>0.639887</td>\n",
       "      <td>0.507478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L2</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>0.282504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L2</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.012287</td>\n",
       "      <td>0.246884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>RF</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.197543</td>\n",
       "      <td>0.327938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>RF</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.457516</td>\n",
       "      <td>0.198488</td>\n",
       "      <td>0.328002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.245507</td>\n",
       "      <td>0.451862</td>\n",
       "      <td>0.348684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.245642</td>\n",
       "      <td>0.451940</td>\n",
       "      <td>0.348791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.258501</td>\n",
       "      <td>0.617526</td>\n",
       "      <td>0.438013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.258501</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L2</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.200169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L2</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.398323</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.200809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>RF</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.259842</td>\n",
       "      <td>0.358761</td>\n",
       "      <td>0.309302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>RF</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.259801</td>\n",
       "      <td>0.358726</td>\n",
       "      <td>0.309264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.339107</td>\n",
       "      <td>0.483429</td>\n",
       "      <td>0.411268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.339166</td>\n",
       "      <td>0.483752</td>\n",
       "      <td>0.411459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.315076</td>\n",
       "      <td>0.599538</td>\n",
       "      <td>0.457307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.599509</td>\n",
       "      <td>0.457289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L2</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.467897</td>\n",
       "      <td>0.017887</td>\n",
       "      <td>0.242892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L2</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.463142</td>\n",
       "      <td>0.018284</td>\n",
       "      <td>0.240713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>RF</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.359405</td>\n",
       "      <td>0.421082</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>RF</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.359308</td>\n",
       "      <td>0.420994</td>\n",
       "      <td>0.390151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.288446</td>\n",
       "      <td>0.460335</td>\n",
       "      <td>0.374390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.288379</td>\n",
       "      <td>0.460276</td>\n",
       "      <td>0.374327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.290277</td>\n",
       "      <td>0.602384</td>\n",
       "      <td>0.446331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.290280</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.446345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L2</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.451242</td>\n",
       "      <td>0.008289</td>\n",
       "      <td>0.229765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L2</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.450730</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>0.229539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>RF</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.307856</td>\n",
       "      <td>0.372724</td>\n",
       "      <td>0.340290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>RF</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.307683</td>\n",
       "      <td>0.372639</td>\n",
       "      <td>0.340161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013035</td>\n",
       "      <td>3005.589815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>3005.583146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>2711.155146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>2711.153088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009478</td>\n",
       "      <td>3314.705020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>3314.701071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019805</td>\n",
       "      <td>2744.160294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019805</td>\n",
       "      <td>2744.160357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k4_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>8861.730418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k4_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011584</td>\n",
       "      <td>8860.856146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k4_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>3333.568840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k4_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>3333.568302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k4_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021752</td>\n",
       "      <td>2802.032751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k4_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021751</td>\n",
       "      <td>2802.036328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k4_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016496</td>\n",
       "      <td>2652.712012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k4_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016496</td>\n",
       "      <td>2652.713122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Level Cluster    ClusterExp            Task             Model Technique  \\\n",
       "0    Global       -             -  Classification              CART  Baseline   \n",
       "1    Global       -             -  Classification              CART   Scaling   \n",
       "2    Global       -             -  Classification             LR_L1  Baseline   \n",
       "3    Global       -             -  Classification             LR_L1   Scaling   \n",
       "4    Global       -             -  Classification             LR_L2  Baseline   \n",
       "5    Global       -             -  Classification             LR_L2   Scaling   \n",
       "6    Global       -             -  Classification                RF  Baseline   \n",
       "7    Global       -             -  Classification                RF   Scaling   \n",
       "8   Cluster       0  k5_all_feats  Classification              CART  Baseline   \n",
       "9   Cluster       0  k5_all_feats  Classification              CART   Scaling   \n",
       "10  Cluster       0  k5_all_feats  Classification             LR_L1  Baseline   \n",
       "11  Cluster       0  k5_all_feats  Classification             LR_L1   Scaling   \n",
       "12  Cluster       0  k5_all_feats  Classification             LR_L2  Baseline   \n",
       "13  Cluster       0  k5_all_feats  Classification             LR_L2   Scaling   \n",
       "14  Cluster       0  k5_all_feats  Classification                RF  Baseline   \n",
       "15  Cluster       0  k5_all_feats  Classification                RF   Scaling   \n",
       "16  Cluster       1  k5_all_feats  Classification              CART  Baseline   \n",
       "17  Cluster       1  k5_all_feats  Classification              CART   Scaling   \n",
       "18  Cluster       1  k5_all_feats  Classification             LR_L1  Baseline   \n",
       "19  Cluster       1  k5_all_feats  Classification             LR_L1   Scaling   \n",
       "20  Cluster       1  k5_all_feats  Classification             LR_L2  Baseline   \n",
       "21  Cluster       1  k5_all_feats  Classification             LR_L2   Scaling   \n",
       "22  Cluster       1  k5_all_feats  Classification                RF  Baseline   \n",
       "23  Cluster       1  k5_all_feats  Classification                RF   Scaling   \n",
       "24  Cluster       2  k5_all_feats  Classification              CART  Baseline   \n",
       "25  Cluster       2  k5_all_feats  Classification              CART   Scaling   \n",
       "26  Cluster       2  k5_all_feats  Classification             LR_L1  Baseline   \n",
       "27  Cluster       2  k5_all_feats  Classification             LR_L1   Scaling   \n",
       "28  Cluster       2  k5_all_feats  Classification             LR_L2  Baseline   \n",
       "29  Cluster       2  k5_all_feats  Classification             LR_L2   Scaling   \n",
       "30  Cluster       2  k5_all_feats  Classification                RF  Baseline   \n",
       "31  Cluster       2  k5_all_feats  Classification                RF   Scaling   \n",
       "32  Cluster       3  k5_all_feats  Classification              CART  Baseline   \n",
       "33  Cluster       3  k5_all_feats  Classification              CART   Scaling   \n",
       "34  Cluster       3  k5_all_feats  Classification             LR_L1  Baseline   \n",
       "35  Cluster       3  k5_all_feats  Classification             LR_L1   Scaling   \n",
       "36  Cluster       3  k5_all_feats  Classification             LR_L2  Baseline   \n",
       "37  Cluster       3  k5_all_feats  Classification             LR_L2   Scaling   \n",
       "38  Cluster       3  k5_all_feats  Classification                RF  Baseline   \n",
       "39  Cluster       3  k5_all_feats  Classification                RF   Scaling   \n",
       "40   Global       -             -      Regression           LassoCV    Scaled   \n",
       "41   Global       -             -      Regression  LinearRegression  Baseline   \n",
       "42  Cluster       0  k3_all_feats      Regression           LassoCV    Scaled   \n",
       "43  Cluster       0  k3_all_feats      Regression  LinearRegression  Baseline   \n",
       "44  Cluster       1  k3_all_feats      Regression           LassoCV    Scaled   \n",
       "45  Cluster       1  k3_all_feats      Regression  LinearRegression  Baseline   \n",
       "46  Cluster       2  k3_all_feats      Regression           LassoCV    Scaled   \n",
       "47  Cluster       2  k3_all_feats      Regression  LinearRegression  Baseline   \n",
       "48  Cluster       0  k4_all_feats      Regression           LassoCV    Scaled   \n",
       "49  Cluster       0  k4_all_feats      Regression  LinearRegression  Baseline   \n",
       "50  Cluster       1  k4_all_feats      Regression           LassoCV    Scaled   \n",
       "51  Cluster       1  k4_all_feats      Regression  LinearRegression  Baseline   \n",
       "52  Cluster       2  k4_all_feats      Regression           LassoCV    Scaled   \n",
       "53  Cluster       2  k4_all_feats      Regression  LinearRegression  Baseline   \n",
       "54  Cluster       3  k4_all_feats      Regression           LassoCV    Scaled   \n",
       "55  Cluster       3  k4_all_feats      Regression  LinearRegression  Baseline   \n",
       "\n",
       "    Precision    Recall     Score        R2          MSE  \n",
       "0    0.284489  0.453134  0.368811       NaN          NaN  \n",
       "1    0.284410  0.453041  0.368725       NaN          NaN  \n",
       "2    0.281975  0.608097  0.445036       NaN          NaN  \n",
       "3    0.281999  0.608103  0.445051       NaN          NaN  \n",
       "4    0.383242  0.003475  0.193359       NaN          NaN  \n",
       "5    0.382331  0.003445  0.192888       NaN          NaN  \n",
       "6    0.300135  0.379523  0.339829       NaN          NaN  \n",
       "7    0.300093  0.379437  0.339765       NaN          NaN  \n",
       "8    0.343519  0.350662  0.347090       NaN          NaN  \n",
       "9    0.340782  0.345936  0.343359       NaN          NaN  \n",
       "10   0.375139  0.638941  0.507040       NaN          NaN  \n",
       "11   0.375069  0.639887  0.507478       NaN          NaN  \n",
       "12   0.555556  0.009452  0.282504       NaN          NaN  \n",
       "13   0.481481  0.012287  0.246884       NaN          NaN  \n",
       "14   0.458333  0.197543  0.327938       NaN          NaN  \n",
       "15   0.457516  0.198488  0.328002       NaN          NaN  \n",
       "16   0.245507  0.451862  0.348684       NaN          NaN  \n",
       "17   0.245642  0.451940  0.348791       NaN          NaN  \n",
       "18   0.258501  0.617526  0.438013       NaN          NaN  \n",
       "19   0.258501  0.617500  0.438000       NaN          NaN  \n",
       "20   0.397059  0.003279  0.200169       NaN          NaN  \n",
       "21   0.398323  0.003296  0.200809       NaN          NaN  \n",
       "22   0.259842  0.358761  0.309302       NaN          NaN  \n",
       "23   0.259801  0.358726  0.309264       NaN          NaN  \n",
       "24   0.339107  0.483429  0.411268       NaN          NaN  \n",
       "25   0.339166  0.483752  0.411459       NaN          NaN  \n",
       "26   0.315076  0.599538  0.457307       NaN          NaN  \n",
       "27   0.315068  0.599509  0.457289       NaN          NaN  \n",
       "28   0.467897  0.017887  0.242892       NaN          NaN  \n",
       "29   0.463142  0.018284  0.240713       NaN          NaN  \n",
       "30   0.359405  0.421082  0.390244       NaN          NaN  \n",
       "31   0.359308  0.420994  0.390151       NaN          NaN  \n",
       "32   0.288446  0.460335  0.374390       NaN          NaN  \n",
       "33   0.288379  0.460276  0.374327       NaN          NaN  \n",
       "34   0.290277  0.602384  0.446331       NaN          NaN  \n",
       "35   0.290280  0.602410  0.446345       NaN          NaN  \n",
       "36   0.451242  0.008289  0.229765       NaN          NaN  \n",
       "37   0.450730  0.008348  0.229539       NaN          NaN  \n",
       "38   0.307856  0.372724  0.340290       NaN          NaN  \n",
       "39   0.307683  0.372639  0.340161       NaN          NaN  \n",
       "40        NaN       NaN       NaN  0.013035  3005.589815  \n",
       "41        NaN       NaN       NaN  0.013037  3005.583146  \n",
       "42        NaN       NaN       NaN  0.013888  2711.155146  \n",
       "43        NaN       NaN       NaN  0.013889  2711.153088  \n",
       "44        NaN       NaN       NaN  0.009478  3314.705020  \n",
       "45        NaN       NaN       NaN  0.009479  3314.701071  \n",
       "46        NaN       NaN       NaN  0.019805  2744.160294  \n",
       "47        NaN       NaN       NaN  0.019805  2744.160357  \n",
       "48        NaN       NaN       NaN  0.011486  8861.730418  \n",
       "49        NaN       NaN       NaN  0.011584  8860.856146  \n",
       "50        NaN       NaN       NaN  0.009960  3333.568840  \n",
       "51        NaN       NaN       NaN  0.009960  3333.568302  \n",
       "52        NaN       NaN       NaN  0.021752  2802.032751  \n",
       "53        NaN       NaN       NaN  0.021751  2802.036328  \n",
       "54        NaN       NaN       NaN  0.016496  2652.712012  \n",
       "55        NaN       NaN       NaN  0.016496  2652.713122  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_rows = []\n",
    "#global classification\n",
    "global_df = global_clf_results[\"all_models\"].copy()\n",
    "global_df = global_df.reset_index()\n",
    "for _, row in global_df.iterrows():\n",
    "    summary_rows.append({\n",
    "        \"Level\": \"Global\",\n",
    "        \"Cluster\": \"-\",\n",
    "        \"ClusterExp\": \"-\",  \n",
    "        \"Task\": \"Classification\",\n",
    "        \"Model\": row[\"model\"],\n",
    "        \"Technique\": row[\"technique\"],\n",
    "        \"Precision\": row[\"Precision\"],\n",
    "        \"Recall\": row[\"Recall\"],\n",
    "        \"Score\": row[\"Score\"],\n",
    "        \"R2\": None,\n",
    "        \"MSE\": None\n",
    "    })\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# CLUSTER CLASSIFICATION (MULTIPLE EXPERIMENTS)\n",
    "# ==========================================================\n",
    "for clust_id, res in cluster_clf_results.items():\n",
    "    df_m = res[\"all_models\"].reset_index()  # bring model, technique out of index\n",
    "\n",
    "    for _, row in df_m.iterrows():\n",
    "        summary_rows.append({\n",
    "            \"Level\": \"Cluster\",\n",
    "            \"Cluster\": clust_id,\n",
    "            \"ClusterExp\": exp_name,\n",
    "            \"Task\": \"Classification\",\n",
    "            \"Model\": row[\"model\"],          # now from columns\n",
    "            \"Technique\": row[\"technique\"],  # Baseline / Scaling\n",
    "            \"Precision\": row[\"Precision\"],\n",
    "            \"Recall\": row[\"Recall\"],\n",
    "            \"Score\": row[\"Score\"],\n",
    "            \"R2\": None,\n",
    "            \"MSE\": None,\n",
    "        })\n",
    "\n",
    "# --------------------------\n",
    "# GLOBAL REGRESSION\n",
    "# --------------------------\n",
    "# linear\n",
    "summary_rows.append({\n",
    "    \"Level\": \"Global\",\n",
    "    \"Cluster\": \"-\",\n",
    "    \"ClusterExp\": \"-\",\n",
    "    \"Task\": \"Regression\",\n",
    "    \"Model\": \"LinearRegression\",\n",
    "    \"Technique\": \"Baseline\",\n",
    "    \"Precision\": None,\n",
    "    \"Recall\": None,\n",
    "    \"Score\": None,\n",
    "    \"R2\": global_reg_results[\"linear\"][\"r2\"],\n",
    "    \"MSE\": global_reg_results[\"linear\"][\"mse\"]\n",
    "})\n",
    "\n",
    "# lasso\n",
    "summary_rows.append({\n",
    "    \"Level\": \"Global\",\n",
    "    \"Cluster\": \"-\",\n",
    "    \"ClusterExp\": \"-\",\n",
    "    \"Task\": \"Regression\",\n",
    "    \"Model\": \"LassoCV\",\n",
    "    \"Technique\": \"Scaled\",\n",
    "    \"Precision\": None,\n",
    "    \"Recall\": None,\n",
    "    \"Score\": None,\n",
    "    \"R2\": global_reg_results[\"lasso\"][\"r2\"],\n",
    "    \"MSE\": global_reg_results[\"lasso\"][\"mse\"]\n",
    "})\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# CLUSTER REGRESSION (MULTIPLE EXPERIMENTS)\n",
    "# ==========================================================\n",
    "for exp_name, cluster_reg_results in all_cluster_reg_results.items():\n",
    "    for clust_id, res in cluster_reg_results.items():\n",
    "\n",
    "        # linear\n",
    "        summary_rows.append({\n",
    "            \"Level\": \"Cluster\",\n",
    "            \"Cluster\": clust_id,\n",
    "            \"ClusterExp\": exp_name, \n",
    "            \"Task\": \"Regression\",\n",
    "            \"Model\": \"LinearRegression\",\n",
    "            \"Technique\": \"Baseline\",\n",
    "            \"Precision\": None,\n",
    "            \"Recall\": None,\n",
    "            \"Score\": None,\n",
    "            \"R2\": res[\"linear\"][\"r2\"],\n",
    "            \"MSE\": res[\"linear\"][\"mse\"]\n",
    "        })\n",
    "\n",
    "        # lasso\n",
    "        summary_rows.append({\n",
    "            \"Level\": \"Cluster\",\n",
    "            \"Cluster\": clust_id,\n",
    "            \"ClusterExp\": exp_name,\n",
    "            \"Task\": \"Regression\",\n",
    "            \"Model\": \"LassoCV\",\n",
    "            \"Technique\": \"Scaled\",\n",
    "            \"Precision\": None,\n",
    "            \"Recall\": None,\n",
    "            \"Score\": None,\n",
    "            \"R2\": res[\"lasso\"][\"r2\"],\n",
    "            \"MSE\": res[\"lasso\"][\"mse\"]\n",
    "        })\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# BUILD FINAL SUMMARY TABLE\n",
    "# --------------------------\n",
    "summary_table = pd.DataFrame(summary_rows)\n",
    "\n",
    "# sorting for readability\n",
    "summary_table = summary_table.sort_values(\n",
    "    by=[\"Task\", \"ClusterExp\", \"Level\", \"Cluster\", \"Model\"]\n",
    ").reset_index(drop=True)\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bad2cd",
   "metadata": {},
   "source": [
    "# More complex approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011332f1",
   "metadata": {},
   "source": [
    "## Helper functions that draw a subset of the total dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2816d388",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84275b0",
   "metadata": {},
   "source": [
    "### HistGradientBoostingClassifier on Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cad4335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global classification split (training already subsampled by your function)\n",
    "Xtr_clf, Xte_clf, ytr_clf, yte_clf = global_clf_results[\"train_split\"]\n",
    "\n",
    "# Global regression split (training already subsampled)\n",
    "Xtr_reg, Xte_reg, ytr_reg, yte_reg = global_reg_results[\"train_split\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee55d0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HGB classifier – Precision: 0.574, Recall: 0.029, Score: 0.301\n"
     ]
    }
   ],
   "source": [
    "def train_hgb_classifier_on_existing_split(\n",
    "    Xtr, Xte, ytr, yte,\n",
    "    random_state=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train HistGradientBoostingClassifier on the (already subsampled) train split.\n",
    "    \"\"\"\n",
    "    hgb_clf = HistGradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        max_iter=200,\n",
    "        max_leaf_nodes=31,\n",
    "        l2_regularization=1.0,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    hgb_clf.fit(Xtr, ytr)\n",
    "    y_pred = hgb_clf.predict(Xte)\n",
    "\n",
    "    p = precision_score(yte, y_pred)\n",
    "    r = recall_score(yte, y_pred)\n",
    "    s = 0.5 * (p + r)\n",
    "\n",
    "    return {\n",
    "        \"model\": hgb_clf,\n",
    "        \"precision\": p,\n",
    "        \"recall\": r,\n",
    "        \"score\": s,\n",
    "        \"n_train_used\": len(Xtr),\n",
    "    }\n",
    "\n",
    "\n",
    "hgb_clf_results = train_hgb_classifier_on_existing_split(\n",
    "    Xtr_clf, Xte_clf, ytr_clf, yte_clf,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(\"HGB classifier – Precision: {:.3f}, Recall: {:.3f}, Score: {:.3f}\".format(\n",
    "    hgb_clf_results[\"precision\"],\n",
    "    hgb_clf_results[\"recall\"],\n",
    "    hgb_clf_results[\"score\"],\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6ad6ef",
   "metadata": {},
   "source": [
    "### Stacking ensemble (LogReg + RF, global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1b92826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elena\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking classifier – Precision: 0.576, Recall: 0.014, Score: 0.295\n"
     ]
    }
   ],
   "source": [
    "def train_stacking_classifier_on_existing_split(\n",
    "    Xtr, Xte, ytr, yte,\n",
    "    random_state=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train stacking classifier (LogisticRegression + RandomForest) on the\n",
    "    subsampled global train split.\n",
    "    \"\"\"\n",
    "    # Base estimators\n",
    "    base_lr = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(\n",
    "            random_state=random_state,\n",
    "            solver=\"liblinear\",\n",
    "            max_iter=300,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    base_rf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_leaf=20,\n",
    "        max_features=\"sqrt\",\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    stack_clf = StackingClassifier(\n",
    "        estimators=[\n",
    "            (\"lr\", base_lr),\n",
    "            (\"rf\", base_rf),\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(\n",
    "            random_state=random_state,\n",
    "            solver=\"lbfgs\",\n",
    "            max_iter=300,\n",
    "        ),\n",
    "        passthrough=True,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    stack_clf.fit(Xtr, ytr)\n",
    "    y_pred = stack_clf.predict(Xte)\n",
    "\n",
    "    p = precision_score(yte, y_pred)\n",
    "    r = recall_score(yte, y_pred)\n",
    "    s = 0.5 * (p + r)\n",
    "\n",
    "    return {\n",
    "        \"model\": stack_clf,\n",
    "        \"precision\": p,\n",
    "        \"recall\": r,\n",
    "        \"score\": s,\n",
    "        \"n_train_used\": len(Xtr),\n",
    "    }\n",
    "\n",
    "\n",
    "stack_clf_results = train_stacking_classifier_on_existing_split(\n",
    "    Xtr_clf, Xte_clf, ytr_clf, yte_clf,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(\"Stacking classifier – Precision: {:.3f}, Recall: {:.3f}, Score: {:.3f}\".format(\n",
    "    stack_clf_results[\"precision\"],\n",
    "    stack_clf_results[\"recall\"],\n",
    "    stack_clf_results[\"score\"],\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9514f652",
   "metadata": {},
   "source": [
    "### HistGradientBoostingClassifier on Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3de2e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_hgb_classifiers(\n",
    "    cluster_clf_results,\n",
    "    random_state=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    For each cluster in cluster_clf_results, train a HistGradientBoostingClassifier\n",
    "    on that cluster's (already-subsampled) train split and evaluate on its test split.\n",
    "    \n",
    "    Assumes each entry has:\n",
    "        res[\"train_split\"] = (Xtr_sub, Xte, ytr_sub, yte)\n",
    "    \"\"\"\n",
    "    cluster_hgb_clf_results = {}\n",
    "\n",
    "    for clust_id, res in cluster_clf_results.items():\n",
    "        if \"train_split\" not in res:\n",
    "            # you can raise or skip; I'm being defensive\n",
    "            continue\n",
    "\n",
    "        Xtr_c, Xte_c, ytr_c, yte_c = res[\"train_split\"]\n",
    "\n",
    "        hgb_clf = HistGradientBoostingClassifier(\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            max_iter=200,\n",
    "            max_leaf_nodes=31,\n",
    "            l2_regularization=1.0,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        hgb_clf.fit(Xtr_c, ytr_c)\n",
    "        y_pred_c = hgb_clf.predict(Xte_c)\n",
    "\n",
    "        p = precision_score(yte_c, y_pred_c)\n",
    "        r = recall_score(yte_c, y_pred_c)\n",
    "        s = 0.5 * (p + r)\n",
    "\n",
    "        cluster_hgb_clf_results[clust_id] = {\n",
    "            \"model\": hgb_clf,\n",
    "            \"precision\": p,\n",
    "            \"recall\": r,\n",
    "            \"score\": s,\n",
    "            \"n_train_used\": len(Xtr_c),\n",
    "        }\n",
    "\n",
    "    return cluster_hgb_clf_results\n",
    "\n",
    "\n",
    "cluster_hgb_clf_results = train_cluster_hgb_classifiers(cluster_clf_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44d62142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_hgb_clf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e1d2d6",
   "metadata": {},
   "source": [
    "### Clustered Stacking (LogReg + RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7fd5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_stacking_classifiers(\n",
    "    cluster_clf_results,\n",
    "    random_state=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    For each cluster, train a stacking classifier (LogReg + RF) on its train split.\n",
    "    \"\"\"\n",
    "\n",
    "    cluster_stack_clf_results = {}\n",
    "\n",
    "    for clust_id, res in cluster_clf_results.items():\n",
    "        if \"train_split\" not in res:\n",
    "            continue\n",
    "\n",
    "        Xtr_c, Xte_c, ytr_c, yte_c = res[\"train_split\"]\n",
    "\n",
    "        # Base estimators per cluster\n",
    "        base_lr = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            LogisticRegression(\n",
    "                random_state=random_state,\n",
    "                solver=\"liblinear\",\n",
    "                max_iter=300,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        base_rf = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            min_samples_leaf=20,\n",
    "            max_features=\"sqrt\",\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=-1,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        stack_clf = StackingClassifier(\n",
    "            estimators=[\n",
    "                (\"lr\", base_lr),\n",
    "                (\"rf\", base_rf),\n",
    "            ],\n",
    "            final_estimator=LogisticRegression(\n",
    "                random_state=random_state,\n",
    "                solver=\"lbfgs\",\n",
    "                max_iter=300,\n",
    "            ),\n",
    "            passthrough=True,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "\n",
    "        stack_clf.fit(Xtr_c, ytr_c)\n",
    "        y_pred_c = stack_clf.predict(Xte_c)\n",
    "\n",
    "        p = precision_score(yte_c, y_pred_c)\n",
    "        r = recall_score(yte_c, y_pred_c)\n",
    "        s = 0.5 * (p + r)\n",
    "\n",
    "        cluster_stack_clf_results[clust_id] = {\n",
    "            \"model\": stack_clf,\n",
    "            \"precision\": p,\n",
    "            \"recall\": r,\n",
    "            \"score\": s,\n",
    "            \"n_train_used\": len(Xtr_c),\n",
    "        }\n",
    "\n",
    "    return cluster_stack_clf_results\n",
    "\n",
    "\n",
    "cluster_stack_clf_results = train_cluster_stacking_classifiers(cluster_clf_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9eb01ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_stack_clf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f7784a",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "### RandomForestRegressor on Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70fc1e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF regressor – R²: 0.029, MSE: 2956.2\n"
     ]
    }
   ],
   "source": [
    "def train_rf_regressor_on_existing_split(\n",
    "    Xtr, Xte, ytr, yte,\n",
    "    random_state=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train RandomForestRegressor on the subsampled global train split.\n",
    "    \"\"\"\n",
    "    rf_reg = RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=15,\n",
    "        min_samples_leaf=20,\n",
    "        max_features=\"sqrt\",\n",
    "        n_jobs=-1,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    rf_reg.fit(Xtr, ytr)\n",
    "    y_pred = rf_reg.predict(Xte)\n",
    "\n",
    "    r2 = r2_score(yte, y_pred)\n",
    "    mse = mean_squared_error(yte, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"model\": rf_reg,\n",
    "        \"r2\": r2,\n",
    "        \"mse\": mse,\n",
    "        \"n_train_used\": len(Xtr),\n",
    "    }\n",
    "\n",
    "\n",
    "rf_reg_results = train_rf_regressor_on_existing_split(\n",
    "    Xtr_reg, Xte_reg, ytr_reg, yte_reg,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(\"RF regressor – R²: {:.3f}, MSE: {:.1f}\".format(\n",
    "    rf_reg_results[\"r2\"],\n",
    "    rf_reg_results[\"mse\"],\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb65c39f",
   "metadata": {},
   "source": [
    "### HistGradientBoostingRegressor on Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f07409f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HGB regressor – R²: 0.028, MSE: 2961.4\n"
     ]
    }
   ],
   "source": [
    "def train_hgb_regressor_on_existing_split(\n",
    "    Xtr, Xte, ytr, yte,\n",
    "    random_state=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train HistGradientBoostingRegressor on the subsampled global train split.\n",
    "    \"\"\"\n",
    "    hgb_reg = HistGradientBoostingRegressor(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        max_iter=200,\n",
    "        max_leaf_nodes=31,\n",
    "        l2_regularization=1.0,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    hgb_reg.fit(Xtr, ytr)\n",
    "    y_pred = hgb_reg.predict(Xte)\n",
    "\n",
    "    r2 = r2_score(yte, y_pred)\n",
    "    mse = mean_squared_error(yte, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"model\": hgb_reg,\n",
    "        \"r2\": r2,\n",
    "        \"mse\": mse,\n",
    "        \"n_train_used\": len(Xtr),\n",
    "    }\n",
    "\n",
    "\n",
    "hgb_reg_results = train_hgb_regressor_on_existing_split(\n",
    "    Xtr_reg, Xte_reg, ytr_reg, yte_reg,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(\"HGB regressor – R²: {:.3f}, MSE: {:.1f}\".format(\n",
    "    hgb_reg_results[\"r2\"],\n",
    "    hgb_reg_results[\"mse\"],\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbab6e79",
   "metadata": {},
   "source": [
    "### Clustered RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "683abba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_rf_regressors(\n",
    "    cluster_reg_results,\n",
    "    random_state=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    For each cluster in cluster_reg_results, train a RandomForestRegressor\n",
    "    on its (already-subsampled) train split and evaluate on test split.\n",
    "    \"\"\"\n",
    "\n",
    "    cluster_rf_reg_results = {}\n",
    "\n",
    "    for clust_id, res in cluster_reg_results.items():\n",
    "        if \"train_split\" not in res:\n",
    "            continue\n",
    "\n",
    "        Xtr_c, Xte_c, ytr_c, yte_c = res[\"train_split\"]\n",
    "\n",
    "        rf_reg = RandomForestRegressor(\n",
    "            n_estimators=200,\n",
    "            max_depth=15,\n",
    "            min_samples_leaf=20,\n",
    "            max_features=\"sqrt\",\n",
    "            n_jobs=-1,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        rf_reg.fit(Xtr_c, ytr_c)\n",
    "        y_pred_c = rf_reg.predict(Xte_c)\n",
    "\n",
    "        r2 = r2_score(yte_c, y_pred_c)\n",
    "        mse = mean_squared_error(yte_c, y_pred_c)\n",
    "\n",
    "        cluster_rf_reg_results[clust_id] = {\n",
    "            \"model\": rf_reg,\n",
    "            \"r2\": r2,\n",
    "            \"mse\": mse,\n",
    "            \"n_train_used\": len(Xtr_c),\n",
    "        }\n",
    "\n",
    "    return cluster_rf_reg_results\n",
    "\n",
    "\n",
    "cluster_rf_reg_results = train_cluster_rf_regressors(cluster_reg_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab472cf7",
   "metadata": {},
   "source": [
    "### Clustered HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27bfde7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_hgb_regressors(\n",
    "    cluster_reg_results,\n",
    "    random_state=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    For each cluster, train a HistGradientBoostingRegressor on its train split.\n",
    "    \"\"\"\n",
    "\n",
    "    cluster_hgb_reg_results = {}\n",
    "\n",
    "    for clust_id, res in cluster_reg_results.items():\n",
    "        if \"train_split\" not in res:\n",
    "            continue\n",
    "\n",
    "        Xtr_c, Xte_c, ytr_c, yte_c = res[\"train_split\"]\n",
    "\n",
    "        hgb_reg = HistGradientBoostingRegressor(\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            max_iter=200,\n",
    "            max_leaf_nodes=31,\n",
    "            l2_regularization=1.0,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        hgb_reg.fit(Xtr_c, ytr_c)\n",
    "        y_pred_c = hgb_reg.predict(Xte_c)\n",
    "\n",
    "        r2 = r2_score(yte_c, y_pred_c)\n",
    "        mse = mean_squared_error(yte_c, y_pred_c)\n",
    "\n",
    "        cluster_hgb_reg_results[clust_id] = {\n",
    "            \"model\": hgb_reg,\n",
    "            \"r2\": r2,\n",
    "            \"mse\": mse,\n",
    "            \"n_train_used\": len(Xtr_c),\n",
    "        }\n",
    "\n",
    "    return cluster_hgb_reg_results\n",
    "\n",
    "\n",
    "cluster_hgb_reg_results = train_cluster_hgb_regressors(cluster_reg_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39799fd",
   "metadata": {},
   "source": [
    "# Add to summary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "994fb3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>ClusterExp</th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Score</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>SubsampledGlobal</td>\n",
       "      <td>0.574300</td>\n",
       "      <td>0.028595</td>\n",
       "      <td>0.301448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Stacking(LR+RF)</td>\n",
       "      <td>SubsampledGlobal</td>\n",
       "      <td>0.576226</td>\n",
       "      <td>0.014283</td>\n",
       "      <td>0.295254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Regression</td>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>SubsampledGlobal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027553</td>\n",
       "      <td>2961.378628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Regression</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>SubsampledGlobal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029247</td>\n",
       "      <td>2956.218808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Level Cluster ClusterExp            Task                           Model  \\\n",
       "0  Global       -          -  Classification  HistGradientBoostingClassifier   \n",
       "1  Global       -          -  Classification                 Stacking(LR+RF)   \n",
       "2  Global       -          -      Regression   HistGradientBoostingRegressor   \n",
       "3  Global       -          -      Regression           RandomForestRegressor   \n",
       "\n",
       "          Technique  Precision    Recall     Score        R2          MSE  \n",
       "0  SubsampledGlobal   0.574300  0.028595  0.301448       NaN          NaN  \n",
       "1  SubsampledGlobal   0.576226  0.014283  0.295254       NaN          NaN  \n",
       "2  SubsampledGlobal        NaN       NaN       NaN  0.027553  2961.378628  \n",
       "3  SubsampledGlobal        NaN       NaN       NaN  0.029247  2956.218808  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_rows = []\n",
    "\n",
    "# Classification – HGB\n",
    "summary_rows.append({\n",
    "    \"Level\": \"Global\",\n",
    "    \"Cluster\": \"-\",\n",
    "    \"ClusterExp\": \"-\",\n",
    "    \"Task\": \"Classification\",\n",
    "    \"Model\": \"HistGradientBoostingClassifier\",\n",
    "    \"Technique\": \"SubsampledGlobal\",\n",
    "    \"Precision\": hgb_clf_results[\"precision\"],\n",
    "    \"Recall\": hgb_clf_results[\"recall\"],\n",
    "    \"Score\": hgb_clf_results[\"score\"],\n",
    "    \"R2\": None,\n",
    "    \"MSE\": None,\n",
    "})\n",
    "\n",
    "# Classification – Stacking\n",
    "summary_rows.append({\n",
    "    \"Level\": \"Global\",\n",
    "    \"Cluster\": \"-\",\n",
    "    \"ClusterExp\": \"-\",\n",
    "    \"Task\": \"Classification\",\n",
    "    \"Model\": \"Stacking(LR+RF)\",\n",
    "    \"Technique\": \"SubsampledGlobal\",\n",
    "    \"Precision\": stack_clf_results[\"precision\"],\n",
    "    \"Recall\": stack_clf_results[\"recall\"],\n",
    "    \"Score\": stack_clf_results[\"score\"],\n",
    "    \"R2\": None,\n",
    "    \"MSE\": None,\n",
    "})\n",
    "\n",
    "# Regression – RF\n",
    "summary_rows.append({\n",
    "    \"Level\": \"Global\",\n",
    "    \"Cluster\": \"-\",\n",
    "    \"ClusterExp\": \"-\",\n",
    "    \"Task\": \"Regression\",\n",
    "    \"Model\": \"RandomForestRegressor\",\n",
    "    \"Technique\": \"SubsampledGlobal\",\n",
    "    \"Precision\": None,\n",
    "    \"Recall\": None,\n",
    "    \"Score\": None,\n",
    "    \"R2\": rf_reg_results[\"r2\"],\n",
    "    \"MSE\": rf_reg_results[\"mse\"],\n",
    "})\n",
    "\n",
    "# Regression – HGB\n",
    "summary_rows.append({\n",
    "    \"Level\": \"Global\",\n",
    "    \"Cluster\": \"-\",\n",
    "    \"ClusterExp\": \"-\",\n",
    "    \"Task\": \"Regression\",\n",
    "    \"Model\": \"HistGradientBoostingRegressor\",\n",
    "    \"Technique\": \"SubsampledGlobal\",\n",
    "    \"Precision\": None,\n",
    "    \"Recall\": None,\n",
    "    \"Score\": None,\n",
    "    \"R2\": hgb_reg_results[\"r2\"],\n",
    "    \"MSE\": hgb_reg_results[\"mse\"],\n",
    "})\n",
    "\n",
    "# Classification – HGB per cluster\n",
    "for clust_id, res in cluster_hgb_clf_results.items():\n",
    "    summary_rows.append({\n",
    "        \"Level\": \"Cluster\",\n",
    "        \"Cluster\": clust_id,\n",
    "        \"ClusterExp\": exp_name if \"exp_name\" in locals() else \"-\",  # or however you're tracking it\n",
    "        \"Task\": \"Classification\",\n",
    "        \"Model\": \"HistGradientBoostingClassifier\",\n",
    "        \"Technique\": \"SubsampledCluster\",\n",
    "        \"Precision\": res[\"precision\"],\n",
    "        \"Recall\": res[\"recall\"],\n",
    "        \"Score\": res[\"score\"],\n",
    "        \"R2\": None,\n",
    "        \"MSE\": None,\n",
    "    })\n",
    "\n",
    "# Classification – Stacking per cluster\n",
    "for clust_id, res in cluster_stack_clf_results.items():\n",
    "    summary_rows.append({\n",
    "        \"Level\": \"Cluster\",\n",
    "        \"Cluster\": clust_id,\n",
    "        \"ClusterExp\": exp_name if \"exp_name\" in locals() else \"-\",\n",
    "        \"Task\": \"Classification\",\n",
    "        \"Model\": \"Stacking(LR+RF)\",\n",
    "        \"Technique\": \"SubsampledCluster\",\n",
    "        \"Precision\": res[\"precision\"],\n",
    "        \"Recall\": res[\"recall\"],\n",
    "        \"Score\": res[\"score\"],\n",
    "        \"R2\": None,\n",
    "        \"MSE\": None,\n",
    "    })\n",
    "\n",
    "# Regression – RF per cluster\n",
    "for clust_id, res in cluster_rf_reg_results.items():\n",
    "    summary_rows.append({\n",
    "        \"Level\": \"Cluster\",\n",
    "        \"Cluster\": clust_id,\n",
    "        \"ClusterExp\": exp_name if \"exp_name\" in locals() else \"-\",\n",
    "        \"Task\": \"Regression\",\n",
    "        \"Model\": \"RandomForestRegressor\",\n",
    "        \"Technique\": \"SubsampledCluster\",\n",
    "        \"Precision\": None,\n",
    "        \"Recall\": None,\n",
    "        \"Score\": None,\n",
    "        \"R2\": res[\"r2\"],\n",
    "        \"MSE\": res[\"mse\"],\n",
    "    })\n",
    "\n",
    "# Regression – HGB per cluster\n",
    "for clust_id, res in cluster_hgb_reg_results.items():\n",
    "    summary_rows.append({\n",
    "        \"Level\": \"Cluster\",\n",
    "        \"Cluster\": clust_id,\n",
    "        \"ClusterExp\": exp_name if \"exp_name\" in locals() else \"-\",\n",
    "        \"Task\": \"Regression\",\n",
    "        \"Model\": \"HistGradientBoostingRegressor\",\n",
    "        \"Technique\": \"SubsampledCluster\",\n",
    "        \"Precision\": None,\n",
    "        \"Recall\": None,\n",
    "        \"Score\": None,\n",
    "        \"R2\": res[\"r2\"],\n",
    "        \"MSE\": res[\"mse\"],\n",
    "    })\n",
    "summary_table_extended = pd.DataFrame(summary_rows)\n",
    "summary_table_extended = summary_table_extended.sort_values(\n",
    "    by=[\"Task\", \"ClusterExp\", \"Level\", \"Cluster\", \"Model\"]\n",
    ").reset_index(drop=True)\n",
    "summary_table_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69189a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Base features from 2023_TEST.csv (before alignment):\n",
      "['airline_bucket', 'origin_bucket', 'destination_bucket', 'lagged_delay_flag', 'prev_real_delay', 'MONTH', 'HOUR', 'origin_flights_day']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>ClusterExp</th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Score</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>SubsampledGlobal</td>\n",
       "      <td>0.574300</td>\n",
       "      <td>0.028595</td>\n",
       "      <td>0.301448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Stacking(LR+RF)</td>\n",
       "      <td>SubsampledGlobal</td>\n",
       "      <td>0.576226</td>\n",
       "      <td>0.014283</td>\n",
       "      <td>0.295254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Regression</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>SubsampledGlobal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029247</td>\n",
       "      <td>2956.218808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Regression</td>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>SubsampledGlobal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027553</td>\n",
       "      <td>2961.378628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>2023_only</td>\n",
       "      <td>Classification</td>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>2023_Test</td>\n",
       "      <td>0.612137</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.306436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>2023_only</td>\n",
       "      <td>Regression</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>2023_Test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019223</td>\n",
       "      <td>2296.796646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>2023_only</td>\n",
       "      <td>Classification</td>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>2023_Test</td>\n",
       "      <td>0.612137</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.306436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>2023_only</td>\n",
       "      <td>Regression</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>2023_Test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019223</td>\n",
       "      <td>2296.796646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Level Cluster ClusterExp            Task                           Model  \\\n",
       "0  Global       -          -  Classification  HistGradientBoostingClassifier   \n",
       "1  Global       -          -  Classification                 Stacking(LR+RF)   \n",
       "2  Global       -          -      Regression           RandomForestRegressor   \n",
       "3  Global       -          -      Regression   HistGradientBoostingRegressor   \n",
       "4  Global       -  2023_only  Classification  HistGradientBoostingClassifier   \n",
       "5  Global       -  2023_only      Regression           RandomForestRegressor   \n",
       "6  Global       -  2023_only  Classification  HistGradientBoostingClassifier   \n",
       "7  Global       -  2023_only      Regression           RandomForestRegressor   \n",
       "\n",
       "          Technique  Precision    Recall     Score        R2          MSE  \n",
       "0  SubsampledGlobal   0.574300  0.028595  0.301448       NaN          NaN  \n",
       "1  SubsampledGlobal   0.576226  0.014283  0.295254       NaN          NaN  \n",
       "2  SubsampledGlobal        NaN       NaN       NaN  0.029247  2956.218808  \n",
       "3  SubsampledGlobal        NaN       NaN       NaN  0.027553  2961.378628  \n",
       "4         2023_Test   0.612137  0.000735  0.306436       NaN          NaN  \n",
       "5         2023_Test        NaN       NaN       NaN  0.019223  2296.796646  \n",
       "6         2023_Test   0.612137  0.000735  0.306436       NaN          NaN  \n",
       "7         2023_Test        NaN       NaN       NaN  0.019223  2296.796646  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, r2_score, mean_squared_error\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. Feature + target configuration (including HOUR)\n",
    "# -------------------------------------------------------------------\n",
    "FEATURES_2023 = [\n",
    "    \"airline_bucket\",\n",
    "    \"origin_bucket\",\n",
    "    \"destination_bucket\",\n",
    "    \"lagged_delay_flag\",\n",
    "    \"prev_real_delay\",\n",
    "    \"MONTH\",\n",
    "    \"HOUR\",               # engineered from CRS_DEP_TIME\n",
    "    \"origin_flights_day\",\n",
    "]\n",
    "\n",
    "CLASS_TARGET_COL = \"DEP_DEL15\"      # binary delay flag\n",
    "REG_TARGET_COL   = \"DEP_DELAY_NEW\"  # delay duration (minutes)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. Engineer HOUR from CRS_DEP_TIME (HHMM → hour-of-day)\n",
    "# -------------------------------------------------------------------\n",
    "def add_hour_feature(df, time_col: str = \"CRS_DEP_TIME\", hour_col: str = \"HOUR\"):\n",
    "    \"\"\"\n",
    "    Engineer an HOUR feature from a scheduled departure time column in HHMM format.\n",
    "    HOUR = floor(CRS_DEP_TIME / 100)\n",
    "    \"\"\"\n",
    "    if time_col not in df.columns:\n",
    "        raise ValueError(f\"Expected time column '{time_col}' not found in DataFrame.\")\n",
    "\n",
    "    t = pd.to_numeric(df[time_col], errors=\"coerce\")\n",
    "    df[hour_col] = (t // 100)\n",
    "    return df\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Align features to match model's training order\n",
    "# -------------------------------------------------------------------\n",
    "def align_features_to_model(X: pd.DataFrame, model):\n",
    "    \"\"\"\n",
    "    Reorder (and subset) X's columns to match the feature_names_in_ used at fit time.\n",
    "    Raises an error if the model expects columns that are missing in X.\n",
    "    \"\"\"\n",
    "    if not hasattr(model, \"feature_names_in_\"):\n",
    "        # model was likely fit on a numpy array; assume current order is correct\n",
    "        return X\n",
    "\n",
    "    expected = list(model.feature_names_in_)\n",
    "    missing = [c for c in expected if c not in X.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"X is missing features expected by the model: {missing}\")\n",
    "\n",
    "    # Reorder columns to exactly match training-time order\n",
    "    return X[expected]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. Load 2023 data and build feature matrices\n",
    "# -------------------------------------------------------------------\n",
    "def load_2023_data(\n",
    "    path: str = \"2023_TEST.csv\",\n",
    "    feature_cols = FEATURES_2023,\n",
    "    clf_target_col: str = CLASS_TARGET_COL,\n",
    "    reg_target_col: str = REG_TARGET_COL,\n",
    "):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Engineer HOUR -- must be in same order as training data\n",
    "    df = add_hour_feature(df, time_col=\"CRS_DEP_TIME\", hour_col=\"HOUR\")\n",
    "\n",
    "    # Sanity check: ensure all configured feature and target columns exist\n",
    "    missing_features = [c for c in feature_cols if c not in df.columns]\n",
    "    if missing_features:\n",
    "        raise ValueError(f\"Missing feature columns in 2023_TEST.csv after engineering HOUR: {missing_features}\")\n",
    "\n",
    "    missing_targets = [c for c in [clf_target_col, reg_target_col] if c not in df.columns]\n",
    "    if missing_targets:\n",
    "        raise ValueError(f\"Missing target columns in 2023_TEST.csv: {missing_targets}\")\n",
    "\n",
    "    X_2023 = df[feature_cols].copy()\n",
    "    y_clf_2023 = df[clf_target_col].copy()\n",
    "    y_reg_2023 = df[reg_target_col].copy()\n",
    "\n",
    "    return df, X_2023, y_clf_2023, y_reg_2023\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5. Evaluation helpers (using feature alignment)\n",
    "# -------------------------------------------------------------------\n",
    "def evaluate_2023_classifier(model, X, y):\n",
    "    \"\"\"\n",
    "    Evaluate a pretrained classifier on 2023 data.\n",
    "    Aligns X columns to the model's feature_names_in_.\n",
    "    \"\"\"\n",
    "    X_aligned = align_features_to_model(X, model)\n",
    "    y_pred = model.predict(X_aligned)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    score = 0.5 * (precision + recall)\n",
    "    return {\"precision\": precision, \"recall\": recall, \"score\": score}\n",
    "\n",
    "def evaluate_2023_regressor(model, X, y):\n",
    "    \"\"\"\n",
    "    Evaluate a pretrained regressor on 2023 data.\n",
    "    Aligns X columns to the model's feature_names_in_.\n",
    "    \"\"\"\n",
    "    X_aligned = align_features_to_model(X, model)\n",
    "    y_pred = model.predict(X_aligned)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    return {\"r2\": r2, \"mse\": mse}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 6. Load data, get pretrained models, and run evaluation\n",
    "# -------------------------------------------------------------------\n",
    "df_2023, X_2023, y_clf_2023, y_reg_2023 = load_2023_data()\n",
    "\n",
    "print(\"✓ Base features from 2023_TEST.csv (before alignment):\")\n",
    "print(X_2023.columns.tolist())\n",
    "\n",
    "hgb_clf_model = hgb_clf_results[\"model\"]\n",
    "rf_reg_model  = rf_reg_results[\"model\"]\n",
    "\n",
    "hgb_2023_metrics = evaluate_2023_classifier(hgb_clf_model, X_2023, y_clf_2023)\n",
    "rf_2023_metrics  = evaluate_2023_regressor(rf_reg_model,  X_2023, y_reg_2023)\n",
    "\n",
    "summary_rows_2023 = [\n",
    "    {\n",
    "        \"Level\": \"Global\",\n",
    "        \"Cluster\": \"-\",\n",
    "        \"ClusterExp\": \"2023_only\",\n",
    "        \"Task\": \"Classification\",\n",
    "        \"Model\": \"HistGradientBoostingClassifier\",\n",
    "        \"Technique\": \"2023_Test\",\n",
    "        \"Precision\": hgb_2023_metrics[\"precision\"],\n",
    "        \"Recall\": hgb_2023_metrics[\"recall\"],\n",
    "        \"Score\": hgb_2023_metrics[\"score\"],\n",
    "        \"R2\": None,\n",
    "        \"MSE\": None,\n",
    "    },\n",
    "    {\n",
    "        \"Level\": \"Global\",\n",
    "        \"Cluster\": \"-\",\n",
    "        \"ClusterExp\": \"2023_only\",\n",
    "        \"Task\": \"Regression\",\n",
    "        \"Model\": \"RandomForestRegressor\",\n",
    "        \"Technique\": \"2023_Test\",\n",
    "        \"Precision\": None,\n",
    "        \"Recall\": None,\n",
    "        \"Score\": None,\n",
    "        \"R2\": rf_2023_metrics[\"r2\"],\n",
    "        \"MSE\": rf_2023_metrics[\"mse\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "summary_rows.extend(summary_rows_2023)\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "display(summary_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
