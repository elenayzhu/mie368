{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ec55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, r2_score, mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    HistGradientBoostingClassifier,\n",
    "    HistGradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier,\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265e9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data_with_clusters.csv\"\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    \"MONTH\",\n",
    "    \"HOUR\",\n",
    "    \"origin_flights_day\",\n",
    "    \"airline_bucket\",\n",
    "    \"origin_bucket\",\n",
    "    \"destination_bucket\",\n",
    "    \"lagged_delay_flag\",\n",
    "    \"prev_real_delay\",\n",
    "]\n",
    "\n",
    "TARGET_CLF = \"DEP_DEL15\" #binary departure delay indicator\n",
    "TARGET_REG = \"DEP_DELAY_NEW\" #continuous departure delay (min)\n",
    "CLUSTER_COL = \"cluster\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# keep only needed columns, drop rows with missing in features/targets\n",
    "df = df.dropna(subset=FEATURE_COLS + [TARGET_CLF, TARGET_REG])\n",
    "\n",
    "X_clf = df[FEATURE_COLS]\n",
    "y_clf = df[TARGET_CLF].astype(int)\n",
    "\n",
    "X_reg = df[FEATURE_COLS]\n",
    "y_reg = df[TARGET_REG].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b93fae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>QUARTER</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>MKT_CARRIER_AIRLINE_ID</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>ORIGIN_AIRPORT_SEQ_ID</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_real_delay</th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>origin_flights_day</th>\n",
       "      <th>origin_bucket</th>\n",
       "      <th>dest_flights_day</th>\n",
       "      <th>destination_bucket</th>\n",
       "      <th>distance_bucket</th>\n",
       "      <th>airline_bucket</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19393</td>\n",
       "      <td>10140</td>\n",
       "      <td>1014005</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>10423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19393</td>\n",
       "      <td>10140</td>\n",
       "      <td>1014005</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>10423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19393</td>\n",
       "      <td>10140</td>\n",
       "      <td>1014005</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>10800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19393</td>\n",
       "      <td>10140</td>\n",
       "      <td>1014005</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>10821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19393</td>\n",
       "      <td>10140</td>\n",
       "      <td>1014005</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>11259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  QUARTER  MONTH  DAY  DAY_OF_WEEK  MKT_CARRIER_AIRLINE_ID  \\\n",
       "0  2024        1      1    1            1                   19393   \n",
       "1  2024        1      1    1            1                   19393   \n",
       "2  2024        1      1    1            1                   19393   \n",
       "3  2024        1      1    1            1                   19393   \n",
       "4  2024        1      1    1            1                   19393   \n",
       "\n",
       "   ORIGIN_AIRPORT_ID  ORIGIN_AIRPORT_SEQ_ID ORIGIN_CITY_NAME  DEST_AIRPORT_ID  \\\n",
       "0              10140                1014005  Albuquerque, NM            10423   \n",
       "1              10140                1014005  Albuquerque, NM            10423   \n",
       "2              10140                1014005  Albuquerque, NM            10800   \n",
       "3              10140                1014005  Albuquerque, NM            10821   \n",
       "4              10140                1014005  Albuquerque, NM            11259   \n",
       "\n",
       "   ...  prev_real_delay     FL_DATE  origin_flights_day  origin_bucket  \\\n",
       "0  ...              0.0  2024-01-01                  67              1   \n",
       "1  ...              0.0  2024-01-01                  67              1   \n",
       "2  ...              0.0  2024-01-01                  67              1   \n",
       "3  ...              0.0  2024-01-01                  67              1   \n",
       "4  ...              0.0  2024-01-01                  67              1   \n",
       "\n",
       "   dest_flights_day  destination_bucket  distance_bucket  airline_bucket  \\\n",
       "0               241                   2                2               1   \n",
       "1               241                   2                2               1   \n",
       "2                90                   1                3               1   \n",
       "3               265                   2                4               1   \n",
       "4               214                   2                2               1   \n",
       "\n",
       "   HOUR  cluster  \n",
       "0     7        0  \n",
       "1    18        0  \n",
       "2    14        1  \n",
       "3    15        0  \n",
       "4     5        0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "024353c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_models():\n",
    "    return {\n",
    "        \"LR_L2\": LogisticRegression(\n",
    "            random_state=0, solver=\"liblinear\", max_iter=200\n",
    "        ),\n",
    "        \"LR_L1\": LogisticRegression(\n",
    "            random_state=0,\n",
    "            penalty=\"l1\",\n",
    "            solver=\"liblinear\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=500,\n",
    "        ),\n",
    "        \"CART\": DecisionTreeClassifier(\n",
    "            random_state=0, class_weight=\"balanced\"\n",
    "        ),\n",
    "        \"RF\": RandomForestClassifier(\n",
    "            random_state=0, class_weight=\"balanced\", n_jobs=-1,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "def init_all_models():\n",
    "    model_names = (\"LR_L2\", \"LR_L1\", \"CART\", \"RF\")\n",
    "    techniques = (\"Baseline\", \"Scaling\")  # subset of full Lab 6 list\n",
    "\n",
    "    idx = pd.MultiIndex.from_product(\n",
    "        [model_names, techniques],\n",
    "        names=(\"model\", \"technique\"),\n",
    "    )\n",
    "    all_models = pd.DataFrame(\n",
    "        index=idx,\n",
    "        columns=[\"Precision\", \"Recall\", \"Score\", \"Model\"],\n",
    "    )\n",
    "    all_models[[\"Precision\", \"Recall\", \"Score\"]] = all_models[\n",
    "        [\"Precision\", \"Recall\", \"Score\"]\n",
    "    ].astype(float)\n",
    "    return all_models\n",
    "\n",
    "\n",
    "def standardize_data(X_train, X_out):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    Xtr = pd.DataFrame(\n",
    "        scaler.transform(X_train),\n",
    "        index=X_train.index,\n",
    "        columns=X_train.columns,\n",
    "    )\n",
    "    Xout = pd.DataFrame(\n",
    "        scaler.transform(X_out),\n",
    "        index=X_out.index,\n",
    "        columns=X_out.columns,\n",
    "    )\n",
    "    return Xtr, Xout, scaler\n",
    "\n",
    "\n",
    "def fit_and_score_model(all_models, stage_name,\n",
    "                        X_train, X_out, y_train, y_out):\n",
    "    models_dict = make_models()\n",
    "\n",
    "    for model_name, model in models_dict.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_out)\n",
    "\n",
    "        p = precision_score(y_out, y_pred)\n",
    "        r = recall_score(y_out, y_pred)\n",
    "        s = 0.5 * (p + r)\n",
    "\n",
    "        idx = (model_name, stage_name)\n",
    "        \n",
    "        all_models.at[idx, \"Precision\"] = p\n",
    "        all_models.at[idx, \"Recall\"] = r\n",
    "        all_models.at[idx, \"Score\"] = s\n",
    "        all_models.at[idx, \"Model\"] = model\n",
    "\n",
    "    return all_models\n",
    "\n",
    "\n",
    "def compare_models(all_models, technique_name=\"Scaling\"):\n",
    "    diffs = (\n",
    "        all_models.xs(technique_name, level=\"technique\").Score.values\n",
    "        - all_models.xs(\"Baseline\", level=\"technique\").Score.values\n",
    "    )\n",
    "    print(\n",
    "        f\"{technique_name}: mean ΔScore={diffs.mean():.3f}, \"\n",
    "        f\"max ΔScore={diffs.max():.3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98712080",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_CLF_TRAIN_FRAC = 0.25   # 25% of global clf train\n",
    "CLUSTER_CLF_TRAIN_FRAC = 0.5    # up to 50% of each cluster's train\n",
    "GLOBAL_REG_TRAIN_FRAC = 0.25   # 25% of global reg train\n",
    "CLUSTER_REG_TRAIN_FRAC = 0.5    # 30% of each cluster's reg train\n",
    "LASSO_TRAIN_FRAC = 0.2  # 20% just for LassoCV (more expensive)\n",
    "\n",
    "MIN_SUBSAMPLE_SIZE = 500000    # don't bother subsampling below this\n",
    "\n",
    "def stratified_subsample_xy_frac(X, y, frac=1.0, random_state=0):\n",
    "    \"\"\"\n",
    "    Classification subsample: take a fraction of (X, y), stratified by y.\n",
    "    If frac >= 1.0 or dataset is already small, return (X, y) unchanged.\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    if frac >= 1.0 or n <= MIN_SUBSAMPLE_SIZE:\n",
    "        return X, y\n",
    "\n",
    "    n_sub = int(n * frac)\n",
    "    if n_sub < MIN_SUBSAMPLE_SIZE:\n",
    "        # if frac is tiny on a small dataset, just keep all\n",
    "        return X, y\n",
    "\n",
    "    X_sub, _, y_sub, _ = train_test_split(\n",
    "        X, y,\n",
    "        train_size=n_sub,\n",
    "        stratify=y,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    return X_sub, y_sub\n",
    "\n",
    "\n",
    "def random_subsample_xy_frac(X, y, frac=1.0, random_state=0):\n",
    "    \"\"\"\n",
    "    Regression subsample: take a random fraction of (X, y).\n",
    "    If frac >= 1.0 or dataset is already small, return (X, y) unchanged.\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    if frac >= 1.0 or n <= MIN_SUBSAMPLE_SIZE:\n",
    "        return X, y\n",
    "\n",
    "    n_sub = int(n * frac)\n",
    "    if n_sub < MIN_SUBSAMPLE_SIZE:\n",
    "        return X, y\n",
    "\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    idx = rng.choice(n, size=n_sub, replace=False)\n",
    "\n",
    "    if isinstance(X, (pd.DataFrame, pd.Series)):\n",
    "        return X.iloc[idx], y.iloc[idx]\n",
    "    else:\n",
    "        return X[idx], y[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13d59b8",
   "metadata": {},
   "source": [
    "# Model Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36aba590",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def train_global_classification_models(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    "    train_frac=GLOBAL_CLF_TRAIN_FRAC,\n",
    "):\n",
    "    # Full split first\n",
    "    Xtr, Xte, ytr, yte = train_test_split(\n",
    "        X, y,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "    # === SUBSAMPLE TRAINING SET (stratified by y) ===\n",
    "    Xtr_sub, ytr_sub = stratified_subsample_xy_frac(\n",
    "        Xtr, ytr,\n",
    "        frac=train_frac,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    all_models = init_all_models()\n",
    "\n",
    "    # Baseline (unscaled) – train on subsample, test on full test set\n",
    "    all_models = fit_and_score_model(\n",
    "        all_models, \"Baseline\",\n",
    "        Xtr_sub, Xte, ytr_sub, yte\n",
    "    )\n",
    "\n",
    "    # Scaling – fit scaler on subsample, transform full test\n",
    "    Xtr_s, Xte_s, scaler = standardize_data(Xtr_sub, Xte)\n",
    "    all_models = fit_and_score_model(\n",
    "        all_models, \"Scaling\",\n",
    "        Xtr_s, Xte_s, ytr_sub, yte\n",
    "    )\n",
    "\n",
    "    compare_models(all_models, \"Scaling\")\n",
    "\n",
    "    best_row = all_models.sort_values(\"Score\").iloc[-1]\n",
    "    best_model = best_row[\"Model\"]\n",
    "\n",
    "    return {\n",
    "        \"all_models\": all_models,\n",
    "        \"best_model\": best_model,\n",
    "        \"scaler\": scaler,\n",
    "        # store what we *actually used* for training\n",
    "        \"train_split\": (Xtr_sub, Xte, ytr_sub, yte),\n",
    "    }\n",
    "\n",
    "\n",
    "global_clf_results = train_global_classification_models(X_clf, y_clf)\n",
    "global_clf_results[\"all_models\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2811f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_classification_models(\n",
    "    df,\n",
    "    feature_cols,\n",
    "    target_col,\n",
    "    cluster_col=\"cluster\",\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    "    train_frac=CLUSTER_CLF_TRAIN_FRAC,\n",
    "):\n",
    "    cluster_results = {}\n",
    "\n",
    "    for clust_id, df_c in df.groupby(cluster_col):\n",
    "        y_c = df_c[target_col].astype(int)\n",
    "        if y_c.nunique() < 2 or len(df_c) < 40:\n",
    "            continue\n",
    "\n",
    "        X_c = df_c[feature_cols]\n",
    "\n",
    "        Xtr, Xte, ytr, yte = train_test_split(\n",
    "            X_c, y_c,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=y_c,\n",
    "        )\n",
    "\n",
    "        # === SUBSAMPLE TRAINING SET IN THIS CLUSTER ===\n",
    "        Xtr_sub, ytr_sub = stratified_subsample_xy_frac(\n",
    "            Xtr, ytr,\n",
    "            frac=train_frac,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        all_models = init_all_models()\n",
    "\n",
    "        # Baseline\n",
    "        all_models = fit_and_score_model(\n",
    "            all_models, \"Baseline\", Xtr_sub, Xte, ytr_sub, yte\n",
    "        )\n",
    "\n",
    "        # Scaling\n",
    "        Xtr_s, Xte_s, scaler = standardize_data(Xtr_sub, Xte)\n",
    "        all_models = fit_and_score_model(\n",
    "            all_models, \"Scaling\", Xtr_s, Xte_s, ytr_sub, yte\n",
    "        )\n",
    "\n",
    "        best_row = all_models.sort_values(\"Score\").iloc[-1]\n",
    "        best_model = best_row[\"Model\"]\n",
    "\n",
    "        cluster_results[clust_id] = {\n",
    "            \"all_models\": all_models,\n",
    "            \"best_model\": best_model,\n",
    "            \"scaler\": scaler,\n",
    "            \"train_split\": (Xtr_sub, Xte, ytr_sub, yte),\n",
    "        }\n",
    "\n",
    "    return cluster_results\n",
    "\n",
    "\n",
    "cluster_clf_results = train_cluster_classification_models(\n",
    "    df,\n",
    "    FEATURE_COLS,\n",
    "    TARGET_CLF,\n",
    "    cluster_col=CLUSTER_COL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edccf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_global_regression_models(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    "    train_frac=GLOBAL_REG_TRAIN_FRAC,\n",
    "    lasso_frac=LASSO_TRAIN_FRAC,\n",
    "):\n",
    "    # Full split\n",
    "    Xtr, Xte, ytr, yte = train_test_split(\n",
    "        X, y,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    # === SUBSAMPLE TRAINING FOR LINEAR & LASSO ===\n",
    "    Xtr_sub, ytr_sub = random_subsample_xy_frac(\n",
    "        Xtr, ytr,\n",
    "        frac=train_frac,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    # Plain linear regression (unscaled)\n",
    "    lin = LinearRegression()\n",
    "    lin.fit(Xtr_sub, ytr_sub)\n",
    "    yhat_lin = lin.predict(Xte)\n",
    "    lin_r2 = r2_score(yte, yhat_lin)\n",
    "    lin_mse = mean_squared_error(yte, yhat_lin)\n",
    "\n",
    "    # LassoCV (scaled) – optionally even smaller subsample\n",
    "    Xtr_lasso, ytr_lasso = random_subsample_xy_frac(\n",
    "        Xtr_sub, ytr_sub,\n",
    "        frac=lasso_frac / max(train_frac, 1e-9) if lasso_frac < train_frac else 1.0,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    Xtr_s, Xte_s, scaler = standardize_data(Xtr_lasso, Xte)\n",
    "    lasso = LassoCV(\n",
    "        cv=3,               # lighter than 5-fold\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    lasso.fit(Xtr_s, ytr_lasso)\n",
    "    yhat_lasso = lasso.predict(Xte_s)\n",
    "    lasso_r2 = r2_score(yte, yhat_lasso)\n",
    "    lasso_mse = mean_squared_error(yte, yhat_lasso)\n",
    "\n",
    "    return {\n",
    "        \"linear\": {\n",
    "            \"model\": lin,\n",
    "            \"r2\": lin_r2,\n",
    "            \"mse\": lin_mse,\n",
    "        },\n",
    "        \"lasso\": {\n",
    "            \"model\": lasso,\n",
    "            \"scaler\": scaler,\n",
    "            \"r2\": lasso_r2,\n",
    "            \"mse\": lasso_mse,\n",
    "        },\n",
    "        \"train_split\": (Xtr_sub, Xte, ytr_sub, yte),\n",
    "    }\n",
    "\n",
    "\n",
    "global_reg_results = train_global_regression_models(X_reg, y_reg)\n",
    "global_reg_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3860af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_regression_models(\n",
    "    df,\n",
    "    feature_cols,\n",
    "    target_col,\n",
    "    cluster_col=\"cluster\",\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    "    min_rows=40,\n",
    "    train_frac=CLUSTER_REG_TRAIN_FRAC,\n",
    "    lasso_frac=LASSO_TRAIN_FRAC,\n",
    "):\n",
    "    cluster_reg_results = {}\n",
    "\n",
    "    for clust_id, df_c in df.groupby(cluster_col):\n",
    "        if len(df_c) < min_rows:\n",
    "            continue\n",
    "\n",
    "        X_c = df_c[feature_cols]\n",
    "        y_c = df_c[target_col].astype(float)\n",
    "\n",
    "        Xtr, Xte, ytr, yte = train_test_split(\n",
    "            X_c, y_c,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        # === SUBSAMPLE TRAINING FOR THIS CLUSTER ===\n",
    "        Xtr_sub, ytr_sub = random_subsample_xy_frac(\n",
    "            Xtr, ytr,\n",
    "            frac=train_frac,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        # Linear\n",
    "        lin = LinearRegression()\n",
    "        lin.fit(Xtr_sub, ytr_sub)\n",
    "        yhat_lin = lin.predict(Xte)\n",
    "        lin_r2 = r2_score(yte, yhat_lin)\n",
    "        lin_mse = mean_squared_error(yte, yhat_lin)\n",
    "\n",
    "        # Lasso\n",
    "        Xtr_lasso, ytr_lasso = random_subsample_xy_frac(\n",
    "            Xtr_sub, ytr_sub,\n",
    "            frac=lasso_frac / max(train_frac, 1e-9) if lasso_frac < train_frac else 1.0,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        Xtr_s, Xte_s, scaler = standardize_data(Xtr_lasso, Xte)\n",
    "        lasso = LassoCV(\n",
    "            cv=3,\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        lasso.fit(Xtr_s, ytr_lasso)\n",
    "        yhat_lasso = lasso.predict(Xte_s)\n",
    "        lasso_r2 = r2_score(yte, yhat_lasso)\n",
    "        lasso_mse = mean_squared_error(yte, yhat_lasso)\n",
    "\n",
    "        cluster_reg_results[clust_id] = {\n",
    "            \"linear\": {\n",
    "                \"model\": lin,\n",
    "                \"r2\": lin_r2,\n",
    "                \"mse\": lin_mse,\n",
    "            },\n",
    "            \"lasso\": {\n",
    "                \"model\": lasso,\n",
    "                \"scaler\": scaler,\n",
    "                \"r2\": lasso_r2,\n",
    "                \"mse\": lasso_mse,\n",
    "            },\n",
    "            \"train_split\": (Xtr_sub, Xte, ytr_sub, yte),\n",
    "        }\n",
    "\n",
    "    return cluster_reg_results\n",
    "\n",
    "\n",
    "cluster_reg_results = train_cluster_regression_models(\n",
    "    df,\n",
    "    FEATURE_COLS,\n",
    "    TARGET_REG,\n",
    "    cluster_col=CLUSTER_COL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ed1dc2",
   "metadata": {},
   "source": [
    "## Not on a subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c4352a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m\n\u001b[1;32m     22\u001b[0m     best_model \u001b[38;5;241m=\u001b[39m best_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_models\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_models,\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_model,\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m\"\u001b[39m: scaler,\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_split\u001b[39m\u001b[38;5;124m\"\u001b[39m: (Xtr, Xte, ytr, yte),\n\u001b[1;32m     29\u001b[0m     }\n\u001b[0;32m---> 32\u001b[0m global_clf_results \u001b[38;5;241m=\u001b[39m train_global_classification_models(X_clf, y_clf)\n\u001b[1;32m     33\u001b[0m global_clf_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_models\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m, in \u001b[0;36mtrain_global_classification_models\u001b[0;34m(X, y, test_size, random_state)\u001b[0m\n\u001b[1;32m      6\u001b[0m all_models \u001b[38;5;241m=\u001b[39m init_all_models()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Baseline\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m all_models \u001b[38;5;241m=\u001b[39m fit_and_score_model(\n\u001b[1;32m     10\u001b[0m     all_models, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline\u001b[39m\u001b[38;5;124m\"\u001b[39m, Xtr, Xte, ytr, yte\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Scaling\u001b[39;00m\n\u001b[1;32m     14\u001b[0m Xtr_s, Xte_s, scaler \u001b[38;5;241m=\u001b[39m standardize_data(Xtr, Xte)\n",
      "Cell \u001b[0;32mIn[5], line 62\u001b[0m, in \u001b[0;36mfit_and_score_model\u001b[0;34m(all_models, stage_name, X_train, X_out, y_train, y_out)\u001b[0m\n\u001b[1;32m     59\u001b[0m models_dict \u001b[38;5;241m=\u001b[39m make_models()\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 62\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     63\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_out)\n\u001b[1;32m     65\u001b[0m     p \u001b[38;5;241m=\u001b[39m precision_score(y_out, y_pred)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    490\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    491\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    492\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    493\u001b[0m )(\n\u001b[1;32m    494\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    495\u001b[0m         t,\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    497\u001b[0m         X,\n\u001b[1;32m    498\u001b[0m         y,\n\u001b[1;32m    499\u001b[0m         sample_weight,\n\u001b[1;32m    500\u001b[0m         i,\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    502\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    503\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    504\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    505\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    508\u001b[0m )\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 192\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    193\u001b[0m         X,\n\u001b[1;32m    194\u001b[0m         y,\n\u001b[1;32m    195\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight,\n\u001b[1;32m    196\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    197\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    201\u001b[0m         X,\n\u001b[1;32m    202\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/tree/_classes.py:305\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    303\u001b[0m y_encoded \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(y\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_):\n\u001b[0;32m--> 305\u001b[0m     classes_k, y_encoded[:, k] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y[:, k], return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mappend(classes_k)\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\u001b[38;5;241m.\u001b[39mappend(classes_k\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[1;32m    275\u001b[0m                     equal_nan\u001b[38;5;241m=\u001b[39mequal_nan)\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/lib/arraysetops.py:338\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    336\u001b[0m     ar\u001b[38;5;241m.\u001b[39msort()\n\u001b[1;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[0;32m--> 338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n\u001b[1;32m    339\u001b[0m mask[:\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (equal_nan \u001b[38;5;129;01mand\u001b[39;00m aux\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m aux\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfmM\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    341\u001b[0m         np\u001b[38;5;241m.\u001b[39misnan(aux[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_global_classification_models(X, y, test_size=0.2, random_state=0):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    all_models = init_all_models()\n",
    "\n",
    "    # Baseline\n",
    "    all_models = fit_and_score_model(\n",
    "        all_models, \"Baseline\", Xtr, Xte, ytr, yte\n",
    "    )\n",
    "\n",
    "    # Scaling\n",
    "    Xtr_s, Xte_s, scaler = standardize_data(Xtr, Xte)\n",
    "    all_models = fit_and_score_model(\n",
    "        all_models, \"Scaling\", Xtr_s, Xte_s, ytr, yte\n",
    "    )\n",
    "\n",
    "    compare_models(all_models, \"Scaling\")\n",
    "\n",
    "    best_row = all_models.sort_values(\"Score\").iloc[-1]\n",
    "    best_model = best_row[\"Model\"]\n",
    "\n",
    "    return {\n",
    "        \"all_models\": all_models,\n",
    "        \"best_model\": best_model,\n",
    "        \"scaler\": scaler,\n",
    "        \"train_split\": (Xtr, Xte, ytr, yte),\n",
    "    }\n",
    "\n",
    "\n",
    "global_clf_results = train_global_classification_models(X_clf, y_clf)\n",
    "global_clf_results[\"all_models\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608de875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_classification_models(df,\n",
    "                                        feature_cols,\n",
    "                                        target_col,\n",
    "                                        cluster_col=\"cluster\",\n",
    "                                        test_size=0.2,\n",
    "                                        random_state=0):\n",
    "    cluster_results = {}\n",
    "\n",
    "    for clust_id, df_c in df.groupby(cluster_col):\n",
    "        y_c = df_c[target_col].astype(int)\n",
    "        if y_c.nunique() < 2 or len(df_c) < 40:\n",
    "            continue\n",
    "\n",
    "        X_c = df_c[feature_cols]\n",
    "\n",
    "        Xtr, Xte, ytr, yte = train_test_split(\n",
    "            X_c, y_c,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=y_c,\n",
    "        )\n",
    "\n",
    "        all_models = init_all_models()\n",
    "\n",
    "        all_models = fit_and_score_model(\n",
    "            all_models, \"Baseline\", Xtr, Xte, ytr, yte\n",
    "        )\n",
    "\n",
    "        Xtr_s, Xte_s, scaler = standardize_data(Xtr, Xte)\n",
    "        all_models = fit_and_score_model(\n",
    "            all_models, \"Scaling\", Xtr_s, Xte_s, ytr, yte\n",
    "        )\n",
    "\n",
    "        best_row = all_models.sort_values(\"Score\").iloc[-1]\n",
    "        best_model = best_row[\"Model\"]\n",
    "\n",
    "        cluster_results[clust_id] = {\n",
    "            \"all_models\": all_models,\n",
    "            \"best_model\": best_model,\n",
    "            \"scaler\": scaler,\n",
    "        }\n",
    "\n",
    "    return cluster_results\n",
    "\n",
    "\n",
    "cluster_clf_results = train_cluster_classification_models(\n",
    "    df,\n",
    "    FEATURE_COLS,\n",
    "    TARGET_CLF,\n",
    "    cluster_col=CLUSTER_COL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d360e644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear': {'model': LinearRegression(),\n",
       "  'r2': 0.004382212091354809,\n",
       "  'mse': 3031.940064178128},\n",
       " 'lasso': {'model': LassoCV(cv=5, random_state=0),\n",
       "  'scaler': StandardScaler(),\n",
       "  'r2': 0.004382149319585027,\n",
       "  'mse': 3031.9402553360665},\n",
       " 'train_split': (         airline_bucket  origin_bucket  destination_bucket  lagged_delay_flag  \\\n",
       "  2840684               1              2                   3                  0   \n",
       "  2506158               1              2                   4                  0   \n",
       "  1795334               1              4                   2                  0   \n",
       "  930487                1              3                   1                  0   \n",
       "  749653                1              4                   1                  0   \n",
       "  ...                 ...            ...                 ...                ...   \n",
       "  2249467               1              1                   2                  0   \n",
       "  5157699               1              2                   4                  0   \n",
       "  2215104               1              4                   2                  1   \n",
       "  1484405               1              3                   1                  0   \n",
       "  4500015               1              3                   1                  0   \n",
       "  \n",
       "           prev_real_delay  \n",
       "  2840684              0.0  \n",
       "  2506158           1482.0  \n",
       "  1795334              0.0  \n",
       "  930487              24.0  \n",
       "  749653               0.0  \n",
       "  ...                  ...  \n",
       "  2249467              0.0  \n",
       "  5157699              0.0  \n",
       "  2215104             36.0  \n",
       "  1484405              0.0  \n",
       "  4500015             27.0  \n",
       "  \n",
       "  [5955264 rows x 5 columns],\n",
       "           airline_bucket  origin_bucket  destination_bucket  lagged_delay_flag  \\\n",
       "  4154393               1              3                   4                  0   \n",
       "  4902533               1              4                   1                  0   \n",
       "  649961                1              2                   3                  0   \n",
       "  489667                1              2                   3                  0   \n",
       "  6209768               1              4                   3                  0   \n",
       "  ...                 ...            ...                 ...                ...   \n",
       "  2005209               1              3                   1                  1   \n",
       "  4582310               0              1                   1                  0   \n",
       "  1673490               1              4                   2                  0   \n",
       "  3544446               1              3                   1                  0   \n",
       "  6635196               1              4                   2                  0   \n",
       "  \n",
       "           prev_real_delay  \n",
       "  4154393              0.0  \n",
       "  4902533             83.0  \n",
       "  649961               0.0  \n",
       "  489667               0.0  \n",
       "  6209768              0.0  \n",
       "  ...                  ...  \n",
       "  2005209            104.0  \n",
       "  4582310              0.0  \n",
       "  1673490              0.0  \n",
       "  3544446              0.0  \n",
       "  6635196              0.0  \n",
       "  \n",
       "  [1488816 rows x 5 columns],\n",
       "  2840684     0.0\n",
       "  2506158     0.0\n",
       "  1795334    60.0\n",
       "  930487      0.0\n",
       "  749653      0.0\n",
       "             ... \n",
       "  2249467     0.0\n",
       "  5157699     0.0\n",
       "  2215104     0.0\n",
       "  1484405     0.0\n",
       "  4500015     0.0\n",
       "  Name: DEP_DELAY_NEW, Length: 5955264, dtype: float64,\n",
       "  4154393      1.0\n",
       "  4902533      0.0\n",
       "  649961       0.0\n",
       "  489667       0.0\n",
       "  6209768      0.0\n",
       "             ...  \n",
       "  2005209      0.0\n",
       "  4582310    255.0\n",
       "  1673490      0.0\n",
       "  3544446      0.0\n",
       "  6635196     17.0\n",
       "  Name: DEP_DELAY_NEW, Length: 1488816, dtype: float64)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_global_regression_models(X, y, test_size=0.2, random_state=0):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Plain linear regression (unscaled)\n",
    "    lin = LinearRegression()\n",
    "    lin.fit(Xtr, ytr)\n",
    "    yhat_lin = lin.predict(Xte)\n",
    "    lin_r2 = r2_score(yte, yhat_lin)\n",
    "    lin_mse = mean_squared_error(yte, yhat_lin)\n",
    "\n",
    "    # LassoCV (scaled)\n",
    "    Xtr_s, Xte_s, scaler = standardize_data(Xtr, Xte)\n",
    "    lasso = LassoCV(cv=5, random_state=random_state)\n",
    "    lasso.fit(Xtr_s, ytr)\n",
    "    yhat_lasso = lasso.predict(Xte_s)\n",
    "    lasso_r2 = r2_score(yte, yhat_lasso)\n",
    "    lasso_mse = mean_squared_error(yte, yhat_lasso)\n",
    "\n",
    "    return {\n",
    "        \"linear\": {\n",
    "            \"model\": lin,\n",
    "            \"r2\": lin_r2,\n",
    "            \"mse\": lin_mse,\n",
    "        },\n",
    "        \"lasso\": {\n",
    "            \"model\": lasso,\n",
    "            \"scaler\": scaler,\n",
    "            \"r2\": lasso_r2,\n",
    "            \"mse\": lasso_mse,\n",
    "        },\n",
    "        \"train_split\": (Xtr, Xte, ytr, yte),\n",
    "    }\n",
    "\n",
    "\n",
    "global_reg_results = train_global_regression_models(X_reg, y_reg)\n",
    "global_reg_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06a2f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_regression_models(df,\n",
    "                                    feature_cols,\n",
    "                                    target_col,\n",
    "                                    cluster_col=\"cluster\",\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=0,\n",
    "                                    min_rows=40):\n",
    "    cluster_reg_results = {}\n",
    "\n",
    "    for clust_id, df_c in df.groupby(cluster_col):\n",
    "        if len(df_c) < min_rows:\n",
    "            continue\n",
    "\n",
    "        X_c = df_c[feature_cols]\n",
    "        y_c = df_c[target_col].astype(float)\n",
    "\n",
    "        Xtr, Xte, ytr, yte = train_test_split(\n",
    "            X_c, y_c,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        # linear\n",
    "        lin = LinearRegression()\n",
    "        lin.fit(Xtr, ytr)\n",
    "        yhat_lin = lin.predict(Xte)\n",
    "        lin_r2 = r2_score(yte, yhat_lin)\n",
    "        lin_mse = mean_squared_error(yte, yhat_lin)\n",
    "\n",
    "        # lasso (scaled)\n",
    "        Xtr_s, Xte_s, scaler = standardize_data(Xtr, Xte)\n",
    "        lasso = LassoCV(cv=5, random_state=random_state)\n",
    "        lasso.fit(Xtr_s, ytr)\n",
    "        yhat_lasso = lasso.predict(Xte_s)\n",
    "        lasso_r2 = r2_score(yte, yhat_lasso)\n",
    "        lasso_mse = mean_squared_error(yte, yhat_lasso)\n",
    "\n",
    "        cluster_reg_results[clust_id] = {\n",
    "            \"linear\": {\n",
    "                \"model\": lin,\n",
    "                \"r2\": lin_r2,\n",
    "                \"mse\": lin_mse,\n",
    "            },\n",
    "            \"lasso\": {\n",
    "                \"model\": lasso,\n",
    "                \"scaler\": scaler,\n",
    "                \"r2\": lasso_r2,\n",
    "                \"mse\": lasso_mse,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    return cluster_reg_results\n",
    "\n",
    "\n",
    "cluster_reg_results = train_cluster_regression_models(\n",
    "    df,\n",
    "    FEATURE_COLS,\n",
    "    TARGET_REG,\n",
    "    cluster_col=CLUSTER_COL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1bc1a7",
   "metadata": {},
   "source": [
    "# Cluster Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf2a49af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_clusters(df, k, cluster_features, cluster_col_name):\n",
    "    X_cluster = df[cluster_features].copy()\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    labels = kmeans.fit_predict(X_cluster)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[cluster_col_name] = labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead0d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_EXPERIMENTS = [\n",
    "    {\n",
    "        \"name\": \"k3_all_feats\",\n",
    "        \"k\": 3,\n",
    "        \"cluster_features\": FEATURE_COLS,      # use all current features\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"k4_all_feats\",\n",
    "        \"k\": 4,\n",
    "        \"cluster_features\": FEATURE_COLS,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"k5_all_feats\",\n",
    "        \"k\": 5,\n",
    "        \"cluster_features\": FEATURE_COLS,\n",
    "    },\n",
    "    # add more as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49f5aca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "all_cluster_clf_results = {}\n",
    "all_cluster_reg_results = {}\n",
    "\n",
    "for cfg in CLUSTER_EXPERIMENTS:\n",
    "    exp_name = cfg[\"name\"]\n",
    "    k = cfg[\"k\"]\n",
    "    cluster_features = cfg[\"cluster_features\"]\n",
    "\n",
    "    # 1) assign cluster labels for this experiment\n",
    "    cluster_col = f\"cluster_{exp_name}\"\n",
    "    df_with_clusters = assign_clusters(df, k, cluster_features, cluster_col)\n",
    "\n",
    "    # 2) train cluster-specific classification models\n",
    "    cluster_clf_results = train_cluster_classification_models(\n",
    "        df_with_clusters,\n",
    "        FEATURE_COLS,       # you can choose to change this too, if needed\n",
    "        TARGET_CLF,\n",
    "        cluster_col=cluster_col,\n",
    "    )\n",
    "\n",
    "    # 3) train cluster-specific regression models\n",
    "    cluster_reg_results = train_cluster_regression_models(\n",
    "        df_with_clusters,\n",
    "        FEATURE_COLS,\n",
    "        TARGET_REG,\n",
    "        cluster_col=cluster_col,\n",
    "    )\n",
    "\n",
    "    # 4) store results keyed by experiment name\n",
    "    all_cluster_clf_results[exp_name] = cluster_clf_results\n",
    "    all_cluster_reg_results[exp_name] = cluster_reg_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea8ff41",
   "metadata": {},
   "source": [
    "# Gathering Summary Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd3e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>ClusterExp</th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Score</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.259102</td>\n",
       "      <td>0.444737</td>\n",
       "      <td>0.351919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.259099</td>\n",
       "      <td>0.444734</td>\n",
       "      <td>0.351916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.239996</td>\n",
       "      <td>0.513178</td>\n",
       "      <td>0.376587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.239987</td>\n",
       "      <td>0.512857</td>\n",
       "      <td>0.376422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L2</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.311712</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.157284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L2</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.311847</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.157354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>RF</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.258949</td>\n",
       "      <td>0.442471</td>\n",
       "      <td>0.350710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>RF</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.258941</td>\n",
       "      <td>0.442458</td>\n",
       "      <td>0.350699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.359075</td>\n",
       "      <td>0.604621</td>\n",
       "      <td>0.481848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.240317</td>\n",
       "      <td>0.447639</td>\n",
       "      <td>0.343978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.338638</td>\n",
       "      <td>0.601810</td>\n",
       "      <td>0.470224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.364837</td>\n",
       "      <td>0.607510</td>\n",
       "      <td>0.486173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.211704</td>\n",
       "      <td>0.522327</td>\n",
       "      <td>0.367016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.339322</td>\n",
       "      <td>0.568427</td>\n",
       "      <td>0.453875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.331784</td>\n",
       "      <td>0.544751</td>\n",
       "      <td>0.438267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>4</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.346546</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>0.475644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.260214</td>\n",
       "      <td>0.452842</td>\n",
       "      <td>0.356528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.258898</td>\n",
       "      <td>0.352007</td>\n",
       "      <td>0.305453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.265713</td>\n",
       "      <td>0.481200</td>\n",
       "      <td>0.373456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Classification</td>\n",
       "      <td>CART</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.307741</td>\n",
       "      <td>0.288359</td>\n",
       "      <td>0.298050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>4</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Classification</td>\n",
       "      <td>LR_L1</td>\n",
       "      <td>Scaling</td>\n",
       "      <td>0.208258</td>\n",
       "      <td>0.387939</td>\n",
       "      <td>0.298098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>3031.940255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Global</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>3031.940064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>6007.356960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>6007.356643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>2889.234537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>2889.234554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>7117.469209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k3_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>7111.294382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>6350.934545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>6350.931530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>2723.883022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>2723.882993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002294</td>\n",
       "      <td>7935.651595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>7934.597012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>4382.175054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>4382.188236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>4</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000894</td>\n",
       "      <td>7699.487776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>4</td>\n",
       "      <td>k5_all_feats</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001242</td>\n",
       "      <td>7702.166822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>2512.836732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>0</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>2512.836059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>4127.691024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>1</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>4127.694307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>3243.101835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>2</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>3243.098624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007436</td>\n",
       "      <td>1993.850727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>3</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007438</td>\n",
       "      <td>1993.847747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>4</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LassoCV</td>\n",
       "      <td>Scaled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>3351.785667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Cluster</td>\n",
       "      <td>4</td>\n",
       "      <td>k5_subset_origin_dest</td>\n",
       "      <td>Regression</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003172</td>\n",
       "      <td>3351.785154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Level Cluster             ClusterExp            Task             Model  \\\n",
       "0    Global       -                      -  Classification              CART   \n",
       "1    Global       -                      -  Classification              CART   \n",
       "2    Global       -                      -  Classification             LR_L1   \n",
       "3    Global       -                      -  Classification             LR_L1   \n",
       "4    Global       -                      -  Classification             LR_L2   \n",
       "5    Global       -                      -  Classification             LR_L2   \n",
       "6    Global       -                      -  Classification                RF   \n",
       "7    Global       -                      -  Classification                RF   \n",
       "8   Cluster       0           k3_all_feats  Classification             LR_L1   \n",
       "9   Cluster       1           k3_all_feats  Classification             LR_L1   \n",
       "10  Cluster       2           k3_all_feats  Classification             LR_L1   \n",
       "11  Cluster       0           k5_all_feats  Classification             LR_L1   \n",
       "12  Cluster       1           k5_all_feats  Classification             LR_L1   \n",
       "13  Cluster       2           k5_all_feats  Classification             LR_L1   \n",
       "14  Cluster       3           k5_all_feats  Classification             LR_L1   \n",
       "15  Cluster       4           k5_all_feats  Classification             LR_L1   \n",
       "16  Cluster       0  k5_subset_origin_dest  Classification             LR_L1   \n",
       "17  Cluster       1  k5_subset_origin_dest  Classification              CART   \n",
       "18  Cluster       2  k5_subset_origin_dest  Classification             LR_L1   \n",
       "19  Cluster       3  k5_subset_origin_dest  Classification              CART   \n",
       "20  Cluster       4  k5_subset_origin_dest  Classification             LR_L1   \n",
       "21   Global       -                      -      Regression           LassoCV   \n",
       "22   Global       -                      -      Regression  LinearRegression   \n",
       "23  Cluster       0           k3_all_feats      Regression           LassoCV   \n",
       "24  Cluster       0           k3_all_feats      Regression  LinearRegression   \n",
       "25  Cluster       1           k3_all_feats      Regression           LassoCV   \n",
       "26  Cluster       1           k3_all_feats      Regression  LinearRegression   \n",
       "27  Cluster       2           k3_all_feats      Regression           LassoCV   \n",
       "28  Cluster       2           k3_all_feats      Regression  LinearRegression   \n",
       "29  Cluster       0           k5_all_feats      Regression           LassoCV   \n",
       "30  Cluster       0           k5_all_feats      Regression  LinearRegression   \n",
       "31  Cluster       1           k5_all_feats      Regression           LassoCV   \n",
       "32  Cluster       1           k5_all_feats      Regression  LinearRegression   \n",
       "33  Cluster       2           k5_all_feats      Regression           LassoCV   \n",
       "34  Cluster       2           k5_all_feats      Regression  LinearRegression   \n",
       "35  Cluster       3           k5_all_feats      Regression           LassoCV   \n",
       "36  Cluster       3           k5_all_feats      Regression  LinearRegression   \n",
       "37  Cluster       4           k5_all_feats      Regression           LassoCV   \n",
       "38  Cluster       4           k5_all_feats      Regression  LinearRegression   \n",
       "39  Cluster       0  k5_subset_origin_dest      Regression           LassoCV   \n",
       "40  Cluster       0  k5_subset_origin_dest      Regression  LinearRegression   \n",
       "41  Cluster       1  k5_subset_origin_dest      Regression           LassoCV   \n",
       "42  Cluster       1  k5_subset_origin_dest      Regression  LinearRegression   \n",
       "43  Cluster       2  k5_subset_origin_dest      Regression           LassoCV   \n",
       "44  Cluster       2  k5_subset_origin_dest      Regression  LinearRegression   \n",
       "45  Cluster       3  k5_subset_origin_dest      Regression           LassoCV   \n",
       "46  Cluster       3  k5_subset_origin_dest      Regression  LinearRegression   \n",
       "47  Cluster       4  k5_subset_origin_dest      Regression           LassoCV   \n",
       "48  Cluster       4  k5_subset_origin_dest      Regression  LinearRegression   \n",
       "\n",
       "   Technique  Precision    Recall     Score        R2          MSE  \n",
       "0   Baseline   0.259102  0.444737  0.351919       NaN          NaN  \n",
       "1    Scaling   0.259099  0.444734  0.351916       NaN          NaN  \n",
       "2   Baseline   0.239996  0.513178  0.376587       NaN          NaN  \n",
       "3    Scaling   0.239987  0.512857  0.376422       NaN          NaN  \n",
       "4   Baseline   0.311712  0.002857  0.157284       NaN          NaN  \n",
       "5    Scaling   0.311847  0.002861  0.157354       NaN          NaN  \n",
       "6   Baseline   0.258949  0.442471  0.350710       NaN          NaN  \n",
       "7    Scaling   0.258941  0.442458  0.350699       NaN          NaN  \n",
       "8   Baseline   0.359075  0.604621  0.481848       NaN          NaN  \n",
       "9    Scaling   0.240317  0.447639  0.343978       NaN          NaN  \n",
       "10   Scaling   0.338638  0.601810  0.470224       NaN          NaN  \n",
       "11   Scaling   0.364837  0.607510  0.486173       NaN          NaN  \n",
       "12   Scaling   0.211704  0.522327  0.367016       NaN          NaN  \n",
       "13  Baseline   0.339322  0.568427  0.453875       NaN          NaN  \n",
       "14   Scaling   0.331784  0.544751  0.438267       NaN          NaN  \n",
       "15   Scaling   0.346546  0.604743  0.475644       NaN          NaN  \n",
       "16   Scaling   0.260214  0.452842  0.356528       NaN          NaN  \n",
       "17   Scaling   0.258898  0.352007  0.305453       NaN          NaN  \n",
       "18   Scaling   0.265713  0.481200  0.373456       NaN          NaN  \n",
       "19   Scaling   0.307741  0.288359  0.298050       NaN          NaN  \n",
       "20   Scaling   0.208258  0.387939  0.298098       NaN          NaN  \n",
       "21    Scaled        NaN       NaN       NaN  0.004382  3031.940255  \n",
       "22  Baseline        NaN       NaN       NaN  0.004382  3031.940064  \n",
       "23    Scaled        NaN       NaN       NaN  0.001508  6007.356960  \n",
       "24  Baseline        NaN       NaN       NaN  0.001508  6007.356643  \n",
       "25    Scaled        NaN       NaN       NaN  0.003329  2889.234537  \n",
       "26  Baseline        NaN       NaN       NaN  0.003329  2889.234554  \n",
       "27    Scaled        NaN       NaN       NaN  0.002586  7117.469209  \n",
       "28  Baseline        NaN       NaN       NaN  0.003451  7111.294382  \n",
       "29    Scaled        NaN       NaN       NaN  0.002085  6350.934545  \n",
       "30  Baseline        NaN       NaN       NaN  0.002085  6350.931530  \n",
       "31    Scaled        NaN       NaN       NaN  0.001415  2723.883022  \n",
       "32  Baseline        NaN       NaN       NaN  0.001415  2723.882993  \n",
       "33    Scaled        NaN       NaN       NaN  0.002294  7935.651595  \n",
       "34  Baseline        NaN       NaN       NaN  0.002427  7934.597012  \n",
       "35    Scaled        NaN       NaN       NaN  0.002771  4382.175054  \n",
       "36  Baseline        NaN       NaN       NaN  0.002768  4382.188236  \n",
       "37    Scaled        NaN       NaN       NaN -0.000894  7699.487776  \n",
       "38  Baseline        NaN       NaN       NaN -0.001242  7702.166822  \n",
       "39    Scaled        NaN       NaN       NaN  0.005689  2512.836732  \n",
       "40  Baseline        NaN       NaN       NaN  0.005689  2512.836059  \n",
       "41    Scaled        NaN       NaN       NaN  0.002043  4127.691024  \n",
       "42  Baseline        NaN       NaN       NaN  0.002043  4127.694307  \n",
       "43    Scaled        NaN       NaN       NaN  0.004787  3243.101835  \n",
       "44  Baseline        NaN       NaN       NaN  0.004788  3243.098624  \n",
       "45    Scaled        NaN       NaN       NaN  0.007436  1993.850727  \n",
       "46  Baseline        NaN       NaN       NaN  0.007438  1993.847747  \n",
       "47    Scaled        NaN       NaN       NaN  0.003171  3351.785667  \n",
       "48  Baseline        NaN       NaN       NaN  0.003172  3351.785154  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_rows = []\n",
    "#global classification\n",
    "global_df = global_clf_results[\"all_models\"].copy()\n",
    "global_df = global_df.reset_index()\n",
    "for _, row in global_df.iterrows():\n",
    "    summary_rows.append({\n",
    "        \"Level\": \"Global\",\n",
    "        \"Cluster\": \"-\",\n",
    "        \"ClusterExp\": \"-\",  \n",
    "        \"Task\": \"Classification\",\n",
    "        \"Model\": row[\"model\"],\n",
    "        \"Technique\": row[\"technique\"],\n",
    "        \"Precision\": row[\"Precision\"],\n",
    "        \"Recall\": row[\"Recall\"],\n",
    "        \"Score\": row[\"Score\"],\n",
    "        \"R2\": None,\n",
    "        \"MSE\": None\n",
    "    })\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# CLUSTER CLASSIFICATION (MULTIPLE EXPERIMENTS)\n",
    "# ==========================================================\n",
    "for clust_id, res in cluster_clf_results.items():\n",
    "    df_m = res[\"all_models\"].reset_index()  # bring model, technique out of index\n",
    "\n",
    "    for _, row in df_m.iterrows():\n",
    "        summary_rows.append({\n",
    "            \"Level\": \"Cluster\",\n",
    "            \"Cluster\": clust_id,\n",
    "            \"ClusterExp\": exp_name,\n",
    "            \"Task\": \"Classification\",\n",
    "            \"Model\": row[\"model\"],          # now from columns\n",
    "            \"Technique\": row[\"technique\"],  # Baseline / Scaling\n",
    "            \"Precision\": row[\"Precision\"],\n",
    "            \"Recall\": row[\"Recall\"],\n",
    "            \"Score\": row[\"Score\"],\n",
    "            \"R2\": None,\n",
    "            \"MSE\": None,\n",
    "        })\n",
    "\n",
    "# --------------------------\n",
    "# GLOBAL REGRESSION\n",
    "# --------------------------\n",
    "# linear\n",
    "summary_rows.append({\n",
    "    \"Level\": \"Global\",\n",
    "    \"Cluster\": \"-\",\n",
    "    \"ClusterExp\": \"-\",\n",
    "    \"Task\": \"Regression\",\n",
    "    \"Model\": \"LinearRegression\",\n",
    "    \"Technique\": \"Baseline\",\n",
    "    \"Precision\": None,\n",
    "    \"Recall\": None,\n",
    "    \"Score\": None,\n",
    "    \"R2\": global_reg_results[\"linear\"][\"r2\"],\n",
    "    \"MSE\": global_reg_results[\"linear\"][\"mse\"]\n",
    "})\n",
    "\n",
    "# lasso\n",
    "summary_rows.append({\n",
    "    \"Level\": \"Global\",\n",
    "    \"Cluster\": \"-\",\n",
    "    \"ClusterExp\": \"-\",\n",
    "    \"Task\": \"Regression\",\n",
    "    \"Model\": \"LassoCV\",\n",
    "    \"Technique\": \"Scaled\",\n",
    "    \"Precision\": None,\n",
    "    \"Recall\": None,\n",
    "    \"Score\": None,\n",
    "    \"R2\": global_reg_results[\"lasso\"][\"r2\"],\n",
    "    \"MSE\": global_reg_results[\"lasso\"][\"mse\"]\n",
    "})\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# CLUSTER REGRESSION (MULTIPLE EXPERIMENTS)\n",
    "# ==========================================================\n",
    "for exp_name, cluster_reg_results in all_cluster_reg_results.items():\n",
    "    for clust_id, res in cluster_reg_results.items():\n",
    "\n",
    "        # linear\n",
    "        summary_rows.append({\n",
    "            \"Level\": \"Cluster\",\n",
    "            \"Cluster\": clust_id,\n",
    "            \"ClusterExp\": exp_name, \n",
    "            \"Task\": \"Regression\",\n",
    "            \"Model\": \"LinearRegression\",\n",
    "            \"Technique\": \"Baseline\",\n",
    "            \"Precision\": None,\n",
    "            \"Recall\": None,\n",
    "            \"Score\": None,\n",
    "            \"R2\": res[\"linear\"][\"r2\"],\n",
    "            \"MSE\": res[\"linear\"][\"mse\"]\n",
    "        })\n",
    "\n",
    "        # lasso\n",
    "        summary_rows.append({\n",
    "            \"Level\": \"Cluster\",\n",
    "            \"Cluster\": clust_id,\n",
    "            \"ClusterExp\": exp_name,\n",
    "            \"Task\": \"Regression\",\n",
    "            \"Model\": \"LassoCV\",\n",
    "            \"Technique\": \"Scaled\",\n",
    "            \"Precision\": None,\n",
    "            \"Recall\": None,\n",
    "            \"Score\": None,\n",
    "            \"R2\": res[\"lasso\"][\"r2\"],\n",
    "            \"MSE\": res[\"lasso\"][\"mse\"]\n",
    "        })\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# BUILD FINAL SUMMARY TABLE\n",
    "# --------------------------\n",
    "summary_table = pd.DataFrame(summary_rows)\n",
    "\n",
    "# sorting for readability\n",
    "summary_table = summary_table.sort_values(\n",
    "    by=[\"Task\", \"ClusterExp\", \"Level\", \"Cluster\", \"Model\"]\n",
    ").reset_index(drop=True)\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bad2cd",
   "metadata": {},
   "source": [
    "# More complex approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011332f1",
   "metadata": {},
   "source": [
    "## Helper functions that draw a subset of the total dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faabe243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_subsample(X, y, max_samples=200_000, random_state=0):\n",
    "    \"\"\"\n",
    "    For classification: draw a stratified subsample of size max_samples.\n",
    "    If dataset is smaller than max_samples, return as-is.\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    if n <= max_samples:\n",
    "        return X, y\n",
    "\n",
    "    X_sub, _, y_sub, _ = train_test_split(\n",
    "        X, y,\n",
    "        train_size=max_samples,\n",
    "        stratify=y,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    return X_sub, y_sub\n",
    "\n",
    "\n",
    "def random_subsample(X, y, max_samples=200_000, random_state=0):\n",
    "    \"\"\"\n",
    "    For regression: draw a random subsample of size max_samples.\n",
    "    If dataset is smaller than max_samples, return as-is.\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    if n <= max_samples:\n",
    "        return X, y\n",
    "\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    idx = rng.choice(n, size=max_samples, replace=False)\n",
    "    if isinstance(X, pd.DataFrame) or isinstance(X, pd.Series):\n",
    "        return X.iloc[idx], y.iloc[idx]\n",
    "    else:\n",
    "        return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84275b0",
   "metadata": {},
   "source": [
    "## HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b1541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hgb_classifier_on_split(\n",
    "    Xtr, Xte, ytr, yte,\n",
    "    max_train_samples=200_000,\n",
    "    random_state=0\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a HistGradientBoostingClassifier on a (possibly) subsampled training split.\n",
    "    Evaluate on the full test split.\n",
    "    \"\"\"\n",
    "    # Subsample training data (stratified)\n",
    "    Xtr_sub, ytr_sub = stratified_subsample(\n",
    "        Xtr, ytr,\n",
    "        max_samples=max_train_samples,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    hgb_clf = HistGradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        max_iter=200,\n",
    "        max_leaf_nodes=31,\n",
    "        l2_regularization=1.0,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    hgb_clf.fit(Xtr_sub, ytr_sub)\n",
    "    y_pred = hgb_clf.predict(Xte)\n",
    "\n",
    "    p = precision_score(yte, y_pred)\n",
    "    r = recall_score(yte, y_pred)\n",
    "    s = 0.5 * (p + r)\n",
    "\n",
    "    results = {\n",
    "        \"model\": hgb_clf,\n",
    "        \"precision\": p,\n",
    "        \"recall\": r,\n",
    "        \"score\": s,\n",
    "        \"n_train_used\": len(Xtr_sub),\n",
    "    }\n",
    "    return results\n",
    "\n",
    "\n",
    "hgb_clf_results = train_hgb_classifier_on_split(\n",
    "    Xtr_clf, Xte_clf, ytr_clf, yte_clf,\n",
    "    max_train_samples=200_000,\n",
    "    random_state=0,\n",
    ")\n",
    "print(\"HGB classifier – Precision: {:.3f}, Recall: {:.3f}, Score: {:.3f}\".format(\n",
    "    hgb_clf_results[\"precision\"],\n",
    "    hgb_clf_results[\"recall\"],\n",
    "    hgb_clf_results[\"score\"],\n",
    "))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
