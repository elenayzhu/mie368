{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ec55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265e9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data_with_clusters.csv\"\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    \"airline_bucket\",\n",
    "    \"origin_bucket\",\n",
    "    \"destination_bucket\",\n",
    "    \"lagged_delay_flag\",\n",
    "    \"prev_real_delay\",\n",
    "]\n",
    "\n",
    "TARGET_CLF = \"DEP_DEL15\" #binary departure delay indicator\n",
    "TARGET_REG = \"DEP_DELAY_NEW\" #continuous departure delay (min)\n",
    "CLUSTER_COL = \"cluster\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# keep only needed columns, drop rows with missing in features/targets\n",
    "df = df.dropna(subset=FEATURE_COLS + [TARGET_CLF, TARGET_REG])\n",
    "\n",
    "X_clf = df[FEATURE_COLS]\n",
    "y_clf = df[TARGET_CLF].astype(int)\n",
    "\n",
    "X_reg = df[FEATURE_COLS]\n",
    "y_reg = df[TARGET_REG].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024353c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_models():\n",
    "    return {\n",
    "        \"LR_L2\": LogisticRegression(\n",
    "            random_state=0, solver=\"liblinear\", max_iter=200\n",
    "        ),\n",
    "        \"LR_L1\": LogisticRegression(\n",
    "            random_state=0,\n",
    "            penalty=\"l1\",\n",
    "            solver=\"liblinear\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=500,\n",
    "        ),\n",
    "        \"CART\": DecisionTreeClassifier(\n",
    "            random_state=0, class_weight=\"balanced\"\n",
    "        ),\n",
    "        \"RF\": RandomForestClassifier(\n",
    "            random_state=0, class_weight=\"balanced\"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "def init_all_models():\n",
    "    model_names = (\"LR_L2\", \"LR_L1\", \"CART\", \"RF\")\n",
    "    techniques = (\"Baseline\", \"Scaling\")  # subset of full Lab 6 list\n",
    "\n",
    "    idx = pd.MultiIndex.from_product(\n",
    "        [model_names, techniques],\n",
    "        names=(\"model\", \"technique\"),\n",
    "    )\n",
    "    all_models = pd.DataFrame(\n",
    "        index=idx,\n",
    "        columns=[\"Precision\", \"Recall\", \"Score\", \"Model\"],\n",
    "    )\n",
    "    all_models[[\"Precision\", \"Recall\", \"Score\"]] = all_models[\n",
    "        [\"Precision\", \"Recall\", \"Score\"]\n",
    "    ].astype(float)\n",
    "    return all_models\n",
    "\n",
    "\n",
    "def standardize_data(X_train, X_out):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    Xtr = pd.DataFrame(\n",
    "        scaler.transform(X_train),\n",
    "        index=X_train.index,\n",
    "        columns=X_train.columns,\n",
    "    )\n",
    "    Xout = pd.DataFrame(\n",
    "        scaler.transform(X_out),\n",
    "        index=X_out.index,\n",
    "        columns=X_out.columns,\n",
    "    )\n",
    "    return Xtr, Xout, scaler\n",
    "\n",
    "\n",
    "def fit_and_score_model(all_models, stage_name,\n",
    "                        X_train, X_out, y_train, y_out):\n",
    "    models_dict = make_models()\n",
    "\n",
    "    for model_name, model in models_dict.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_out)\n",
    "\n",
    "        p = precision_score(y_out, y_pred)\n",
    "        r = recall_score(y_out, y_pred)\n",
    "        s = 0.5 * (p + r)\n",
    "\n",
    "        all_models.loc[(model_name, stage_name), :] = [\n",
    "            p, r, s, model\n",
    "        ]\n",
    "    return all_models\n",
    "\n",
    "\n",
    "def compare_models(all_models, technique_name=\"Scaling\"):\n",
    "    diffs = (\n",
    "        all_models.xs(technique_name, level=\"technique\").Score.values\n",
    "        - all_models.xs(\"Baseline\", level=\"technique\").Score.values\n",
    "    )\n",
    "    print(\n",
    "        f\"{technique_name}: mean ΔScore={diffs.mean():.3f}, \"\n",
    "        f\"max ΔScore={diffs.max():.3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c4352a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\elena\\anaconda3\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3605\u001b[0m, in \u001b[0;36mndim\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m   3604\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m   3606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'ndim'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 32\u001b[0m\n\u001b[0;32m     22\u001b[0m     best_model \u001b[38;5;241m=\u001b[39m best_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_models\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_models,\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_model,\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m\"\u001b[39m: scaler,\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_split\u001b[39m\u001b[38;5;124m\"\u001b[39m: (Xtr, Xte, ytr, yte),\n\u001b[0;32m     29\u001b[0m     }\n\u001b[1;32m---> 32\u001b[0m global_clf_results \u001b[38;5;241m=\u001b[39m train_global_classification_models(X_clf, y_clf)\n\u001b[0;32m     33\u001b[0m global_clf_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_models\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m, in \u001b[0;36mtrain_global_classification_models\u001b[1;34m(X, y, test_size, random_state)\u001b[0m\n\u001b[0;32m      6\u001b[0m all_models \u001b[38;5;241m=\u001b[39m init_all_models()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Baseline\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m all_models \u001b[38;5;241m=\u001b[39m fit_and_score_model(\n\u001b[0;32m     10\u001b[0m     all_models, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline\u001b[39m\u001b[38;5;124m\"\u001b[39m, Xtr, Xte, ytr, yte\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Scaling\u001b[39;00m\n\u001b[0;32m     14\u001b[0m Xtr_s, Xte_s, scaler \u001b[38;5;241m=\u001b[39m standardize_data(Xtr, Xte)\n",
      "Cell \u001b[1;32mIn[4], line 69\u001b[0m, in \u001b[0;36mfit_and_score_model\u001b[1;34m(all_models, stage_name, X_train, X_out, y_train, y_out)\u001b[0m\n\u001b[0;32m     66\u001b[0m     r \u001b[38;5;241m=\u001b[39m recall_score(y_out, y_pred)\n\u001b[0;32m     67\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (p \u001b[38;5;241m+\u001b[39m r)\n\u001b[1;32m---> 69\u001b[0m     all_models\u001b[38;5;241m.\u001b[39mloc[(model_name, stage_name), :] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     70\u001b[0m         p, r, s, model\n\u001b[0;32m     71\u001b[0m     ]\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_models\n",
      "File \u001b[1;32mc:\\Users\\elena\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 911\u001b[0m iloc\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(indexer, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\elena\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1942\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1939\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1941\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1942\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\elena\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1979\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ABCDataFrame):\n\u001b[0;32m   1977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_frame_value(indexer, value, name)\n\u001b[1;32m-> 1979\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1980\u001b[0m     \u001b[38;5;66;03m# TODO: avoid np.ndim call in case it isn't an ndarray, since\u001b[39;00m\n\u001b[0;32m   1981\u001b[0m     \u001b[38;5;66;03m#  that will construct an ndarray, which will be wasteful\u001b[39;00m\n\u001b[0;32m   1982\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_2d_value(indexer, value)\n\u001b[0;32m   1984\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m lplane_indexer \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(pi):\n\u001b[0;32m   1985\u001b[0m     \u001b[38;5;66;03m# We are setting multiple rows in a single column.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elena\\anaconda3\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3607\u001b[0m, in \u001b[0;36mndim\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m   3605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m   3606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m-> 3607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m asarray(a)\u001b[38;5;241m.\u001b[39mndim\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "def train_global_classification_models(X, y, test_size=0.2, random_state=0):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    all_models = init_all_models()\n",
    "\n",
    "    # Baseline\n",
    "    all_models = fit_and_score_model(\n",
    "        all_models, \"Baseline\", Xtr, Xte, ytr, yte\n",
    "    )\n",
    "\n",
    "    # Scaling\n",
    "    Xtr_s, Xte_s, scaler = standardize_data(Xtr, Xte)\n",
    "    all_models = fit_and_score_model(\n",
    "        all_models, \"Scaling\", Xtr_s, Xte_s, ytr, yte\n",
    "    )\n",
    "\n",
    "    compare_models(all_models, \"Scaling\")\n",
    "\n",
    "    best_row = all_models.sort_values(\"Score\").iloc[-1]\n",
    "    best_model = best_row[\"Model\"]\n",
    "\n",
    "    return {\n",
    "        \"all_models\": all_models,\n",
    "        \"best_model\": best_model,\n",
    "        \"scaler\": scaler,\n",
    "        \"train_split\": (Xtr, Xte, ytr, yte),\n",
    "    }\n",
    "\n",
    "\n",
    "global_clf_results = train_global_classification_models(X_clf, y_clf)\n",
    "global_clf_results[\"all_models\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608de875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_classification_models(df,\n",
    "                                        feature_cols,\n",
    "                                        target_col,\n",
    "                                        cluster_col=\"cluster\",\n",
    "                                        test_size=0.2,\n",
    "                                        random_state=0):\n",
    "    cluster_results = {}\n",
    "\n",
    "    for clust_id, df_c in df.groupby(cluster_col):\n",
    "        y_c = df_c[target_col].astype(int)\n",
    "        if y_c.nunique() < 2 or len(df_c) < 40:\n",
    "            continue\n",
    "\n",
    "        X_c = df_c[feature_cols]\n",
    "\n",
    "        Xtr, Xte, ytr, yte = train_test_split(\n",
    "            X_c, y_c,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=y_c,\n",
    "        )\n",
    "\n",
    "        all_models = init_all_models()\n",
    "\n",
    "        all_models = fit_and_score_model(\n",
    "            all_models, \"Baseline\", Xtr, Xte, ytr, yte\n",
    "        )\n",
    "\n",
    "        Xtr_s, Xte_s, scaler = standardize_data(Xtr, Xte)\n",
    "        all_models = fit_and_score_model(\n",
    "            all_models, \"Scaling\", Xtr_s, Xte_s, ytr, yte\n",
    "        )\n",
    "\n",
    "        best_row = all_models.sort_values(\"Score\").iloc[-1]\n",
    "        best_model = best_row[\"Model\"]\n",
    "\n",
    "        cluster_results[clust_id] = {\n",
    "            \"all_models\": all_models,\n",
    "            \"best_model\": best_model,\n",
    "            \"scaler\": scaler,\n",
    "        }\n",
    "\n",
    "    return cluster_results\n",
    "\n",
    "\n",
    "cluster_clf_results = train_cluster_classification_models(\n",
    "    df,\n",
    "    FEATURE_COLS,\n",
    "    TARGET_CLF,\n",
    "    cluster_col=CLUSTER_COL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d360e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_global_regression_models(X, y, test_size=0.2, random_state=0):\n",
    "    Xtr, Xte, ytr, yte = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Plain linear regression (unscaled)\n",
    "    lin = LinearRegression()\n",
    "    lin.fit(Xtr, ytr)\n",
    "    yhat_lin = lin.predict(Xte)\n",
    "    lin_r2 = r2_score(yte, yhat_lin)\n",
    "    lin_mse = mean_squared_error(yte, yhat_lin)\n",
    "\n",
    "    # LassoCV (scaled)\n",
    "    Xtr_s, Xte_s, scaler = standardize_data(Xtr, Xte)\n",
    "    lasso = LassoCV(cv=5, random_state=random_state)\n",
    "    lasso.fit(Xtr_s, ytr)\n",
    "    yhat_lasso = lasso.predict(Xte_s)\n",
    "    lasso_r2 = r2_score(yte, yhat_lasso)\n",
    "    lasso_mse = mean_squared_error(yte, yhat_lasso)\n",
    "\n",
    "    return {\n",
    "        \"linear\": {\n",
    "            \"model\": lin,\n",
    "            \"r2\": lin_r2,\n",
    "            \"mse\": lin_mse,\n",
    "        },\n",
    "        \"lasso\": {\n",
    "            \"model\": lasso,\n",
    "            \"scaler\": scaler,\n",
    "            \"r2\": lasso_r2,\n",
    "            \"mse\": lasso_mse,\n",
    "        },\n",
    "        \"train_split\": (Xtr, Xte, ytr, yte),\n",
    "    }\n",
    "\n",
    "\n",
    "global_reg_results = train_global_regression_models(X_reg, y_reg)\n",
    "global_reg_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a2f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_regression_models(df,\n",
    "                                    feature_cols,\n",
    "                                    target_col,\n",
    "                                    cluster_col=\"cluster\",\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=0,\n",
    "                                    min_rows=40):\n",
    "    cluster_reg_results = {}\n",
    "\n",
    "    for clust_id, df_c in df.groupby(cluster_col):\n",
    "        if len(df_c) < min_rows:\n",
    "            continue\n",
    "\n",
    "        X_c = df_c[feature_cols]\n",
    "        y_c = df_c[target_col].astype(float)\n",
    "\n",
    "        Xtr, Xte, ytr, yte = train_test_split(\n",
    "            X_c, y_c,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        # linear\n",
    "        lin = LinearRegression()\n",
    "        lin.fit(Xtr, ytr)\n",
    "        yhat_lin = lin.predict(Xte)\n",
    "        lin_r2 = r2_score(yte, yhat_lin)\n",
    "        lin_mse = mean_squared_error(yte, yhat_lin)\n",
    "\n",
    "        # lasso (scaled)\n",
    "        Xtr_s, Xte_s, scaler = standardize_data(Xtr, Xte)\n",
    "        lasso = LassoCV(cv=5, random_state=random_state)\n",
    "        lasso.fit(Xtr_s, ytr)\n",
    "        yhat_lasso = lasso.predict(Xte_s)\n",
    "        lasso_r2 = r2_score(yte, yhat_lasso)\n",
    "        lasso_mse = mean_squared_error(yte, yhat_lasso)\n",
    "\n",
    "        cluster_reg_results[clust_id] = {\n",
    "            \"linear\": {\n",
    "                \"model\": lin,\n",
    "                \"r2\": lin_r2,\n",
    "                \"mse\": lin_mse,\n",
    "            },\n",
    "            \"lasso\": {\n",
    "                \"model\": lasso,\n",
    "                \"scaler\": scaler,\n",
    "                \"r2\": lasso_r2,\n",
    "                \"mse\": lasso_mse,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    return cluster_reg_results\n",
    "\n",
    "\n",
    "cluster_reg_results = train_cluster_regression_models(\n",
    "    df,\n",
    "    FEATURE_COLS,\n",
    "    TARGET_REG,\n",
    "    cluster_col=CLUSTER_COL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd3e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_rows = []\n",
    "#global classification\n",
    "global_df = global_clf_results[\"all_models\"].copy()\n",
    "global_df = global_df.reset_index()\n",
    "for _, row in global_df.iterrows():\n",
    "    summary_rows.append({\n",
    "        \"Level\": \"Global\",\n",
    "        \"Cluster\": \"-\",\n",
    "        \"Task\": \"Classification\",\n",
    "        \"Model\": row[\"model\"],\n",
    "        \"Technique\": row[\"technique\"],\n",
    "        \"Precision\": row[\"Precision\"],\n",
    "        \"Recall\": row[\"Recall\"],\n",
    "        \"Score\": row[\"Score\"],\n",
    "        \"R2\": None,\n",
    "        \"MSE\": None\n",
    "    })\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# CLUSTER CLASSIFICATION\n",
    "# (best model per cluster)\n",
    "# --------------------------\n",
    "for clust_id, res in cluster_clf_results.items():\n",
    "    best_row = res[\"all_models\"].sort_values(\"Score\").iloc[-1]\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"Level\": \"Cluster\",\n",
    "        \"Cluster\": clust_id,\n",
    "        \"Task\": \"Classification\",\n",
    "        \"Model\": best_row.name[0],  # model name\n",
    "        \"Technique\": best_row.name[1],  # Baseline/Scaling\n",
    "        \"Precision\": best_row[\"Precision\"],\n",
    "        \"Recall\": best_row[\"Recall\"],\n",
    "        \"Score\": best_row[\"Score\"],\n",
    "        \"R2\": None,\n",
    "        \"MSE\": None\n",
    "    })\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# GLOBAL REGRESSION\n",
    "# --------------------------\n",
    "# linear\n",
    "summary_rows.append({\n",
    "    \"Level\": \"Global\",\n",
    "    \"Cluster\": \"-\",\n",
    "    \"Task\": \"Regression\",\n",
    "    \"Model\": \"LinearRegression\",\n",
    "    \"Technique\": \"Baseline\",\n",
    "    \"Precision\": None,\n",
    "    \"Recall\": None,\n",
    "    \"Score\": None,\n",
    "    \"R2\": global_reg_results[\"linear\"][\"r2\"],\n",
    "    \"MSE\": global_reg_results[\"linear\"][\"mse\"]\n",
    "})\n",
    "\n",
    "# lasso\n",
    "summary_rows.append({\n",
    "    \"Level\": \"Global\",\n",
    "    \"Cluster\": \"-\",\n",
    "    \"Task\": \"Regression\",\n",
    "    \"Model\": \"LassoCV\",\n",
    "    \"Technique\": \"Scaled\",\n",
    "    \"Precision\": None,\n",
    "    \"Recall\": None,\n",
    "    \"Score\": None,\n",
    "    \"R2\": global_reg_results[\"lasso\"][\"r2\"],\n",
    "    \"MSE\": global_reg_results[\"lasso\"][\"mse\"]\n",
    "})\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# CLUSTER REGRESSION\n",
    "# --------------------------\n",
    "for clust_id, res in cluster_reg_results.items():\n",
    "\n",
    "    # linear\n",
    "    summary_rows.append({\n",
    "        \"Level\": \"Cluster\",\n",
    "        \"Cluster\": clust_id,\n",
    "        \"Task\": \"Regression\",\n",
    "        \"Model\": \"LinearRegression\",\n",
    "        \"Technique\": \"Baseline\",\n",
    "        \"Precision\": None,\n",
    "        \"Recall\": None,\n",
    "        \"Score\": None,\n",
    "        \"R2\": res[\"linear\"][\"r2\"],\n",
    "        \"MSE\": res[\"linear\"][\"mse\"]\n",
    "    })\n",
    "\n",
    "    # lasso\n",
    "    summary_rows.append({\n",
    "        \"Level\": \"Cluster\",\n",
    "        \"Cluster\": clust_id,\n",
    "        \"Task\": \"Regression\",\n",
    "        \"Model\": \"LassoCV\",\n",
    "        \"Technique\": \"Scaled\",\n",
    "        \"Precision\": None,\n",
    "        \"Recall\": None,\n",
    "        \"Score\": None,\n",
    "        \"R2\": res[\"lasso\"][\"r2\"],\n",
    "        \"MSE\": res[\"lasso\"][\"mse\"]\n",
    "    })\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# BUILD FINAL SUMMARY TABLE\n",
    "# --------------------------\n",
    "summary_table = pd.DataFrame(summary_rows)\n",
    "\n",
    "# sorting for readability\n",
    "summary_table = summary_table.sort_values(\n",
    "    by=[\"Task\", \"Level\", \"Cluster\", \"Model\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "summary_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
